[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Instructor/TA",
    "section": "",
    "text": "Instructor: Andrew Zieffler  Email: zief0002@umn.edu  Office: Education Sciences Building 178  Office Hours: Tuesday 11:30 AM‚Äì12:30 PM; and by appointment  Virtual Office: If you want to meet virtually, send me a Google calendar invite and include a Zoom link in the invite."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Due Dates",
    "section": "",
    "text": "Below are the due dates for the assignments, as well as links to each assignment. All assignments are due by 5:00 PM on the due date. The due dates may change at the instructor‚Äôs discretion. Any revised due dates will be announced in class and posted to the website."
  },
  {
    "objectID": "assignments.html#faqs",
    "href": "assignments.html#faqs",
    "title": "Assignment Due Dates",
    "section": "FAQs",
    "text": "FAQs\nHow do I submit the assignment?\nCreate a PDF of your responses and submit the PDF via email to both the instructor and TA. Also cc any group members. Before you submit the assignment check that:\n\nAll group members‚Äô names are on the assignment.\nAll tables are numbered and have a caption.\nAll figures are numbered and have a caption.\nAll figures are re-sized to not take up more page space than is necessary to read them.\nNo R syntax is included unless the question specifically asked for the syntax to be included. If there is R syntax included, be sure that it is typeset in a monospaced font (e.g., Courier, Inconsolata).\nDo not submit the script file you used unless the directions specifically ask you to submit it.\n\nDo I need to turn in the script file?\nNo‚Ä¶unless the directions specifically ask you to submit the script file. The script file is for your reference. Future assignments will sometimes have questions that reference older assignments, so an organized and well-commented script file is a good idea. Moreover, the TA or myself may ask you to submit your syntax after you submit the assignment to help us interpret mistakes you made on the assignment so that we can provide more thorough feedback.\nWill you provide answer keys to the assignments?\nNo.¬†You will get back several comments on your assignments that address what you did wrong. The educational research is pretty clear that feedback is more helpful to student learning than providing correct answers. If you have further questions or need additional clarification, you are welcome to come to office hours or make an appointment with the instructor or TA.\nWill you go over the answers in class?\nNo.¬†I will address broad concepts if several students/groups made the same mistake, but otherwise, since each student/group makes unique mistakes going over the assignments more broadly is not a good use of our limited class time. The feedback should be helpful in understanding any mistakes you made, but if it isn‚Äôt, you are welcome to come to office hours or make an appointment with the instructor or TA.\nWill you look at our assignment prior to us submitting it?\nThe instructor or TA will not ‚Äúpre-grade‚Äù your assignment. If there is a ‚ÄúPreparation‚Äù part of the assignment we can ensure that you did that part correctly, and we can also give you feedback about syntax, but we will not tell you if an answer is correct or not. We can also answer clarifying questions (e.g., ‚ÄòI know Question 8 is asking about [‚Ä¶], but I‚Äôm not sure what this question is looking for. Is there another way to restate this question?‚Äô). If you completed the assignment without any trouble, then be confident in your work and simply submit the assignment! üòÑ If you are unsure about something specific, then ask about that specific thing rather than a general ‚Äòdid I do this right‚Äô!\nWill we be able to re-do the assignment?\nGenerally no. Since you have the opportunity to work in groups on the assignments, you should be able offset any of the issues that come up that would necessitate a re-submission. The exception to this is that we may allow you to re-do Assignment 1. If we do this, we will send you an email requesting that you resubmit part, or all of Assignment 1. You will not receive much feedback on your assignment prior to your re-submission. This is because during the first assignment you are learning not only content, but also expectations around how to respond to the questions we ask."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Below are the links to the data sets and data codebooks used in the notes, scripts, and assignments."
  },
  {
    "objectID": "data.html#how-to-download-a-csv-file-to-your-computer",
    "href": "data.html#how-to-download-a-csv-file-to-your-computer",
    "title": "Data",
    "section": "How to Download a CSV File to Your Computer",
    "text": "How to Download a CSV File to Your Computer\nTo download a data (CSV) file, click on the data set. Then click the RAW button. Now you should be able to right-click the dataset and save it. If you are using Safari on a Mac, make sure that the downloaded data does not have an extra .txt appended to it when it downloads. If it does, just delete the extra .txt suffix."
  },
  {
    "objectID": "index.html#welcome-to-epsy-8251-methods-in-data-analysis-for-educational-research-i",
    "href": "index.html#welcome-to-epsy-8251-methods-in-data-analysis-for-educational-research-i",
    "title": "",
    "section": "Welcome to EPsy 8251: Methods in Data Analysis for Educational Research I",
    "text": "Welcome to EPsy 8251: Methods in Data Analysis for Educational Research I\nEPsy 8251: Methods in Data Analysis for Educational Research I is the first course in an entry-level, doctoral sequence for students in education. The two semester sequence provides in-depth coverage of widely used statistical methods and models and prepares students for advanced statistical coursework. EPsy 8251 provides rigorous coverage of estimation and hypothesis testing with a particular focus on the General Linear Model. The roadmap for the course is:\n\n\n\n\n\n\n\n\n\nEPsy 8251 is a 3 credit course. It is expected that the academic work required of Graduate School and professional school students will exceed three hours per credit per week (see Expected Student Academic Work Policy). In my experience, it is typical for students to spend 10‚Äì15 hours a week on this course. As with every class, some students will spend more time than that on this course, while others will spend less time than that‚Äîit all depends on your prior experiences with statistics and computing. If you find yourself consistently spending more than 20 hours a week on the course, please make an appointment to see the instructor so that we can strategize about how to best optimize how you are devoting time to the course. \n\nA Note on Inclusion and Respect\nIn this class, we will work together to develop a learning community that is inclusive and respectful, and where every student is supported in the learning process. As a class full of diverse individuals (reflected by differences in race, culture, age, religion, gender identity, sexual orientation, socioeconomic background, abilities, professional goals, and other social identities and life experiences) I expect that different students may need different things to support and promote their learning. The TAs and I will do everything we can to help with this, but as we only know what we know, we need you to communicate with us if things are not working for you or you need something we are not providing. I hope you all feel comfortable in helping to promote an inclusive classroom through respecting one another‚Äôs individual differences, speaking up, and challenging oppressive/problematic ideas. Finally, I look forward to learning from each of you and the experiences you bring to the class."
  },
  {
    "objectID": "index.html#classroom",
    "href": "index.html#classroom",
    "title": "",
    "section": "Classroom",
    "text": "Classroom\n\nMonday/Wednesday (2:30pm‚Äì3:45pm): Scott Hall 4"
  },
  {
    "objectID": "index.html#textbooks",
    "href": "index.html#textbooks",
    "title": "",
    "section": "Textbooks",
    "text": "Textbooks\nThe course textbook is available via the University of Minnesota library.\n\nFox, J. (2013). A mathematical primer for social statistics. Sage.\n\nHere are several free resources that will help you fill in any missing pre-requisite knowledge:\n\nStatistical Modeling and Computation for Educational Scientists\n\nLearn basics of R\nLearn {dplyr} for wrangling data\nLearn {ggplot2} for visualizing data\nLearn about simple and multiple regression\nLearn about Ordinary Least squares (OLS)\nLearn about correlation/standardized regression\nLearn about regression assumptions\nLearn about dummy coding for dichotomous/polychotomous predictors\nLearn about interaction effects\n\nEPsy 8252 Materials\n\nLearn about Maximum Likelihood\nLearn about information criteria\nLearn about polynomial effects\nLearn about log-transformations\nLearn about logistic models\nLearn about linear mixed-effects models"
  },
  {
    "objectID": "index.html#course-requirements-and-grading",
    "href": "index.html#course-requirements-and-grading",
    "title": "",
    "section": "Course Requirements and Grading",
    "text": "Course Requirements and Grading\nStudents will complete eight homework assignments. The homework assignments and due dates will be posted on the Assignments page of the course website. These assignments include problems that will help you learn the course material through reflection and practice. Submit each assignment as a PDF file via email to the TA.\nTo foster cooperation and collaboration, you are permitted to form groups of no larger than three to work on the homework. Submit only one assignment per group, and list the names of each group member on the assignment. Each assignment will be scored and this score will be given to all individuals in the group. From past experience, student collaborations work most fluidly when everyone in the group has chosen the same grading option for the course (e.g., A/F, S/N, etc.).\nIf you work alone on the assignments, you need to truly work alone. To protect against running afoul of the scholastic dishonesty policy, students working alone are not permitted to interact with any other student in regards to the assignment, including discussion, obtaining help, etc."
  },
  {
    "objectID": "index.html#chatgpt-and-other-ai",
    "href": "index.html#chatgpt-and-other-ai",
    "title": "",
    "section": "ChatGPT and Other AI",
    "text": "ChatGPT and Other AI\nArtificial intelligence (AI) language models, such as ChatGPT, may be used to help you write R syntax with appropriate citation, but not for answering any of the questions on the assignment. If you are in doubt as to whether you are using AI language models appropriately in this course, I encourage you to discuss your situation with me or the TA. Examples of citing AI language models are available at: https://libguides.umn.edu/chatgpt. You are responsible for ensuring any syntax composed by AI is correct.\n\n\nPolicy for Missing Class and Making up Missed/Late Work\nStudents are responsible for planning their schedules to avoid excessive conflicts with course requirements and must notify the instructor of unavoidable scheduling conflicts as early as possible. For circumstances where absences are unavoidable, accommodations for makeup work will be made according to University Policy. If you miss class:\n\nEmail the instructor as soon as you know you will be missing class.\nStudents are expected to obtain notes from a classmate of class material missed.\nPlease note that I will not be recording class sessions at the request of individual students, nor will I be Zooming students in to the class. Although, if you can arrange it with a classmate, they can Zoom you in.\n\nIf you are zooming in a classmate, please let the instructor know.\n\nIf you will be gone the day an assignment is due, you will need to make arrangements with the instructor about when you will turn in the assignment.\n\nIf you do not communicate with the instructor and make arrangements for turning in work when you are absent, the assignment will receive a 0.\n\n\n\nEvaluation of Student Performance\nCourse grades will be based entirely on performance on the homework assignments. The points from the eight homework assignment will be pooled to compute a percentage in the class, which will be converted to a final course grade using:\n\n\n\n\n\n\n\n\nCutoff\nGrade\nDefinition for Graduate Credit\n\n\n\n\n93%‚Äì100%\nA\nFor exceptional work, well above the minimum criteria\n\n\n90%‚Äì92%\nA‚Äì\nFor outstanding work, well above the minimum criteria\n\n\n87%‚Äì89%\nB+\nFor excellent work, significant above the minimum criteria\n\n\n83%‚Äì86%\nB\nFor work above the minimum criteria\n\n\n80%‚Äì82%\nB‚Äì\n\n\n\n77%‚Äì79%\nC+\n\n\n\n73%‚Äì76%\nC\nFor work which meets the course requirements in every respect\n\n\n70%‚Äì72%\nC‚Äì\n\n\n\n63%‚Äì69%\nD\nWorthy of credit even though it fails to meet the course requirements\n\n\n0%‚Äì62%\nF\nFailed to meet minimum course requirements\n\n\n\nIf you are taking the course S/N, the minimum criterion to receive an S is 80% (the equivalent of a B‚Äì letter grade). The S grade does not carry grade points and is not part of the GPA calculation, but the credits will count toward the student‚Äôs degree program if allowed by the college, campus, or program.\nAny student who does not complete all homework assignments without making prior arrangements with the instructor will receive a grade of F/N.\n\n\n\nIncomplete\nInstructors may assign the registration symbol ‚ÄúI‚Äù for Incomplete if, at the time the incomplete is requested: (1) the student has successfully completed a substantial portion of the work of the course; and (2) due to extraordinary circumstances (as determined by the instructor), the student was prevented from completing the work of the course on time. The assignment of an ‚ÄúI‚Äù requires a written agreement with the student specifying the time and manner in which the student will complete the course requirements. For more information see Grading and Transcripts.\n\n\n\nAccessing Course Grades\nShortly after the course, you may access your grades online at myU. Assignments will be handed back in class or during office hours. Uncollected assignments will be retained for six weeks after the course and then discarded.\n\n\n\nStress Management\nStress management is an important piece of the skill set needed for success in graduate school. Pet Away Worry & Stress (PAWS) is one of the many resources available to students. Find out more at https://boynton.umn.edu/paws.\n\nYou can follow Tilly the Therapy Chicken on Twitter (@TherapyChicken)."
  },
  {
    "objectID": "index.html#statistical-computing",
    "href": "index.html#statistical-computing",
    "title": "",
    "section": "Statistical Computing",
    "text": "Statistical Computing\nStatistical computing is an integral part of statistical work, and subsequently, EPsy 8251. To support your learning in this area, this course will emphasize the use of R. R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS https://www.r-project.org. It should be noted that while some R syntax and programming is taught during class time, there is also a fair amount that you may need to learn on your own outside of class. There are several tutorials and resources linked from the course website to help you learn R.\nYou can install R and RStudio onto your local machine. (There are instructions for how to do this on the course website.) You are responsible for getting things to work on your computer. While it should be straightforward, each OS and computer has their quirks. I can try to help you with this if you are having trouble.\n\n\nTechnology Policy\nThe course uses technology on a regular basis during both instruction and assessments (e.g., homework assignments, exams, etc.). Student difficulty with obtaining or operating the various software programs and technologies‚Äîincluding printer trouble‚Äîwill not be acceptable as an excuse for late work. Due to the variation in computer types and systems, the instructor or TA may not be able to assist in trouble shooting all problems you may have.\n\n\n\n\nCEHD Policy on Recording Classes\nAll class sessions may be recorded by the instructor using the procedures in the CEHD Policy on Recording Classes, with or without prior notice. Students should assume that a class session is being recorded unless otherwise notified. No person (student or otherwise) may record a class without express written permission from the instructor or an authorized administrator implementing a disability accommodation. All permitted recordings are governed by this policy‚Äôs limits on distribution and redistribution of recordings."
  },
  {
    "objectID": "index.html#image-attribution",
    "href": "index.html#image-attribution",
    "title": "",
    "section": "Image Attribution",
    "text": "Image Attribution\n\nThe icon in the Inclusion Note was created by Freepik - Flaticon.\nThe icon in the Technology Policy was created by Freepik - Flaticon.\nThe icon of Tilly the Therapy Chicken in the Stress Managment note is used with permissin of the PAWS program.\nThe icon in the CEHD Policy on Recording note was created by Hilmy Abiyyu A. - Flaticon.\nThe icon in the Missing Class Policy was created by Freepik - Flaticon."
  },
  {
    "objectID": "mission-statements.html",
    "href": "mission-statements.html",
    "title": "Mission Statements",
    "section": "",
    "text": "Quantitative Methods in Education Mission Statement\nQME strives to be a premier program recognized for leadership, innovation, and excellence, and to enable human potential through the advancement of education. QME prepares students to become cutting-edge professionals in educational measurement, evaluation, statistics, and statistics education, through excellence in teaching, research, and service; and through investigating and developing research methodology in education.\n\n\n\nDepartment of Educational Psychology Mission Statement\nEducational psychology involves the study of cognitive, emotional, and social learning processes that underlie education and human development across the lifespan. Research in educational psychology advances scientific knowledge of those processes and their application in diverse educational and community settings. The department provides training in the psychological foundations of education, research methods, and the practice and science of counseling psychology, school psychology, and special education. Faculty and students provide leadership and consultation to the state, the nation, and the international community in each area of educational psychology. The department‚Äôs scholarship and teaching enhance professional practice in schools and universities, community mental health agencies, business and industrial organizations, early childhood programs, and government agencies. Adopted by the Department. of Educational Psychology faculty October 27, 2004\n\n\n\nCollege of Education + Human Development Mission Statement\nThe mission of the University of Minnesota College of Education and Human Development is to contribute to a just and sustainable future through engagement with the local and global communities to enhance human learning and development at all stages of the life span."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Calendar",
    "section": "",
    "text": "The calendar below lists the tentative course topics. The dates listed are subject to change at the instructor‚Äôs discretion.\nAs part of the course, there are several articles, papers and technical reports that you will need to read during the semester. Most of the articles themselves are accessible through the University of Minnesota library website (http://www.lib.umn.edu). In order to access the full text of some of the articles, you will need to log in using your University x500 username and password. More detailed information, including references or links to specific readings, are linked under the day‚Äôs ‚ÄúReading‚Äù.\n\n\n\n‚Äì&gt;     \n\n\n\n\nDate\n\n\nReading\n\n\nTopic\n\n\nNotes\n\n\n\n\n\n\n\n¬†\n\n\nSept.¬†05\n\n\n\n\n\nWelcome to EPsy 8264\n\n\n¬†\n\n\n\n\n\nUnit 01: Mathematical and Computational Foundations\n\n\n\n\n¬†\n\n\nSept.¬†07\n\n\n\n\n\nIntroduction to Matrix Algebra\n\n\n\n\n\n\n\n¬†\n\n\nSept.¬†12\n\n\n\n\n¬†\n\n\nSept.¬†14\n\n\n\n\n\nOLS Regression using Matrices and its Properties\n\n\n\n\n\n\n\n¬†\n\n\nSept.¬†19\n\n\n\n\n\nUnit 02: Simulation\n\n\n\n\n¬†\n\n\nSept.¬†21\n\n\n\n\n\nSimulating from the Regression Model\n\n\n\n\n\n\n\n¬†\n\n\nSept.¬†26\n\n\n\n\n¬†\n\n\nSept.¬†28\n\n\n\n\n\nUnit 03: Path Analysis\n\n\n\n\n\n¬†\n\n\nOct.¬†03\n\n\n\n\n\nRegression from Summary Measures\n\n\n\n\n\n\n\n¬†\n\n\nOct.¬†05\n\n\n\n\nPath Analysis\n\n\n\n\n\n\n\n¬†\n\n\nOct.¬†10\n\n\n\n\n\nMore Path Models\n\n\n\n\n\n\n\n\n\n\n\n\nUnit 04: Regression Diagnostics\n\n\n\n\n¬†\n\n\nOct.¬†12\n\n\n\n\n\nRegression Diagnostics\n\n\n\n\n\n\n\n¬†\n\n\nOct.¬†17\n\n\n\n\n¬†\n\n\nOct.¬†19\n\n\n\n\nNO CLASS‚ÄîMental Health Day üõå üç∑\n\n\n\n\n\n\n\nUnit 05: Tools for Dealing with Heteroskedasticity\n\n\n\n\n¬†\n\n\nOct.¬†24\n\n\n\n\n\nVariance Stabilizing Transformations\n\n\n\n\n\n\n\n¬†\n\n\nOct.¬†26\n\n\n\n\n\nWeighted Least Squares (WLS) and Sandwich Estimation\n\n\n\n\n\n\n\n\nUnit 06: Diagnosing Collinearity and Tools for Dealing with It\n\n\n\n\n¬†\n\n\nOct.¬†31\n\n\n\n\n\nDiagnosing Collinearity\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†02\n\n\n\n\n¬†\n\n\nNov.¬†07\n\n\n\n\n\nPrincipal Components Analysis via Spectral Decomposition\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†09\n\n\n\n\n¬†\n\n\nNov.¬†14\n\n\n\n\n\nPrincipal Components Analysis via Singular Value Decomposition\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†16\n\n\n\n\n\nBiased Estimation: Ridge Regression\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†21\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†23\n\n\n\n\nNO CLASS‚ÄîThanksgiving Break ü¶É üåΩ ü•ß\n\n\n\n\n\n\n\nUnit 07: Model Selection\n\n\n\n\n¬†\n\n\nNov.¬†28\n\n\n\n\nModel Selection Activity\n\n\n\n\n\n\n\n¬†\n\n\nNov.¬†30\n\n\n\n\n\nModel Selection: The ‚ÄòVintage‚Äô Methods\n\n\n\n\n\n\n\n¬†\n\n\nDec.¬†05\n\n\n\n\n\nModel Selection: Cross-Validation Methods\n\n\n\n\n\n\n\n¬†\n\n\nDec.¬†07\n\n\n\n\n¬†\n\n\nDec.¬†12\n\n\n\n\nTBD"
  },
  {
    "objectID": "umn-policies.html",
    "href": "umn-policies.html",
    "title": "University of Minnesota Policies and Procedures",
    "section": "",
    "text": "Academic freedom is a cornerstone of the University. Within the scope and content of the course as defined by the instructor, it includes the freedom to discuss relevant matters in the classroom. Along with this freedom comes responsibility. Students are encouraged to develop the capacity for critical judgment and to engage in a sustained and independent search for truth. Students are free to take reasoned exception to the views offered in any course of study and to reserve judgment about matters of opinion, but they are responsible for learning the content of any course of study for which they are enrolled.1 Reports of concerns about academic freedom are taken seriously, and there are individuals and offices available for help. Contact the instructor (Andrew Zieffler; zief0002@umn.edu), the Department Chair (Anne Foegen; afoegen@umn.edu), your adviser, the associate dean of the college (Tabitha Grier-Reed; grier001@umn.edu), or the Vice Provost for Faculty and Academic Affairs in the Office of the Provost (Beth Lewis; blewis@umn.edu)."
  },
  {
    "objectID": "umn-policies.html#academic-freedom-and-responsibility",
    "href": "umn-policies.html#academic-freedom-and-responsibility",
    "title": "University of Minnesota Policies and Procedures",
    "section": "",
    "text": "Academic freedom is a cornerstone of the University. Within the scope and content of the course as defined by the instructor, it includes the freedom to discuss relevant matters in the classroom. Along with this freedom comes responsibility. Students are encouraged to develop the capacity for critical judgment and to engage in a sustained and independent search for truth. Students are free to take reasoned exception to the views offered in any course of study and to reserve judgment about matters of opinion, but they are responsible for learning the content of any course of study for which they are enrolled.1 Reports of concerns about academic freedom are taken seriously, and there are individuals and offices available for help. Contact the instructor (Andrew Zieffler; zief0002@umn.edu), the Department Chair (Anne Foegen; afoegen@umn.edu), your adviser, the associate dean of the college (Tabitha Grier-Reed; grier001@umn.edu), or the Vice Provost for Faculty and Academic Affairs in the Office of the Provost (Beth Lewis; blewis@umn.edu)."
  },
  {
    "objectID": "umn-policies.html#appropriate-student-use-of-class-notes-and-course-materials",
    "href": "umn-policies.html#appropriate-student-use-of-class-notes-and-course-materials",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Appropriate Student Use of Class Notes and Course Materials",
    "text": "Appropriate Student Use of Class Notes and Course Materials\nTaking notes is a means of recording information but more importantly of personally absorbing and integrating the educational experience. However, broadly disseminating class notes beyond the classroom community or accepting compensation for taking and distributing classroom notes undermines instructor interests in their intellectual work product while not substantially furthering instructor and student interests in effective learning. Such actions violate shared norms and standards of the academic community. For additional information, please see: https://policy.umn.edu/education/studentresp."
  },
  {
    "objectID": "umn-policies.html#disability-accommodations",
    "href": "umn-policies.html#disability-accommodations",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Disability Accommodations",
    "text": "Disability Accommodations\nThe University of Minnesota views disability as an important aspect of diversity, and is committed to providing equitable access to learning opportunities for all students. The Disability Resource Center (DRC) is the campus office that collaborates with students who have disabilities to provide and/or arrange reasonable accommodations.\n\nIf you have, or think you have, a disability in any area such as, mental health, attention, learning, chronic health, sensory, or physical, please contact the DRC office on your campus (612.626.1333) to arrange a confidential discussion regarding equitable access and reasonable accommodations.\nStudents with short-term disabilities, such as a broken arm, can often work with instructors to minimize classroom barriers. In situations where additional assistance is needed, students should contact the DRC as noted above.\nIf you are registered with the DRC and have a disability accommodation letter dated for this semester or this year, please contact your instructor early in the semester to review how the accommodations will be applied in the course.\nIf you are registered with the DRC and have questions or concerns about your accommodations please contact your (access consultant/disability specialist).\n\nAdditional information is available on the DRC website or e-mail drc@umn.edu with questions."
  },
  {
    "objectID": "umn-policies.html#equity-diversity-equal-opportunity-and-affirmative-action",
    "href": "umn-policies.html#equity-diversity-equal-opportunity-and-affirmative-action",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Equity, Diversity, Equal Opportunity, and Affirmative Action",
    "text": "Equity, Diversity, Equal Opportunity, and Affirmative Action\nThe University will provide equal access to and opportunity in its programs and facilities, without regard to race, color, creed, religion, national origin, gender, age, marital status, disability, public assistance status, veteran status, sexual orientation, gender identity, or gender expression. For more information, please consult Board of Regents Policy."
  },
  {
    "objectID": "umn-policies.html#makeup-work-for-legitimate-absences",
    "href": "umn-policies.html#makeup-work-for-legitimate-absences",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Makeup Work for Legitimate Absences",
    "text": "Makeup Work for Legitimate Absences\nStudents will not be penalized for absence during the semester due to unavoidable or legitimate circumstances. Such circumstances include verified illness, participation in intercollegiate athletic events, subpoenas, jury duty, military service, bereavement, and religious observances. Such circumstances do not include voting in local, state, or national elections. For complete information, please see: https://policy.umn.edu/education/makeupwork."
  },
  {
    "objectID": "umn-policies.html#mental-health-and-stress-management",
    "href": "umn-policies.html#mental-health-and-stress-management",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Mental Health and Stress Management",
    "text": "Mental Health and Stress Management\nAs a student you may experience a range of issues that can cause barriers to learning, such as strained relationships, increased anxiety, alcohol/drug problems, feeling down, difficulty concentrating and/ or lack of motivation. These mental health concerns or stressful events may lead to diminished academic performance and may reduce your ability to participate in daily activities. University of Minnesota services are available to assist you. You can learn more about the broad range of confidential mental health services available on campus via the Student Mental Health Website."
  },
  {
    "objectID": "umn-policies.html#scholastic-dishonesty",
    "href": "umn-policies.html#scholastic-dishonesty",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Scholastic Dishonesty",
    "text": "Scholastic Dishonesty\nYou are expected to do your own academic work and cite sources as necessary. Failing to do so is scholastic dishonesty. Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. (Student Conduct Code)\nIf it is determined that a student has cheated, the student may be given an ‚ÄúF‚Äù or an ‚ÄúN‚Äù for the course, and may face additional sanctions from the University. For additional information, please see the policy statement. The Office for Community Standards has compiled a useful list of Frequently Asked Questions pertaining to scholastic dishonesty. If you have additional questions, please clarify with your instructor for the course. Your instructor can respond to your specific questions regarding what would constitute scholastic dishonesty in the context of a particular class‚Äîe.g., whether collaboration on assignments is permitted, requirements and methods for citing sources, if electronic aids are permitted or prohibited during an exam."
  },
  {
    "objectID": "umn-policies.html#senate-academic-workload-policy",
    "href": "umn-policies.html#senate-academic-workload-policy",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Senate Academic Workload Policy",
    "text": "Senate Academic Workload Policy\nOne conventional credit is hereby defined as equivalent to three hours of learning effort per week, averaged over an appropriate time interval, necessary for an average student taking that course to achieve an average grade in that course. It is expected that the academic work required of graduate and professional students will exceed three hours per credit per week or 45 hours per semester."
  },
  {
    "objectID": "umn-policies.html#sexual-harassment-sexual-assault-stalking-and-relationship-violence",
    "href": "umn-policies.html#sexual-harassment-sexual-assault-stalking-and-relationship-violence",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Sexual Harassment, Sexual Assault, Stalking and Relationship Violence",
    "text": "Sexual Harassment, Sexual Assault, Stalking and Relationship Violence\nThe University prohibits sexual misconduct, and encourages anyone experiencing sexual misconduct to access resources for personal support and reporting. If you want to speak confidentially with someone about an experience of sexual misconduct, please contact your campus resources including the Aurora Center, Boynton Mental Health or Student Counseling Services https://eoaa.umn.edu/report-misconduct. If you want to report sexual misconduct, or have questions about the University‚Äôs policies and procedures related to sexual misconduct, please contact your campus Title IX office or relevant policy contacts.\nInstructors are required to share information they learn about possible sexual misconduct with the campus Title IX office that addresses these concerns. This allows a Title IX staff member to reach out to those who have experienced sexual misconduct to provide information about personal support resources and options for investigation. You may talk to instructors about concerns related to sexual misconduct, and they will provide support and keep the information you share private to the extent possible given their University role. https://regents.umn.edu/sites/regents.umn.edu/files/2019-09/policy_sexual_harassment_sexual_assault_stalking_and_relationship_violence.pdf"
  },
  {
    "objectID": "umn-policies.html#sexual-harassment",
    "href": "umn-policies.html#sexual-harassment",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Sexual Harassment",
    "text": "Sexual Harassment\n‚ÄúSexual harassment‚Äù means unwelcome sexual advances, requests for sexual favors, and/or other verbal or physical conduct of a sexual nature. Such conduct has the purpose or effect of unreasonably interfering with an individual‚Äôs work or academic performance or creating an intimidating, hostile, or offensive working or academic environment in any University activity or program. Such behavior is not acceptable in the University setting. For additional information, please consult Board of Regents Policy"
  },
  {
    "objectID": "umn-policies.html#student-conduct-code",
    "href": "umn-policies.html#student-conduct-code",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Student Conduct Code",
    "text": "Student Conduct Code\nThe University seeks an environment that promotes academic achievement and integrity, that is protective of free inquiry, and that serves the educational mission of the University. Similarly, the University seeks a community that is free from violence, threats, and intimidation; that is respectful of the rights, opportunities, and welfare of students, faculty, staff, and guests of the University; and that does not threaten the physical or mental health or safety of members of the University community. As a student at the University you are expected adhere to Board of Regents Policy: Student Conduct Code.\nNote that the conduct code specifically addresses disruptive classroom conduct, which means ‚Äúengaging in behavior that substantially or repeatedly interrupts either the instructor‚Äôs ability to teach or student learning. The classroom extends to any setting where a student is engaged in work toward academic credit or satisfaction of program-based requirements or related activities.‚Äù"
  },
  {
    "objectID": "umn-policies.html#use-of-personal-electronic-devices-in-the-classroom",
    "href": "umn-policies.html#use-of-personal-electronic-devices-in-the-classroom",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Use of Personal Electronic Devices in the Classroom",
    "text": "Use of Personal Electronic Devices in the Classroom\nUsing personal electronic devices in the classroom setting can hinder instruction and learning, not only for the student using the device but also for other students in the class. To this end, the University establishes the right of each faculty member to determine if and how personal electronic devices are allowed to be used in the classroom. For complete information, please reference: https://policy.umn.edu/education/studentresp."
  },
  {
    "objectID": "umn-policies.html#grading-and-transcripts",
    "href": "umn-policies.html#grading-and-transcripts",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Grading and Transcripts",
    "text": "Grading and Transcripts\nUniversity Grading Scales The University has two distinct grading scales: A‚ÄìF and S‚ÄìN.\nA‚ÄìF grading scale. The A‚ÄìF grading scale allows the following grades and corresponding GPA points:\n\n\n\n\n\n\n\n\nGrade\nGPA Points\nDefinitions for undergraduate credit\n\n\n\n\nA\n4.000\nRepresents achievement that significantly exceeds expectations in the course.\n\n\nA-\n3.667\n\n\n\nB+\n3.333\n\n\n\nB\n3.000\nRepresents achievement that is above the minimum expectations in the course.\n\n\nB-\n2.667\n\n\n\nC+\n2.333\n\n\n\nC\n2.000\nRepresents achievement that meets the minimum expectations in the course.\n\n\nC-\n1.667\n\n\n\nD+\n1.333\n\n\n\nD\n1.000\nRepresents achievement that partially meets the minimum expectations in the course. Credit is earned but it may not fulfill major or program requirements.\n\n\nF\n0.000\nRepresents failure in the course and no credit is earned.\n\n\n\nS‚ÄìN grading scale. The S‚ÄìN grading scale allows for the following grades and corresponding GPA points:\n\n\n\nGrade\nGPA Points\nDefinitions for undergraduate credit\n\n\n\n\nS\n0.000\nSatisfactory (equivalent to a C- or better).\n\n\nN\n0.667\nNot Satisfactory\n\n\n\nFor additional information, please refer to: https://policy.umn.edu/education/gradingtranscripts."
  },
  {
    "objectID": "umn-policies.html#footnotes",
    "href": "umn-policies.html#footnotes",
    "title": "University of Minnesota Policies and Procedures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLanguage adapted from the American Association of University Professors ‚ÄúJoint Statement on Rights and Freedoms of Students‚Äù.‚Ü©Ô∏é"
  },
  {
    "objectID": "readings/01-welcome-to-8264.html",
    "href": "readings/01-welcome-to-8264.html",
    "title": "r paste(emo::ji('book'), 'Welcome to EPsy 8264')",
    "section": "",
    "text": "In this class, we will work together to develop a learning community that is inclusive and respectful, and where every student is supported in the learning process. As a class full of diverse individuals (reflected by differences in race, culture, age, religion, gender identity, sexual orientation, socioeconomic background, abilities, professional goals, and other social identities and life experiences) I expect that different students may need different things to support and promote their learning.\nThe TAs and I will do everything we can to help with this, but, as we only know what we know, we need you to communicate with us if things are not working for you or you need something we are not providing. I hope you all feel comfortable in helping to promote an inclusive classroom through respecting one another‚Äôs individual differences, speaking up, and challenging oppressive/problematic ideas. Finally, I look forward to learning from each of you and the experiences you bring to the class."
  },
  {
    "objectID": "readings/01-welcome-to-8264.html#prerequisites",
    "href": "readings/01-welcome-to-8264.html#prerequisites",
    "title": "r paste(emo::ji('book'), 'Welcome to EPsy 8264')",
    "section": "Prerequisites",
    "text": "Prerequisites\nThe pre-requisites for this course are EPsy 8251 and EPsy 8252. Prerequisite knowledge include topics from a basic statistics course:\n\nFoundational topics in data analysis;\n\nDesign (e.g., random assignment and random sampling)\nDescriptive statistics and plots\nOne- and two-sample tests\n\n\nAnd, topics from EPsy 8251: Methods in Data Analysis for Educational Research I:\n\nStatistical Computation\n\nUsing R\nData wrangling/manipulation\nPlotting\n\nCorrelation;\nSimple regression analysis;\n\nModel-level and coefficient-level interpretation\nOrdinary least squares estimation\nStandardized regression\nPartitioning sums of squares\nModel-level and coefficient-level inference\nAssumption checking/residual analysis\n\nMultiple linear regression\n\nModel-level and coefficient-level interpretation and inference\nAssumption checking/residual analysis\nWorking with categorical predictors (including adjusting p-values for multiple tests)\nInteraction effects\n\n\nAnd topics from EPsy 8252: Methods in Data Analysis for Educational Research II:\n\nDealing with nonlinearity;\n\nQuadratic effects\nLog-transformations\n\nProbability distributions;\n\nProbability density\n\nMaximum likelihood estimation;\nModel selection;\n\nInformation criteria\n\nLinear mixed-effects models (cross-sectional/longitudinal)\n\nBasic ideas of mixed-effects models\nFitting models with random-intercepts and random-slopes\nAssumptions\nLikelihood ratio tests\n\nGeneralized linear models\n\nLogistic models"
  },
  {
    "objectID": "readings/01-welcome-to-8264.html#resources",
    "href": "readings/01-welcome-to-8264.html#resources",
    "title": "r paste(emo::ji('book'), 'Welcome to EPsy 8264')",
    "section": "Resources",
    "text": "Resources\nFor the topics listed, students would be expected to be able to carry out an appropriate data analysis and properly interpret the results. It is also assumed that everyone enrolled in the course has some familiarity with using R. If you need a refresher on any of these topics, see:\n\nComputational Toolkit for Educational Scientists\nStatistical Modeling and Computation for Educational Scientists [EPsy 8251 material]\nEPsy 8252 website"
  },
  {
    "objectID": "readings/02-introduction-to-matrix-algebra.html",
    "href": "readings/02-introduction-to-matrix-algebra.html",
    "title": "r paste(emo::ji('book'), 'Introduction to Matrix Algebra')",
    "section": "",
    "text": "Read the following (short) chapters in Matrix Algebra for Educational Scientists:\n\nIntroduction\nData Structures\nVectors\nVector Operations\n\nIn class, we will be working through some problems to cement these ideas. We will also examine and work through some problems related to matrix operations, so you could also read through:\n\nMatrices\nMatrix Addition and Subtraction\nMatrix Multiplication\nMatrix Transposition"
  },
  {
    "objectID": "readings/03-ols.html",
    "href": "readings/03-ols.html",
    "title": "r paste(emo::ji('book'), 'OLS Regression using Matrices and its Properties')",
    "section": "",
    "text": "Read the following (short) chapters in Matrix Algebra for Educational Scientists:\n\nSystems of Equations\nStatistical Application: Estimating Regression Coefficients\n\nIn class, we will be working through the ideas in the following chapters:\n\nImportant Matrices in Regression\nSums of Squares in Regression\nStandard Errors and Variance Estimates\nAssumptions of the Regression Model"
  },
  {
    "objectID": "readings/04-simulating-from-the-regression-model.html",
    "href": "readings/04-simulating-from-the-regression-model.html",
    "title": "r paste(emo::ji('book'), 'Simulating from the Regression Model')",
    "section": "",
    "text": "Read the following chapters from Carsey, T. M., & Harden, J. J. (2014). Monte Carlo simulation and resampling methods for social science. Sage. It should be accessible via the link after logging in with your x500 and password.\n\nIntroduction: This chapter gives a short introduction to the use of simulation in the social sciences."
  },
  {
    "objectID": "readings/05-regression-diagnostics.html",
    "href": "readings/05-regression-diagnostics.html",
    "title": "r paste(emo::ji('book'), 'Regression Diagnostics')",
    "section": "",
    "text": "Read the following chapter. It should be accessible via the link after logging in with your x500 and password.\n\nFox, J. (1991). Outlying and influential data. In Regression diagnostics (pp.¬†21‚Äì40). Sage. doi: https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781412985604.n4\n\n\n\nAdditional Resources\n\nKim, B. (2015). Understanding diagnostic plots for linear regression analysis. University of Virginia Library.\nCook, R. D. (1998). Regression graphics: Ideas for studying regressions through graphics. Wiley."
  },
  {
    "objectID": "readings/06-variance-stabilizing-transformations.html",
    "href": "readings/06-variance-stabilizing-transformations.html",
    "title": "r paste(emo::ji('book'), 'Variance Stabilizing Transformations')",
    "section": "",
    "text": "Read the following article.\n\nOsborne, J. W. (2009). Notes on the use of data transformations. Practical Assessment, Research & Evaluation, 8(6). https://doi.org/10.7275/4vng-5608\n\n\n\nAdditional Resources\n\nKaufman, R. L. (2013). Heteroskedasticity in regression: Detection and correction. Sage. https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781452270128.n4"
  },
  {
    "objectID": "readings/07-wls-and-sandwich-estimation.html",
    "href": "readings/07-wls-and-sandwich-estimation.html",
    "title": "r paste(emo::ji('book'), 'Weighted Least Squares (WLS) and Sandwich Estimation')",
    "section": "",
    "text": "Read the following chapter. It should be accessible via the link after logging in with your x500 and password.\n\nRead Kaufman, R. L. (2013). Heteroskedasticity-consistent (robust) standard errors. In Heteroskedasticity in regression: Detection and correction (pp.¬†43‚Äì50). Sage. https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781452270128.n4\n\n\n\nAdditional Resources\n\nShin, H.-C. (1998). Weighted least squares estimation with sampling weights. Journal of Econometrics, 8(2), 251‚Äì271.\nSolon, G., Haider, S. J., & Woolridge, J. (2013). What are we weighting for? (Working Paper No.¬†18859; NBER Working Paper Series). National Bureau of Economic Research."
  },
  {
    "objectID": "readings/08-diagnosing-collinearity.html",
    "href": "readings/08-diagnosing-collinearity.html",
    "title": "r paste(emo::ji('book'), 'Diagnosing Collinearity')",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Eigenvalues and Eigenvectors. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nCook, D. (2019). How to use a tour to check if your model suffers from multicollinearity. Personal blog."
  },
  {
    "objectID": "readings/09-pca-via-spectral-decomposition.html",
    "href": "readings/09-pca-via-spectral-decomposition.html",
    "title": "r paste(emo::ji('book'), 'Principal Components Analysis via Spectral Decomposition')",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Basis vectors and matrices. In Matrix algebra for educational scientists.\n\nRodriguez, M., & Zieffler, A. (2021). Eigenvalues and eigenvectors. In Matrix algebra for educational scientists.\n\nRodriguez, M., & Zieffler, A. (2021). Spectral decomposition. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nWilke, C. O. (2020). PCA tidyverse style. Personal blog."
  },
  {
    "objectID": "readings/10-pca-via-svd.html",
    "href": "readings/10-pca-via-svd.html",
    "title": "r paste(emo::ji('book'), 'Principal Components Analysis via Singular Value Decomposition')",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Singular value decomposition. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nGundersen, G. (2018). Singular value decomposition as simply as possible.\nWang, Z. (2019). PCA and SVD explained with numpy.\nWikipdeia. (2020). Singular value decomposition."
  },
  {
    "objectID": "readings/11-biased-estimation-ridge-regression.html",
    "href": "readings/11-biased-estimation-ridge-regression.html",
    "title": "r paste(emo::ji('book'), 'Biased Estimation: Ridge Regression')",
    "section": "",
    "text": "Read the following:\n\nFortmann-Roe, S. (2012). Understanding the bias-variance tradeoff.\n\n\n\nAdditional Resources\n\nCross-Validated. (2014). Why is ridge regression called ‚Äúridge‚Äù, why is it needed, and what happens when \\(\\lambda\\) goes to infinity?.\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning: with applications in R. New York: Springer.\nStatistical Learning MOOC taught by Hastie and Tibshirani"
  },
  {
    "objectID": "readings/12-model-selection.html",
    "href": "readings/12-model-selection.html",
    "title": "r paste(emo::ji('book'), 'Model Selection')",
    "section": "",
    "text": "Read the following:\n\nHeinze, G., Wallisch, C., & Dunkler, D. (2018). Variable selection ‚Äî A review and recommendations for the practicing statistician. Biometrical Journal. Biometrische Zeitschrift, 60(3), 431‚Äì449. https://doi.org/10.1002/bimj.201700067\n\n\n\nAdditional Resources\n\nolsrr Vignette\nWilliams, B., Hansen, G., Baraban, A., & Santoni, A. (2015). A practical approach to variable selection‚ÄîA comparison of various techniques. Casualty Actuarial Society E-Forum, Summer, 1‚Äì20."
  },
  {
    "objectID": "readings/13-cross-validation.html",
    "href": "readings/13-cross-validation.html",
    "title": "r paste(emo::ji('book'), 'Cross-Validation')",
    "section": "",
    "text": "Read the following:\n\nFeick, L. (2019). Evaluating model performance by building cross-validation from scratch. STATWORX Blog.\n\n\n\nAdditional Resources\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). Cross-validation. In An introduction to statistical learning: with applications in R (pp.¬†176‚Äì186). New York: Springer."
  },
  {
    "objectID": "readings/14-regression-from-summary-measures.html",
    "href": "readings/14-regression-from-summary-measures.html",
    "title": "r paste(emo::ji('book'), 'Regression from Summary Measures')",
    "section": "",
    "text": "Read the following chapter:\n\nRodriguez, M., & Zieffler, A. (2021). Statistical application: SSCP, variance‚Äìcovariance, and correlation matrices.. Matrix Algebra for Educational Scientists.\n\nIn particular pay attention to the relationships between these three matrices."
  },
  {
    "objectID": "worksheets/02-introduction-to-matrix-algebra.html",
    "href": "worksheets/02-introduction-to-matrix-algebra.html",
    "title": "r paste(emo::ji('muscle'), 'Introduction to Matrix Algebra')",
    "section": "",
    "text": "Directions\nComplete the problems on this worksheet with your small group. You may want to refer to the Matrix Algebra for Educational Scientists text.\nYou will likely be learning (or re-encountering) many new mathematical terms. It is a good idea to note and define all the vocabulary/terms that you encounter as you work through this worksheet. You may want to do this individually or create a shared document that you can all contribute to.\n\n\n\nProblems\nConsider the following matrices:\n\\[\n\\mathbf{A} = \\begin{bmatrix}3 & -2\\\\5 & 1\\end{bmatrix} \\quad \\mathbf{B} = \\begin{bmatrix}3 & -1\\\\-1 & 2\\end{bmatrix}\\quad \\mathbf{C} = \\begin{bmatrix}1 & 2 & 3\\\\0 & 1 & 2\\end{bmatrix}\n\\]\nMake sure everyone in your group can solve each of these problem by hand and using R.\n\nWhat are the dimensions of A? C?\nIs C a square matrix? Explain.\nFind the trace of A.\nFind the determinant of A.\nAdd A and B\nFind the transpose of C.\nBy referring to the dimensions, can you compute AC? How about CA?\nCompute AC.\nCompute BI\nCreate a \\(3\\times3\\) diagonal matrix whose trace is 10.\nHow do you know that B has an inverse? Explain.\nCompute \\(\\mathbf{B}^{-1}\\)\nCreate a \\(3\\times3\\) matrix that has rank 2. Verify this using R.\nCreate a \\(3\\times3\\) matrix that is symmetric and is not I.\nSolve the system of linear equations using algebra (e.g., substitution, elimination) and then solve them using matrix methods (with R). To do this you will need to read the Systems of Equations chapter in Matrix Algebra for Educational Scientists.\n\n\\[\n\\begin{split}\nx + y + z &= 2 \\\\\n6x - 4y + 5z &= 31 \\\\\n5x + 2y + 2z &= 13\n\\end{split}\n\\]"
  },
  {
    "objectID": "worksheets/13-model-selection.html",
    "href": "worksheets/13-model-selection.html",
    "title": "üí™ Model Selection (In-Class Activity)",
    "section": "",
    "text": "The data in states-2019.csv include statistics collected from Wikipedia, the 2019 American Community Survey, and the National Centers for Environmental Information.\n\n[CSV]\n[Data Codebook]\n\n\nYour goal is to use the data (and everything you‚Äôve learned so far in your coursework) to create a model to predict variation in life expectancy. Keep track of the process you use to create this model, including:\n\nWhich predictors should be included in the model?\n\nWhat is the criteria/evidence you are using to make these decisions?\n\nWhen in the process do you identify problematic observations?\n\nDo you remove those problematic observations or not?\nWhat criteria/evidence are you using to make these decisions?\n\nWhen in the process do you examine the model for collinearity?\n\nWhat is the criteria/evidence you are using to make this decision?\nWhat (if anything) will you do to fix this?\n\nWhen in the process do you examine the tenability of assumptions?\n\nAlso pay attention to when in the process you are making decisions based on sample evidence (graphs/statistics) versus when those decisions are being made using statistical inference (hypothesis tests, confidence intervals). Your group will be asked to report back to the class on the process, criteria, and evidence you used."
  },
  {
    "objectID": "codebooks/contraception.html",
    "href": "codebooks/contraception.html",
    "title": "contraception.csv",
    "section": "",
    "text": "The data in contraception.csv were collected from several sources (e.g., World Bank). The variables are:\n\ncountry: Country name\nregion: Region of the world\ncontraceptive: Percentage of women who are practicing, or whose sexual partners are practicing, any form of contraception. It is usually measured for women ages 15‚Äì49 who are married or in union.\neduc_female: Average number of years of formal education (schooling) for females\ngni: Categorical measure of the economy indicating if the country has a low or high gross national income\n\n\n\nPreview\n\n\nCode\n# Import data\ncontraception = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/contraception.csv\")\n\n# View data\ncontraception\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nReferences\n\n\nRoser, M. (2017). Fertility rate. Our world in data.\n\n\nUNICEF. (2016). State of the world‚Äôs children 2016. United Nations Population Division‚Äôs World Contraceptive Use, household surveys including Demographic and Health Surveys and Multiple Indicator Cluster Surveys.\n\n\nWorld Bank (2019). World Bank open data."
  },
  {
    "objectID": "codebooks/credit.html",
    "href": "codebooks/credit.html",
    "title": "credit.csv",
    "section": "",
    "text": "The data in credit.csv contains simulated credit card data for 400 individuals. These data are from James, Witten, Hastie, & Tibshirani (2013). The variables in the data set are:\n\nbalance: Customer‚Äôs average credit card balance (in dollars)\nincome: Customer‚Äôs reported income (in $10,000 dollars)\nlimit: Credit limit issued to customer\nrating: Customer‚Äôs credit rating; higher values indicate a better credit rating\ncards: Number of credit cards the customer has\nage: Customer‚Äôs age\neducation: Number of years of education\n\n\n\nPreview\n\n\nCode\n# Import data\ncredit = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/credit.csv\")\n\n# View data\ncredit\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning: With applications in R. New York: Springer."
  },
  {
    "objectID": "codebooks/equal-education-opportunity.html",
    "href": "codebooks/equal-education-opportunity.html",
    "title": "equal-education-opportunity.csv",
    "section": "",
    "text": "In 1964, the US Congress passed the Civil Rights Act and also ordered a survey of school districts to evaluate the availability of equal educational opportunity in public education. The results of this survey were reported on in Coleman et al. (1966) and Mosteller & Moynihan (1972). The data in equal-education-opportunity.csv are a subset of the data collected. These data, provided by Chatterjee & Hadi (2012), constitute a random sample of 70 schools from the original data. The attributes, which have all been mean-centered and standardized, include:\n\nachievement: Measurement indicating the student achievement level\nfaculty: Measurement indicating the faculty‚Äôs credentials\npeer: Measurement indicating the influence of peer groups in the school\nschool: Measurement indicating the school facilities (e.g., building, teaching materials)\n\n\n\nPreview\n\n\nCode\n# Import data\neeo = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\n\n# View data\neeo\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nChatterjee, S., & Hadi, A. S. (2012). Regression analysis by example. New York: Wiley.\n\n\nColeman, J. S., Cambell, E. Q., Hobson, C. J., McPartland, J., Mood, A. M., Weinfield, F. D., & York, R. L. (1966). Equality of educational opportunity. Washington, DC: U.S. Government Printing Office.\n\n\nMosteller, F., & Moynihan, D. F. (1972). On equality of educational opportunity. New York: Random House."
  },
  {
    "objectID": "codebooks/evaluations.html",
    "href": "codebooks/evaluations.html",
    "title": "evaluations.csv",
    "section": "",
    "text": "The data in evaluations.csv come from Hamermesh & Parker (2005) and were made available by Gelman & Hill (2007). This data were collected from student evaluations of instructors‚Äô beauty and teaching quality for several courses at the University of Texas. The teaching evaluations were conducted at the end of the semester, and the beauty judgments were made later, by six students who had not attended the classes and were not aware of the course evaluations. The variables are:\n\nprof_id: Professor ID number\navg_eval: Average course rating\nnum_courses: Number of courses for which the professor has evaluations\nnum_students: Number of students enrolled in the professor‚Äôs courses\nperc_evaluating: Average percentage of enrolled students who completed an evaluation\nbeauty: Measure of the professor‚Äôs beauty composed of the average score on six standardized beauty ratings\ntenured: Is the professor tenured? (0 = non-tenured; 1 = tenured)\nnative_english: Is the professor a native English speaker? (0 = non-native English speaker; 1 = native English speaker)\nage: Professor‚Äôs age (in years)\nfemale: Is the professor female? (0 = not female; 1 = female)\n\n\n\nPreview\n\n\nCode\n# Import data\nevaluations = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/evaluations.csv\")\n\n# View data\nevaluations\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. New York: Cambridge University Press.\n\n\nHamermesh, D. S., & Parker, A. M. (2005). Beauty in the classroom: Instructors‚Äô pulchritude and putative pedagogical productivity. Economics of Education Review, 24, 369‚Äì376."
  },
  {
    "objectID": "codebooks/iowa-judges.html",
    "href": "codebooks/iowa-judges.html",
    "title": "iowa-judges.csv",
    "section": "",
    "text": "The Iowa State Bar Association has conducted the Judicial Performance Review as a way of giving voters information on the Iowa judges up for retention in an election year. Judges are evaluated on their professional competence and demeanor as determined by the attorneys who frequently appeared before them. The attorneys also indicate whether or not they believe the judge should be retained. The data in iowa-judges.csv were published by the The Iowa State Bar Association (2018). The variables are:\n\nyear: Year of the judicial performance review\njudge: Name of the judge\ndistrict: Judicial district\nrespondents: Number of attorneys who rated the judge\nretention: Percentage of attorneys who indicated the judge should be retained\n\nThe following characteristics were rated on the scale: 5 (Excellent; performance is outstanding), 4 (Good; performance is above average), 3 (Satisfactory; performance is adequate), 2 (Deficient; performance is below average), 1 (Very Poor; performance is well below average and unacceptable).\n\nknowledge: Knowledge and application of the law\nperception: Perception of factual issues\npunctuality: Punctuality for court proceedings\nattention: Attentiveness to evidence and arguments\nmanagement: Management and control of the courtroom\ndemeanor: Temperament and demeanor\nclarity: Clarity and quality of written opinions\npromptness: Promptness of rulings and decisions\n\nThe following characteristics were rated on the scale: 5 (Strongly Agree), 4 (Agree), 3 (Neither), 2 (Disagree), 1 (Strongly Disagree)\n\ncriticism: Avoids undue personal observations or criticisms of litigants, judges and lawyers from bench or in written opinions\ndecision: Decides cases on basis of applicable law and fact, not affected by outside influence.\ncourteous: Is courteous and patient with litigants, lawyers and court personnel.\nequality: Treats people equally regardless of race, gender, age, national origin, religion, sexual orientation, socio-economic status or disability.\n\n\n\nPreview\n\n\nCode\n# Import data\njudges = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/iowa-judges.csv\")\n\n# View data\njudges\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nThe Iowa State Bar Association. (2018). 2018 judicial performance review. The Iowa State Bar Association. Retrieved from https://cdn.ymaws.com/www.iowabar.org/resource/resmgr/judicial_performance_review/2018/2018_Judicial_Performance_Re.pdf"
  },
  {
    "objectID": "codebooks/keith2.html",
    "href": "codebooks/keith2.html",
    "title": "keith2.csv",
    "section": "",
    "text": "The data, stored in keith2.csv includes three attributes on \\(n = 32\\) 8th-grade students. These data come from Keith (2015). The attributes are:\n\ngpa: Overall Grade-point average (GPA) in all subjects (on a standard 100-point scale)\nhomework: Average time spent on homework per week across all subjects (in hours)\nparent_ed: Education-level (in years of schooling) for the parent with the highest level of education\n\n\n\nPreview\n\n\nCode\n# Import data\nkeith2 = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/keith2.csv\")\n\n# View data\nkeith2\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nKeith, T. V. (2015). Multiple regression and beyond: An introduction to multiple regression and structural equation modeling (2nd ed.). New York: Routledge."
  },
  {
    "objectID": "codebooks/mpls-violent-crime.html",
    "href": "codebooks/mpls-violent-crime.html",
    "title": "mpls-violent-crimes.csv",
    "section": "",
    "text": "The mpls-violent-crime.csv file contains data collected from the Minneapolis Police Department and reported by the Star Tribune on The two attributes in this file are:\n\nyear: Year\ncrime_rate: Violent crime rate per 100,000 people\n\n\n\nPreview\n\n\nCode\n# Import data\ncrime = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/mpls-violent-crime.csv\")\n\n# View data\ncrime"
  },
  {
    "objectID": "codebooks/path-model-achievement.html",
    "href": "codebooks/path-model-achievement.html",
    "title": "path-model-achievement.csv",
    "section": "",
    "text": "The data, stored in path-model-achievement.csv includes five standardized attributes collected from \\(n = 1000\\) students. These data come from Keith (2015). The attributes are:\n\nachieve: Standardized measure of achievement\nability: Standardized measure of student ability level\nmotivation: Standardized measure of motivation\ncoursework: Standardized measure of previous coursework\nfam_back: Standardized measure of family background\n\n\n\nPreview\n\n\nCode\n# Import data\npath_model = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/path-model-achievement.csv\")\n\n# View data\npath_model\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nKeith, T. V. (2015). Multiple regression and beyond: An introduction to multiple regression and structural equation modeling (2nd ed.). New York: Routledge."
  },
  {
    "objectID": "codebooks/slid.html",
    "href": "codebooks/slid.html",
    "title": "slid.csv",
    "section": "",
    "text": "The data in slid.csv includes a subset of data collected during the 1994 wave of Statistics Canada‚Äôs Survey of Labour and Income Dynamics (SLID). These data constitute employed citizens living in Ontario, Canada between the ages of 16 and 65. These data are taken from the public-use dataset that was made available by Statistics Canada, and prepared by the Institute for Social Research, York University. They were made available in Fox, Weisberg, & Price (2022). The variables in the data set are:\n\nwages: Composite hourly wage rate based on all the participant‚Äôs jobs\nage: Age of the participant (in years)\neducation: Number of years of schooling\nmale: A dummy-coded predictor for sex (0=Non-male; 1=Male)\n\n\n\nPreview\n\n\nCode\n# Import data\nslid = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/slid.csv\")\n\n# View data\nslid\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nFox, J., Weisberg, S., & Price, B. (2022). CarData: Companion to applied regression data sets. R package version 3.0-5. Retrieved from https://CRAN.R-project.org/package=carData"
  },
  {
    "objectID": "codebooks/stack-1979.html",
    "href": "codebooks/stack-1979.html",
    "title": "stack-1979.csv",
    "section": "",
    "text": "Stack (1979) studied predictors of income inequality in a paper published in the American Sociological Review. He posited that more political participation and a strong Socialist party in a country would be associated with less income inequality. To control for variation in economic development, he included a measure of energy consumption, which had been identified as a reasonable economic proxy in previous studies. Stack‚Äôs data, stored in stack-1979.csv, include four attributes measured on 18 countries. The attributes are:\n\ncountry: Country name\ninequality: Ratio of the share of income received by the most wealthy population quintile (richest 20%) to the share received by the poorest 40% of the population; Higher values indicate more income inequality\nturnout: Proportion of the adult population voting in the most recent national election prior to 1972\nenergy: Energy consumption per capita (expressed in million metric tons of coal equivalents; higher values indicate more economic development\nsocialist: Annual average proportion of seats held by socialist parties in the national legislature, over the first twenty postwar years\n\n\n\nData Preview\n\n\nCode\n# Import data\nstack = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/stack-1979.csv\")\n\n# View data\nstack\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nStack, S. (1979). The effects of political participation and socialist party strength on the degree of income inequality. American Sociological Review, 44(1), 168‚Äì171."
  },
  {
    "objectID": "codebooks/states-2019.html",
    "href": "codebooks/states-2019.html",
    "title": "states-2019.csv",
    "section": "",
    "text": "The data in states-2019.csv include statistics collected from Wikipedia, the 2019 American Community Survey, and the National Centers for Environmental Information. The attributes in the data are:\n\nstate: State/territory name\nlife_expectancy: Life expectancy (in years)\npopulation: Population estimate (in millions)\nincome: Per capita income (in thousands of dollars)\nilliteracy: Illiteracy rate (in percent)\nmurder: Murder and non-negligent manslaughter rate (per 100,000 population)\nhs_grad: Percentage of high school graduates\nfrost: Mean number of days with minimum temperature below freezing\narea: Land area (in square miles)\n\n\n\nPreview\n\n\nCode\n# Import data\nusa = readr::read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/states-2019.csv\")\n\n# View data\nusa\n\n\n\n\n  \n\n\n\n\n\n\nReferences"
  },
  {
    "objectID": "readings/00-welcome-to-8264.html",
    "href": "readings/00-welcome-to-8264.html",
    "title": "üìñ Welcome to EPsy 8264",
    "section": "",
    "text": "The pre-requisites for this course are EPsy 8251 and EPsy 8252. Prerequisite knowledge include topics from a basic statistics course:\n\nFoundational topics in data analysis;\n\nDesign (e.g., random assignment and random sampling)\nDescriptive statistics and plots\nOne- and two-sample tests\n\n\nAnd, topics from EPsy 8251: Methods in Data Analysis for Educational Research I:\n\nStatistical Computation\n\nUsing R\nData wrangling/manipulation\nPlotting\n\nCorrelation;\nSimple regression analysis;\n\nModel-level and coefficient-level interpretation\nOrdinary least squares estimation\nStandardized regression\nPartitioning sums of squares\nModel-level and coefficient-level inference\nAssumption checking/residual analysis\n\nMultiple linear regression\n\nModel-level and coefficient-level interpretation and inference\nAssumption checking/residual analysis\nWorking with categorical predictors (including adjusting p-values for multiple tests)\nInteraction effects\n\n\nAnd topics from EPsy 8252: Methods in Data Analysis for Educational Research II:\n\nDealing with nonlinearity;\n\nQuadratic effects\nLog-transformations\n\nProbability distributions;\n\nProbability density\n\nMaximum likelihood estimation;\nModel selection;\n\nInformation criteria\n\nLinear mixed-effects models (cross-sectional/longitudinal)\n\nBasic ideas of mixed-effects models\nFitting models with random-intercepts and random-slopes\nAssumptions\nLikelihood ratio tests\n\nGeneralized linear models\n\nLogistic models"
  },
  {
    "objectID": "readings/00-welcome-to-8264.html#prerequisites",
    "href": "readings/00-welcome-to-8264.html#prerequisites",
    "title": "üìñ Welcome to EPsy 8264",
    "section": "",
    "text": "The pre-requisites for this course are EPsy 8251 and EPsy 8252. Prerequisite knowledge include topics from a basic statistics course:\n\nFoundational topics in data analysis;\n\nDesign (e.g., random assignment and random sampling)\nDescriptive statistics and plots\nOne- and two-sample tests\n\n\nAnd, topics from EPsy 8251: Methods in Data Analysis for Educational Research I:\n\nStatistical Computation\n\nUsing R\nData wrangling/manipulation\nPlotting\n\nCorrelation;\nSimple regression analysis;\n\nModel-level and coefficient-level interpretation\nOrdinary least squares estimation\nStandardized regression\nPartitioning sums of squares\nModel-level and coefficient-level inference\nAssumption checking/residual analysis\n\nMultiple linear regression\n\nModel-level and coefficient-level interpretation and inference\nAssumption checking/residual analysis\nWorking with categorical predictors (including adjusting p-values for multiple tests)\nInteraction effects\n\n\nAnd topics from EPsy 8252: Methods in Data Analysis for Educational Research II:\n\nDealing with nonlinearity;\n\nQuadratic effects\nLog-transformations\n\nProbability distributions;\n\nProbability density\n\nMaximum likelihood estimation;\nModel selection;\n\nInformation criteria\n\nLinear mixed-effects models (cross-sectional/longitudinal)\n\nBasic ideas of mixed-effects models\nFitting models with random-intercepts and random-slopes\nAssumptions\nLikelihood ratio tests\n\nGeneralized linear models\n\nLogistic models"
  },
  {
    "objectID": "readings/00-welcome-to-8264.html#resources",
    "href": "readings/00-welcome-to-8264.html#resources",
    "title": "üìñ Welcome to EPsy 8264",
    "section": "Resources",
    "text": "Resources\nFor the topics listed, students would be expected to be able to carry out an appropriate data analysis and properly interpret the results. It is also assumed that everyone enrolled in the course has some familiarity with using R. If you need a refresher on any of these topics, see:\n\nStatistical Modeling and Computation for Educational Scientists [EPsy 8251 material]\nEPsy 8252 website"
  },
  {
    "objectID": "readings/01-01-introduction-to-matrix-algebra.html",
    "href": "readings/01-01-introduction-to-matrix-algebra.html",
    "title": "üìñ Introduction to Matrix Algebra",
    "section": "",
    "text": "Read the following (short) chapters in Matrix Algebra for Educational Scientists:\n\nIntroduction\nData Structures\nVectors\nVector Operations\n\nIn class, we will be working through some problems to cement these ideas. We will also examine and work through some problems related to matrix operations, so you could also read through:\n\nMatrices\nMatrix Addition and Subtraction\nMatrix Multiplication\nMatrix Transposition"
  },
  {
    "objectID": "readings/01-02-ols.html",
    "href": "readings/01-02-ols.html",
    "title": "üìñ OLS Regression using Matrices and its Properties",
    "section": "",
    "text": "Read the following (short) chapters in Matrix Algebra for Educational Scientists:\n\nSystems of Equations\nStatistical Application: Estimating Regression Coefficients\n\nIn class, we will be working through the ideas in the following chapters:\n\nImportant Matrices in Regression\nSums of Squares in Regression\nStandard Errors and Variance Estimates\nAssumptions of the Regression Model"
  },
  {
    "objectID": "readings/02-01-simulating-from-the-regression-model.html",
    "href": "readings/02-01-simulating-from-the-regression-model.html",
    "title": "üìñ Simulating from the Regression Model",
    "section": "",
    "text": "Read the following chapters from Carsey, T. M., & Harden, J. J. (2014). Monte Carlo simulation and resampling methods for social science. Sage. It should be accessible via the link after logging in with your x500 and password.\n\nIntroduction: This chapter gives a short introduction to the use of simulation in the social sciences."
  },
  {
    "objectID": "readings/03-01-regression-from-summary-measures.html",
    "href": "readings/03-01-regression-from-summary-measures.html",
    "title": "üìñ Regression from Summary Measures",
    "section": "",
    "text": "Read the following chapter:\n\nRodriguez, M., & Zieffler, A. (2021). Statistical application: SSCP, variance‚Äìcovariance, and correlation matrices.. Matrix Algebra for Educational Scientists.\n\nIn particular pay attention to the relationships between these three matrices."
  },
  {
    "objectID": "readings/04-01-regression-diagnostics.html",
    "href": "readings/04-01-regression-diagnostics.html",
    "title": "üìñ Regression Diagnostics",
    "section": "",
    "text": "Read the following chapter. It should be accessible via the link after logging in with your x500 and password.\n\nFox, J. (1991). Outlying and influential data. In Regression diagnostics (pp.¬†21‚Äì40). Sage. doi: https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781412985604.n4\n\n\n\nAdditional Resources\n\nKim, B. (2015). Understanding diagnostic plots for linear regression analysis. University of Virginia Library.\nCook, R. D. (1998). Regression graphics: Ideas for studying regressions through graphics. Wiley."
  },
  {
    "objectID": "readings/05-01-variance-stabilizing-transformations.html",
    "href": "readings/05-01-variance-stabilizing-transformations.html",
    "title": "üìñ Variance Stabilizing Transformations",
    "section": "",
    "text": "Read the following article.\n\nOsborne, J. W. (2009). Notes on the use of data transformations. Practical Assessment, Research & Evaluation, 8(6). https://doi.org/10.7275/4vng-5608\n\n\n\nAdditional Resources\n\nKaufman, R. L. (2013). Heteroskedasticity in regression: Detection and correction. Sage. https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781452270128.n4"
  },
  {
    "objectID": "readings/05-02-wls-and-sandwich-estimation.html",
    "href": "readings/05-02-wls-and-sandwich-estimation.html",
    "title": "üìñ Weighted Least Squares (WLS) and Sandwich Estimation",
    "section": "",
    "text": "Read the following chapter. It should be accessible via the link after logging in with your x500 and password.\n\nRead Kaufman, R. L. (2013). Heteroskedasticity-consistent (robust) standard errors. In Heteroskedasticity in regression: Detection and correction (pp.¬†43‚Äì50). Sage. https://dx-doi-org.ezp1.lib.umn.edu/10.4135/9781452270128.n4\n\n\n\nAdditional Resources\n\nShin, H.-C. (1998). Weighted least squares estimation with sampling weights. Journal of Econometrics, 8(2), 251‚Äì271.\nSolon, G., Haider, S. J., & Woolridge, J. (2013). What are we weighting for? (Working Paper No.¬†18859; NBER Working Paper Series). National Bureau of Economic Research."
  },
  {
    "objectID": "readings/06-01-diagnosing-collinearity.html",
    "href": "readings/06-01-diagnosing-collinearity.html",
    "title": "üìñ Diagnosing Collinearity",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Eigenvalues and Eigenvectors. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nCook, D. (2019). How to use a tour to check if your model suffers from multicollinearity. Personal blog."
  },
  {
    "objectID": "readings/06-02-pca-via-spectral-decomposition.html",
    "href": "readings/06-02-pca-via-spectral-decomposition.html",
    "title": "üìñ Principal Components Analysis via Spectral Decomposition",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Basis vectors and matrices. In Matrix algebra for educational scientists.\n\nRodriguez, M., & Zieffler, A. (2021). Eigenvalues and eigenvectors. In Matrix algebra for educational scientists.\n\nRodriguez, M., & Zieffler, A. (2021). Spectral decomposition. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nWilke, C. O. (2020). PCA tidyverse style. Personal blog."
  },
  {
    "objectID": "readings/06-03-pca-via-svd.html",
    "href": "readings/06-03-pca-via-svd.html",
    "title": "üìñ Principal Components Analysis via Singular Value Decomposition",
    "section": "",
    "text": "Read the following:\n\nRodriguez, M., & Zieffler, A. (2021). Singular value decomposition. In Matrix algebra for educational scientists.\n\n\n\nAdditional Resources\n\nGundersen, G. (2018). Singular value decomposition as simply as possible.\nWang, Z. (2019). PCA and SVD explained with numpy.\nWikipdeia. (2020). Singular value decomposition."
  },
  {
    "objectID": "readings/06-04-biased-estimation-ridge-regression.html",
    "href": "readings/06-04-biased-estimation-ridge-regression.html",
    "title": "üìñ Biased Estimation: Ridge Regression",
    "section": "",
    "text": "Read the following:\n\nFortmann-Roe, S. (2012). Understanding the bias-variance tradeoff.\n\n\n\nAdditional Resources\n\nCross-Validated. (2014). Why is ridge regression called ‚Äúridge‚Äù, why is it needed, and what happens when \\(\\lambda\\) goes to infinity?.\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning: with applications in R. New York: Springer.\nStatistical Learning MOOC taught by Hastie and Tibshirani"
  },
  {
    "objectID": "readings/07-02-model-selection.html",
    "href": "readings/07-02-model-selection.html",
    "title": "üìñ Model Selection",
    "section": "",
    "text": "Read the following:\n\nHeinze, G., Wallisch, C., & Dunkler, D. (2018). Variable selection ‚Äî A review and recommendations for the practicing statistician. Biometrical Journal. Biometrische Zeitschrift, 60(3), 431‚Äì449. https://doi.org/10.1002/bimj.201700067\n\n\n\nAdditional Resources\n\nolsrr Vignette\nWilliams, B., Hansen, G., Baraban, A., & Santoni, A. (2015). A practical approach to variable selection‚ÄîA comparison of various techniques. Casualty Actuarial Society E-Forum, Summer, 1‚Äì20."
  },
  {
    "objectID": "readings/07-03-cross-validation.html",
    "href": "readings/07-03-cross-validation.html",
    "title": "üìñ Cross-Validation",
    "section": "",
    "text": "Read the following:\n\nFeick, L. (2019). Evaluating model performance by building cross-validation from scratch. STATWORX Blog.\n\n\n\nAdditional Resources\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). Cross-validation. In An introduction to statistical learning: with applications in R (pp.¬†176‚Äì186). New York: Springer."
  },
  {
    "objectID": "worksheets/01-01-introduction-to-matrix-algebra.html",
    "href": "worksheets/01-01-introduction-to-matrix-algebra.html",
    "title": "üí™ Introduction to Matrix Algebra",
    "section": "",
    "text": "Directions\nComplete the problems on this worksheet with your small group. You may want to refer to the Matrix Algebra for Educational Scientists text.\nYou will likely be learning (or re-encountering) many new mathematical terms. It is a good idea to note and define all the vocabulary/terms that you encounter as you work through this worksheet. You may want to do this individually or create a shared document that you can all contribute to.\n\n\n\nProblems\nConsider the following matrices:\n\\[\n\\mathbf{A} = \\begin{bmatrix}3 & -2\\\\5 & 1\\end{bmatrix} \\quad \\mathbf{B} = \\begin{bmatrix}3 & -1\\\\-1 & 2\\end{bmatrix}\\quad \\mathbf{C} = \\begin{bmatrix}1 & 2 & 3\\\\0 & 1 & 2\\end{bmatrix}\n\\]\nMake sure everyone in your group can solve each of these problem by hand and using R.\n\nWhat are the dimensions of A? C?\nIs C a square matrix? Explain.\nFind the trace of A.\nFind the determinant of A.\nAdd A and B\nFind the transpose of C.\nBy referring to the dimensions, can you compute AC? How about CA?\nCompute AC.\nCompute BI\nCreate a \\(3\\times3\\) diagonal matrix whose trace is 10.\nHow do you know that B has an inverse? Explain.\nCompute \\(\\mathbf{B}^{-1}\\)\nCreate a \\(3\\times3\\) matrix that has rank 2. Verify this using R.\nCreate a \\(3\\times3\\) matrix that is symmetric and is not I.\nSolve the system of linear equations using algebra (e.g., substitution, elimination) and then solve them using matrix methods (with R). To do this you will need to read the Systems of Equations chapter in Matrix Algebra for Educational Scientists.\n\n\\[\n\\begin{split}\nx + y + z &= 2 \\\\\n6x - 4y + 5z &= 31 \\\\\n5x + 2y + 2z &= 13\n\\end{split}\n\\]"
  },
  {
    "objectID": "worksheets/07-01-model-selection.html",
    "href": "worksheets/07-01-model-selection.html",
    "title": "üí™ Model Selection (In-Class Activity)",
    "section": "",
    "text": "The data in states-2019.csv include statistics collected from Wikipedia, the 2019 American Community Survey, and the National Centers for Environmental Information.\n\n[CSV]\n[Data Codebook]\n\n\nYour goal is to use the data (and everything you‚Äôve learned so far in your coursework) to create a model to predict variation in life expectancy. Keep track of the process you use to create this model, including:\n\nWhich predictors should be included in the model?\n\nWhat is the criteria/evidence you are using to make these decisions?\n\nWhen in the process do you identify problematic observations?\n\nDo you remove those problematic observations or not?\nWhat criteria/evidence are you using to make these decisions?\n\nWhen in the process do you examine the model for collinearity?\n\nWhat is the criteria/evidence you are using to make this decision?\nWhat (if anything) will you do to fix this?\n\nWhen in the process do you examine the tenability of assumptions?\n\nAlso pay attention to when in the process you are making decisions based on sample evidence (graphs/statistics) versus when those decisions are being made using statistical inference (hypothesis tests, confidence intervals). Your group will be asked to report back to the class on the process, criteria, and evidence you used."
  },
  {
    "objectID": "notes/02-01-simulating-from-the-regression-model.html",
    "href": "notes/02-01-simulating-from-the-regression-model.html",
    "title": "üé∂ Simulating from the Regression Model",
    "section": "",
    "text": "Here are links to several script files and handouts that we will use in class.\n\n\nGenerating Data\n\nGenerating Random Data from a Regression Model is a script file that provides syntax for generating data from a given population regression model.\n\n\n\n\nSimulation 1: Simulating from a Regression Model\n\nSimulating from a Regression Model is a script file that provides syntax for carrying out a simulation to produce distributions of estimates from a regression model.\nVizualization of Simulating from a Regression Model is a handout visualizing the simulation process for generating data from a given population regression model.\n\n\n\n\nSimulation 2: Simulating from a Null Regression Model\n\nSimulating from a Null Regression Model is a script file that provides syntax for carrying out a simulation to produce distributions of estimates assuming certain parameters in the regression model are zero.\nVizualization of Simulating from a Null Regression Model is a handout visualizing the simulation process for generating data to produce distributions of estimates assuming certain parameters in the regression model are zero.\n\n\n\n\nResources\nHere are several resources to help your understanding of simulation. The chapters from Monte Carlo Simulation and Resampling Methods for Social Science should be accessible via the links after logging in with your x500 and password.\n\nProbability: Common probability distributions and how to compute with them.\nRandom Number Generation: Learn how to draw random numbers from different distributions. Also information about repeating processes in R, including writing your own functions, using for loops, and using if-else functions."
  },
  {
    "objectID": "notes/03-01-regression-from-summary-measures.html",
    "href": "notes/03-01-regression-from-summary-measures.html",
    "title": "üé∂ Regression from Summary Measures",
    "section": "",
    "text": "When we have raw data, we can fit a regression model using the lm() function and obtain model- and coefficient-level summaries using the glance() and tidy() functions respectively. However, there are times we might want to compute regression coefficients and standard errors, but are not given the raw data. This is common for example in articles, which often report summaries rather than providing raw data. In this set of notes, we will examine how we can fit a regression model to summaries of the data, rather than to the raw data itself.\nSo long as we have certain statistical information we can compute the regression coefficients and standard errors without having the raw data. To do this, we need the sample size, means, standard deviations, and correlations between variables. For example, consider the following summary table:\nCorrelation matrix for five attributes measured on n = 1,000 students. Means (standard deviations) for each attribute are provided on the main diagonal. \n\n\nMeasure\n1.\n2.\n3.\n4.\n5.\n\n\n\n\n1. Achievement\n50 (10)\n---\n---\n---\n---\n\n\n2. Ability\n0.737\n100 (15)\n---\n---\n---\n\n\n3. Motivation\n0.255\n0.205\n50 (10)\n---\n---\n\n\n4. Previous Coursework\n0.615\n0.498\n0.375\n4 (2)\n---\n\n\n5. Family Background\n0.417\n0.417\n0.190\n0.372\n0 (1)\nSay we wanted to use this information to fit a regression model to predict variation in achievement using the other four predictors. Mathematically,\n\\[\n\\begin{split}\n\\mathrm{Achievement}_i = &\\beta_0 + \\beta_1(\\mathrm{Ability}_i) + \\beta_2(\\mathrm{Motivation}_i) + \\\\\n&\\beta_3(\\mathrm{Coursework~}_i) + \\beta_4(\\mathrm{Family~Background}_i) + \\epsilon_i\n\\end{split}\n\\]\nTo do this we are going to create the correlation matrix, the vector of attribute means, and the vector of attribute standard deviations.\n# Create correlation matrix\ncorrs = matrix(\n  data = c(\n    1.000, 0.737, 0.255, 0.615, 0.417,\n    0.737, 1.000, 0.205, 0.498, 0.417,\n    0.255, 0.205, 1.000, 0.375, 0.190,\n    0.615, 0.498, 0.375, 1.000, 0.372,\n    0.417, 0.417, 0.190, 0.372, 1.000\n  ),\n  nrow = 5\n)\n\n# View correlation matrix\ncorrs\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 1.000 0.737 0.255 0.615 0.417\n[2,] 0.737 1.000 0.205 0.498 0.417\n[3,] 0.255 0.205 1.000 0.375 0.190\n[4,] 0.615 0.498 0.375 1.000 0.372\n[5,] 0.417 0.417 0.190 0.372 1.000\n\n# Create mean vector\nmeans = c(50, 100, 50, 4, 0)\n\n# Create sd vector\nsds = c(10, 15, 10, 2, 1)\n\n# Set sample size\nn = 1000"
  },
  {
    "objectID": "notes/03-01-regression-from-summary-measures.html#going-from-the-correlations-to-covariances",
    "href": "notes/03-01-regression-from-summary-measures.html#going-from-the-correlations-to-covariances",
    "title": "üé∂ Regression from Summary Measures",
    "section": "Going From the Correlations to Covariances",
    "text": "Going From the Correlations to Covariances\nThe summary measures we have give correlations, not covariances. However, it is quite easy to convert a correlation matrix to a covariance matrix. From the chapter Statistical Application: SSCP, Variance‚ÄìCovariance, and Correlation Matrices in Matrix Algebra for Educational Scientists, know that:\n\\[\n\\mathbf{R} = \\mathbf{S} \\boldsymbol\\Sigma \\mathbf{S}\n\\]\nwhere R is the correlation matrix, \\(\\boldsymbol\\Sigma\\) is the covariance matrix, and S is a diagonal scaling matrix with diagonal elements equal to the reciprocal of the standard deviations of each of the variables in the covariance matrix. Re-arranging this:\n\\[\n\\boldsymbol\\Sigma = \\mathbf{S}^{-1} \\mathbf{R} \\mathbf{S}^{-1}\n\\]\nRecall that the inverse of a diagonal matrix is another diagonal matrix where the diagonal elements are the resciprocals of the original. Thus the diagonal elements of the inverse of our scaling matrix will be the standard deviations of the variables. Using this formula, we can now convert the given correlation matrix to a covariance matrix.\n\n# Compute the scaling matrix S^(-1)\nS_inv = diag(sds)\nS_inv\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   10    0    0    0    0\n[2,]    0   15    0    0    0\n[3,]    0    0   10    0    0\n[4,]    0    0    0    2    0\n[5,]    0    0    0    0    1\n\n# Compute covariance matrix\ncovs = S_inv %*% corrs %*% S_inv\ncovs\n\n       [,1]    [,2]   [,3]   [,4]  [,5]\n[1,] 100.00 110.550  25.50 12.300 4.170\n[2,] 110.55 225.000  30.75 14.940 6.255\n[3,]  25.50  30.750 100.00  7.500 1.900\n[4,]  12.30  14.940   7.50  4.000 0.744\n[5,]   4.17   6.255   1.90  0.744 1.000\n\n\nAdding in the row and column names:\n\n\n\nVariance-covariance matrix for five attributes measured on n = 1,000 students. \n\n\n\nAchievement\nAbility\nMotivation\nPrevious.Coursework\nFamily.Background\n\n\n\n\nAchievement\n100.00\n110.550\n25.50\n12.300\n4.170\n\n\nAbility\n110.55\n225.000\n30.75\n14.940\n6.255\n\n\nMotivation\n25.50\n30.750\n100.00\n7.500\n1.900\n\n\nPrevious Coursework\n12.30\n14.940\n7.50\n4.000\n0.744\n\n\nFamily Background\n4.17\n6.255\n1.90\n0.744\n1.000\n\n\n\n\n\n\n\n\nRemember, the diagonal elements in the covariance matrix are variances of each variable and the off-diagonal elements are the covariances between two variables. For example, the first diagonal element is 100, which is the variance of the achievement variable. The remaining elements in the first column indicate the covariances between achievement and ability, achievement and motivation, achievement and previous coursework, and achievement and family background."
  },
  {
    "objectID": "notes/03-01-regression-from-summary-measures.html#finding-the-predictor-coefficients",
    "href": "notes/03-01-regression-from-summary-measures.html#finding-the-predictor-coefficients",
    "title": "üé∂ Regression from Summary Measures",
    "section": "Finding the Predictor Coefficients",
    "text": "Finding the Predictor Coefficients\nTo compute the coefficients for the predictors, we need to obtain two things:\n\nCov(X, X): The variance-covariance matrix of the predictors, and\nCov(X, y): The vector that contains the covariances between the outcome and each predictor. (Note: This vector does not include the variance of the outcome, only the covariances with the predictors.)\n\nIn our example, the elements in the first column (or row) of the variance-covariance matrix other than the variance of the outcome are the values in the vector Cov(X, y). The elements in the other rows/columns make up the elements of the Cov(X, X) matrix.\n\n\n\nVariance-covariance matrix for five attributes measured on n = 1,000 students. \n\n\n\nAchievement\nAbility\nMotivation\nPrevious.Coursework\nFamily.Background\n\n\n\n\nAchievement\n100.00\n110.550\n25.50\n12.300\n4.170\n\n\nAbility\n110.55\n225.000\n30.75\n14.940\n6.255\n\n\nMotivation\n25.50\n30.750\n100.00\n7.500\n1.900\n\n\nPrevious Coursework\n12.30\n14.940\n7.50\n4.000\n0.744\n\n\nFamily Background\n4.17\n6.255\n1.90\n0.744\n1.000\n\n\n\n\n\n\n\n\nHere the blue elements compose Cov(X, y) and the reddish-purple elements constitute Cov(X, X). We can create this vector and matrix using indexing.\n\n# Create Cov(X, y)\ncov_xy = covs[-1 , 1]\ncov_xy\n\n[1] 110.55  25.50  12.30   4.17\n\n# Create Cov(X, X)\ncov_xx = covs[-1 , -1]\ncov_xx\n\n        [,1]   [,2]   [,3]  [,4]\n[1,] 225.000  30.75 14.940 6.255\n[2,]  30.750 100.00  7.500 1.900\n[3,]  14.940   7.50  4.000 0.744\n[4,]   6.255   1.90  0.744 1.000\n\n\nThen we can use these to compute the predictor coefficients.\n\n# Compute predictor coefficients\nb = solve(cov_xx) %*% cov_xy\nb\n\n           [,1]\n[1,] 0.36737330\n[2,] 0.01257721\n[3,] 1.55001342\n[4,] 0.69497334\n\n\nThus the coefficient estimates are:\n\n\\(\\hat\\beta_{\\mathrm{Ability}} = 0.367\\)\n\\(\\hat\\beta_{\\mathrm{Motivation}} = 0.013\\)\n\\(\\hat\\beta_{\\mathrm{Previous~Coursework}} = 1.550\\)\n\\(\\hat\\beta_{\\mathrm{Family~Background}} = 0.695\\)"
  },
  {
    "objectID": "notes/03-01-regression-from-summary-measures.html#computing-the-intercept",
    "href": "notes/03-01-regression-from-summary-measures.html#computing-the-intercept",
    "title": "üé∂ Regression from Summary Measures",
    "section": "Computing the Intercept",
    "text": "Computing the Intercept\nTo compute the intercept, we can use the following:\n\\[\n\\hat\\beta_0 = \\bar{y} - \\bar{\\mathbf{x}}^\\intercal\\mathbf{b}\n\\]\nwhere \\(\\bar{y}\\) is the mean of the outcome, \\(\\bar{\\mathbf{x}}\\) is the vector of predictor means, and b is the associated vector of predictor coefficients.\nIn our example,\n\n# Compute intercept\nb_0 = means[1] - t(means[2:5]) %*% b\nb_0\n\n         [,1]\n[1,] 6.433756\n\n\nThus the fitted equation for the unstandardized model is:\n\\[\n\\begin{split}\n\\widehat{\\mathrm{Achievement}_i} = &6.434 + 0.367(\\mathrm{Ability}_i) + 0.013(\\mathrm{Motivation}_i) + \\\\\n&1.550(\\mathrm{Coursework~}_i) + 0.695(\\mathrm{Family~Background}_i)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/03-01-regression-from-summary-measures.html#compute-mathbfxintercalmathbfx-matrix",
    "href": "notes/03-01-regression-from-summary-measures.html#compute-mathbfxintercalmathbfx-matrix",
    "title": "üé∂ Regression from Summary Measures",
    "section": "Compute \\(\\mathbf{X}^\\intercal\\mathbf{X}\\) Matrix",
    "text": "Compute \\(\\mathbf{X}^\\intercal\\mathbf{X}\\) Matrix\nThe elements in the first row and column of the \\(\\mathbf{X}^\\intercal\\mathbf{X}\\) matrix are functions of the sample size and means of the predictor variables. Namely the first element in the first row and column is n and the remaining elements in the that row and column are created as \\(n\\mathbf{M_x}\\), where n is the sample size, and \\(\\mathbf{M_x}\\) is the vector of predictor means. The remaining elements constitute a submatrix defined as:\n\\[\n(\\mathbf{X}^\\intercal\\mathbf{X})_{\\mathrm{Sub}} = (n-1)\\mathrm{Cov}(X,X) + n(\\mathbf{M_x})(\\mathbf{M_x}^\\intercal)\n\\]\nwhere n is the sample size, Cov(X,X) is the variance covariance matrix ofthe predictors, and \\(\\mathbf{M_x}\\) is again the vector of predictor means. We cn then create the \\(\\mathbf{X}^\\intercal\\mathbf{X}\\) matrix as:\n\\[\n\\require{color}\n\\begin{split}\n\\mathbf{X}^\\intercal\\mathbf{X} &= \\begin{bmatrix}{\\color[rgb]{0.044147,0.363972,0.636955}n} & {\\color[rgb]{0.044147,0.363972,0.636955}n\\mathbf{M_x}}\\\\{\\color[rgb]{0.044147,0.363972,0.636955}n\\mathbf{M_x}} & {\\color[rgb]{0.748052,0.381230,0.589698}(\\mathbf{X}^\\intercal\\mathbf{X})_{\\mathrm{Sub}}}\\end{bmatrix}\n\\\\[2ex]\n&= \\begin{bmatrix}{\\color[rgb]{0.044147,0.363972,0.636955}n} & {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X1}} & {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X2}} &  {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X3}} & {\\color[rgb]{0.044147,0.363972,0.636955}\\ldots} & {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{Xk}}\\\\ {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X1}} & & & & &  \\\\ {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X2}} & & & & &  \\\\ {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{X3}} & & & {\\color[rgb]{0.748052,0.381230,0.589698}(\\mathbf{X}^\\intercal\\mathbf{X})_{\\mathrm{Sub}}} & &  \\\\ {\\color[rgb]{0.044147,0.363972,0.636955}\\vdots} & & & & &  \\\\ {\\color[rgb]{0.044147,0.363972,0.636955}n\\overline{Xk}} & & & & &   \\end{bmatrix}\n\\end{split}\n\\]\nTo create this matrix using R, we will:\n\nCompute the submatrix \\((\\mathbf{X}^\\intercal\\mathbf{X})_{\\mathrm{Sub}}\\).\nBind the \\(n\\mathbf{M_x}\\) vector to the top of the submatrix.\nBind the vector that contains n and \\(n\\mathbf{M_x}\\) to the left of the resulting matrix from Step 2.\n\nThe resulting matrix is the \\(\\mathbf{X}^\\intercal\\mathbf{X}\\) matrix. For our example,\n\n# Step 1: Create submatrix\nsub_mat = 999 * cov_xx + 1000 * means[2:5] %*% t(means[2:5])\nsub_mat\n\n             [,1]      [,2]       [,3]     [,4]\n[1,] 10224775.000 5030719.2 414925.060 6248.745\n[2,]  5030719.250 2599900.0 207492.500 1898.100\n[3,]   414925.060  207492.5  19996.000  743.256\n[4,]     6248.745    1898.1    743.256  999.000\n\n# Step 2: Bind n(M_x) to top of submatrix\nmat_2 = rbind(1000 * means[2:5], sub_mat)\nmat_2\n\n             [,1]      [,2]       [,3]     [,4]\n[1,]   100000.000   50000.0   4000.000    0.000\n[2,] 10224775.000 5030719.2 414925.060 6248.745\n[3,]  5030719.250 2599900.0 207492.500 1898.100\n[4,]   414925.060  207492.5  19996.000  743.256\n[5,]     6248.745    1898.1    743.256  999.000\n\n# Step 3: Bind vector to left of Step 2 matrix\nXtX = cbind(c(1000, 1000 * means[2:5]), mat_2)\nXtX\n\n       [,1]         [,2]      [,3]       [,4]     [,5]\n[1,]   1000   100000.000   50000.0   4000.000    0.000\n[2,] 100000 10224775.000 5030719.2 414925.060 6248.745\n[3,]  50000  5030719.250 2599900.0 207492.500 1898.100\n[4,]   4000   414925.060  207492.5  19996.000  743.256\n[5,]      0     6248.745    1898.1    743.256  999.000\n\n\nWe can then scale this matrix using our previous estimate of the residual variance to obtain the variance-covariance matrix for the coefficients and compute the coefficient standard errors.\n\n# Compute var-cov matrix of b\ncov_b = s2_e * solve(XtX)\ncov_b\n\n            [,1]            [,2]            [,3]         [,4]          [,5]\n[1,]  2.86183238 -0.021078176856 -0.018522600965  0.052341868  0.1280945885\n[2,] -0.02107818  0.000240314903 -0.000001964506 -0.000713772 -0.0009683908\n[3,] -0.01852260 -0.000001964506  0.000435428791 -0.000763097 -0.0002472826\n[4,]  0.05234187 -0.000713772031 -0.000763096999  0.014297546 -0.0047228461\n[5,]  0.12809459 -0.000968390764 -0.000247282552 -0.004722846  0.0473303248\n\n# Compute SEs\nse = sqrt(diag(cov_b))\nse\n\n[1] 1.69169512 0.01550209 0.02086693 0.11957235 0.21755534\n\n\nThese are the standard errors for the intercept and each predictor. Here I add the coefficients and standard errors to a data frame and use them to compute t-values, associated p-values, and confidence intervals.\n\n# Load library\nlibrary(tidyverse)\n\n# Create regression table\ndata.frame(\n  Predictor = c(\"Intercept\", \"Ability\", \"Motivation\", \"Previous Coursework\", \"Family Background\"),\n  B = c(b_0, b),\n  SE = se\n) |&gt;\n  mutate(\n    t = round(B /SE, 3),\n    p = round(2 * pt(-abs(t), df = 995), 5),\n    CI = paste0(\"(\", round(B + qt(.025, df = 995)*SE, 3), \", \", round(B + qt(.975, df = 995)*SE, 3), \")\")\n  )"
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html",
    "href": "notes/03-regression-diagnostics-2023.html",
    "title": "üìù Regression Diagnostics",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to empirical diagnostics to detect extreme observations. We will use the contraception.csv data to evaluate the effect of female education level on contraception rates.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Import data\ncontraception = read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/contraception.csv\")\n\n# View data\ncontraception"
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html#identifying-high-leverage-observations-in-the-contraception-example",
    "href": "notes/03-regression-diagnostics-2023.html#identifying-high-leverage-observations-in-the-contraception-example",
    "title": "üìù Regression Diagnostics",
    "section": "Identifying High Leverage Observations in the Contraception Example",
    "text": "Identifying High Leverage Observations in the Contraception Example\nIn practice, we can use the augment() function from the {broom} package to obtain the leverage values for each observation for a fitted model. These values are provided in the .hat column. Previously, we had assigned the augment output for lm.1 to an object called out_1.\n\n# View augmented data\nout_1\n\n\n\n  \n\n\n\nHere, for example, we can see that the leverage value for the first observation is 0.0875. To determine which observations have high leverage, we will create an index plot of the leverage values.\n\n# Add case number to the augmented data\nout_1 = out_1 |&gt;\n  mutate(\n    case = row_number()\n    )\n\n# View augmented data\nout_1\n\n\n\n  \n\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_point(size = 4) +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\n\n\n\n\nWhile it seems we may be able to identify observations with high leverage in this plot, sometimes this can be difficult depending on the data. For example, the two highest observations seem like they probably have high leverage relative to the others, but what about the four observations with leverage values between 0.10 and 0.12?\nOne criterion that applied researchers use is that an observation has high leverage if:\n\\[\nh_{ii} &gt; \\frac{2p}{n}\n\\]\nwhere p is the trace of H, which also happens to be the sum of the \\(h_{ii}\\) values. This implies that,\n\\[\n\\begin{split}\nh_{ii} &&gt; \\frac{2p}{n} \\\\[1em]\n&&gt; \\frac{2\\sum h_{ii}}{n} \\\\[1em]\n&&gt; 2 \\bar{h}\n\\end{split}\n\\]\nwhere \\(\\bar{h}\\) is the average leverage value. Thus, we are identifying observations with a leverage value greater than twice the average value, and those are the observations we are saying have high leverage. It is often useful to draw a horizontal line in the index plot at this value. Below we add in this line, and also plot the observations‚Äô case value rather than plotting points. This helps us identify the cases with high leverage.\n\n# Compute cutoff\ncutoff = 2 * mean(out_1$.hat)\ncutoff\n\n[1] 0.08247423\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_text(aes(label = case)) +\n  geom_hline(yintercept = cutoff, color = \"#cc79a7\") +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their case value. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value.\n\n\n\n\nBased on this criterion, there are several observations that have high leverage values in this model. Since these observations represent countries, and we have country names in the original data, we could also create this index plot using country names to label the observations instead of case numbers.\n\n# Add country names to augmented data\nout_1 = out_1 |&gt;\n  mutate(\n    country = contraception$country\n  )\n\n# View data\nout_1\n\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their country name. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value.\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_text(aes(label = country)) +\n  geom_hline(yintercept = cutoff, color = \"#cc79a7\") +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their country name. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value."
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html#statistical-test-for-identifying-observations-with-large-residuals",
    "href": "notes/03-regression-diagnostics-2023.html#statistical-test-for-identifying-observations-with-large-residuals",
    "title": "üìù Regression Diagnostics",
    "section": "Statistical Test for Identifying Observations with Large Residuals",
    "text": "Statistical Test for Identifying Observations with Large Residuals\nSome educational scientists evaluate whether a particular observation is a regression outlier, by using a hypothesis test to determine whether its residual differs statistically from 0. To do this, we can use a t-test where we evaluate the standardized residual,\n\\[\ne^*_i = \\frac{e_i}{\\mathrm{SE}(e_i)}\n\\]\nThis is evaluated in a t-distribution with df equivalent to the residual degrees-of-freedom from the model. The t-value here looks a lot like the formula we used to compute the standardized residual.\nUnfortunately, we cannot use the standardized residual here since, if we do, the numerator and denominator are not independent (the term \\(s^2_e\\) in the denominator is a function of \\(e_i\\).). This would mean that the resulting statistic is not t-distributed. To fix this problem, we can compute an estimate of \\(s^2_e\\) that is computed based on the regression deleting the ith observation. That is,\n\\[\nt_i = \\frac{e_i}{\\sqrt{s^2_{e(-i)} (1 - h_{ii})}}\n\\] To differentiate this change in the standard error, sometimes statisticians refer to this value as a studentized residual rather than a standardized residual.4\n\n\nComputing the Studentized Residual\nAll of the components to compute the stuentized residuals are provided in the augment() output.\n\n# View augmented output\nout_1\n\n\n\n  \n\n\n\nThe values in the .sigma column are estimates of \\(s_e\\) computed based on the regression deleting the ith observation. That is, they are \\(s_{e(-i)}\\). To compute the studentized residual for Observation 1,\n\\[\n\\begin{split}\nt_1 &= \\frac{e_i}{s_{e(-i)}\\sqrt{(1 - h_{ii})}} \\\\[1em]\n&= \\frac{1.34}{14.5\\sqrt{1 - .0875}} \\\\[1em]\n&= 0.09674318\n\\end{split}\n\\] We can also use this formula to compute the studentized residual for each observation in the augmented() output.\n\n# Compute studentized residuals\nout_1 = out_1 |&gt;\n  mutate(\n    t_i = .resid / (.sigma * sqrt(1 - .hat))\n  )\n\n# View output\nout_1\n\n\n\n  \n\n\n\nAlternatively, we can also use the rstudent() function to compute the studentized residuals directly. This function takes the model object as its input.\n\n# Compute studentized residuals\nout_1 = out_1 |&gt;\n  mutate(\n    t_i = rstudent(lm.1)\n  )\n\n# View output\nout_1\n\n\n\n  \n\n\n\n\n\n\nTesting Observations for Outlyingness\nNow that we have the t-value for each of the residuals, we can evaluate each residual for outlyingness by evaluating each t-statistics in the t-distribution with df equivalent to the residual degrees-of-freedom from the model. In our case,\n\\[\n\\mathit{df} = 93\n\\] Thus, to evaluate whethe the first observation is a regression outlier, we would evaluate\n\\[\nt(93) = 0.097\n\\] to determine if the residual is statistically different than 0. Below, we compute the p-value associated with the first observation.\n\n# Compute p-value for Obs. 1\n2 * pt(-0.097, df = 93)\n\n[1] 0.9229351\n\n\nBecause we need to carry out this test for each of the 97 observations, we need to adjust each p-value based on the number of comparisons. This is typically done by using a Bonferroni adjustment.\n\n# Bonferroni adjustment for Obs. 1\n0.9229351 * 97\n\n[1] 89.5247\n\n\nSince this results in a value greater than 1, and p-values need to be between 0 and 1, we report this p-value as 1. Since this is not statistically significant (at the \\(\\alpha = 0.05\\) level), Observation 1 is not considered a regression outlier. Below is the syntax I use to compute the Bonferroni adjusted p-values for each of the 97 observations.\n\n# Bonferroni adjustment for all observations\nout_1 = out_1 |&gt;\n  mutate(\n    p = 2 * pt(-abs(t_i), df = 97),\n    p_adj = p.adjust(p, method = \"bonferroni\")\n  )\n\n# Order data by adjusted p-values\narrange(out_1, p_adj)\n\n\n\n  \n\n\n\nThese results indicate that none of the observations are more extreme than would be expected given the sample size. In other words, the test would not identify any observations as regression outliers."
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html#dfbetas",
    "href": "notes/03-regression-diagnostics-2023.html#dfbetas",
    "title": "üìù Regression Diagnostics",
    "section": "DFBETAS",
    "text": "DFBETAS\nThe most direct way to measure the influence of an observation is to drop that observation from the dataset and measure the difference in regression coefficients. We can define this difference as \\(d_{ij}\\) (the difference between the jth regression coefficient when the ith observation is dropped) as:\n\\[\nd_{ij} = \\hat{\\beta}_j - \\hat{\\beta}_{j(-i)}\n\\]\nThese are referred to as DFBETAs following the naming convention set by Belsley, Kuh, & Welsch (1980). The dfbeta() function computes the DFBETA values for each coefficient for all observations. This function takes the fitted model object as its input. (Here we pipe this output into a data frame for better screen printing in the notes.)\n\ndfbeta(lm.1) |&gt;\n  data.frame()\n\n\n\n  \n\n\n\nPositive DFBETA values indicate that removing the observation results in a lower regression coefficient value, while a negative DFBETA value would indicate that removing the observation results in a higher regression coefficient value. For example, focusing on the interaction term, we see that removing Observation 1 would result in a higher value on the interaction coefficient by .0299 units.\nBecause the DFBETA values are in the same unit as the coefficients, it can sometimes be difficult to assess whether those values are indicative of a small or large amount of influence. To remedy this, the DFBETA values are typically scaled. To do this, the DFBETA value is divided by a scaled RMSE estimate,\n\\[\nd^*_{ij} = \\frac{d_{ij}}{s_{e(-i)}\\sqrt{c_{jj}}}\n\\]\nwhere \\(s_{e(-i)}\\) is the RMSE estimate when the ith observation is deleted from the model, and \\(c_{jj}\\) is the jth diagonal element of the \\((\\mathbf{XX}^\\intercal)^{-1}\\) matrix corresponding to the appropriate regression coefficient. For example, here we compute the \\((\\mathbf{XX}^\\intercal)^{-1}\\) matrix for the fitted model.\n\nX = model.matrix(lm.1)\nsolve(t(X) %*% X)\n\n                     (Intercept)  educ_female    high_gni educ_female:high_gni\n(Intercept)           0.07946790 -0.013509292 -0.07946790          0.013509292\neduc_female          -0.01350929  0.003068899  0.01350929         -0.003068899\nhigh_gni             -0.07946790  0.013509292  0.62476222         -0.070745716\neduc_female:high_gni  0.01350929 -0.003068899 -0.07074572          0.009320611\n\n\nThe \\(c_{jj}\\) value corresponding to the interaction term is 0.009320611.\nAgain, using the .sigma value from the augmented output to obtain \\(s_{e(-i)}\\), we can compute the scaled DFBETA value for the interaction term based on the first observation as:\n\n#Compute scaled DFBETA for interaction term (Obs. 1)\n-0.0299422430 / (14.5 * sqrt(0.009320611))\n\n[1] -0.02138918\n\n\nRemoving Observation 1 would result in a higher value on the interaction coefficient by .0214 standard deviation units. We can use the dfbetas() function to compute all the scaled DFBETA values. (Here we pipe this output into a data frame for better screen printing in the notes.)\n\n# Get scaled DFBETA values\ndfbetas(lm.1) |&gt;\n  data.frame()\n\n\n\n  \n\n\n\nAs with our other measures, it is useful to create an index plot of the scaled DFBETA values. Typically you would create separate index plots for each of the coefficients. Below, I include the scaled DFBETA values in a data frame, and create the index plots. Because we are interested in large scaled DFBETA values regardless of sign, I plot the absolute value of the scaled DFBETA values in each case plot. Here I focus on the index plot associated with the interaction term since that is the primary effect of interests in an interaction model.\n\n# Set up data with case number and scaled DFBETA values\nscl_dfbeta = data.frame(\n  case = 1:97\n) |&gt;\n  cbind(dfbetas(lm.1))\n\n\n# Create index plots\nggplot(data = scl_dfbeta, aes(x = case, y = abs(`educ_female:high_gni`))) +\n  geom_text(aes(label = case), size = 3) +\n  xlab(\"Observation number\") +\n  ylab(\"Scaled DFBETA value\") +\n  theme_bw() +\n  geom_hline(yintercept = 2 / sqrt(97), color = \"#cc79a7\")\n\n\n\n\nIndex plot of the absolute value of the standardized DFBETA values for the interaction effect between female education level and high GNI.\n\n\n\n\nNote that because the variable name included a colon (which is a special character in R syntax), we had to enclose the variable name educ_female:high_gni in back ticks in the ggplot() syntax. We also add a guideline to demarcate observations where \\(\\vert d^*_{ij}\\vert &gt; \\frac{2}{\\sqrt{n}}\\).\nWe want to use the plot to identify cases that have an absolute scaled DFBETA value that is substantially higher than most other observations‚Äô absolute scaled DFBETA values. (The guideline can help us identify these cases.) Observations 53 (Maldives), 84 (Tajikistan), and 41 (Japan) seem to have influence on the interaction coefficient of interest. Observation 19 (Colombia) also may have a modest amount of influence on the interaction term."
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html#cooks-distance",
    "href": "notes/03-regression-diagnostics-2023.html#cooks-distance",
    "title": "üìù Regression Diagnostics",
    "section": "Cook‚Äôs Distance",
    "text": "Cook‚Äôs Distance\nWhile the DFBETA and scaled DFBETA values directly measure the impact of an observation on each of the coefficients, these measures of influence are not commonly used in practice. Instead, Cook‚Äôs Distance (Cook, 1977) is a more commonly used measure of influence by applied researchers. This measure is computed as:\n\\[\nD_i = \\frac{(e^*_i)^2}{p + 1} \\times \\frac{h_{ii}}{1 - h_{ii}}\n\\]\nwhere \\(e^*_i\\) is the standardized residual for the ith observation, p is the number of predictors in the fitted model, and \\(h_{ii}\\) is the leverage value for the ith observation. Below we compute Cook‚Äôs Distance for Observation 1 using values obtained from the augment() output.\n\n# Compute D_i for Obs. 1\n0.0976^2 / (3 + 1) * 0.0875 / (1 - 0.0875)\n\n[1] 0.0002283573\n\n\nThe Cook‚Äôs Distance values are also generated in the .cooksd column of the augment() output.\n\n# View augmented output\nout_1\n\n\n\n  \n\n\n\nObservations with a Cook‚Äôs Distance such that \\(D_i &gt; \\frac{4}{n-p-1}\\) are considered influential. In this case, Observation 1 would not be considered influential as its Cook‚Äôs Distance of 0.0002 is not larger than the cutoff of 0.043.\nUnlike the DFBETA measures which computes multiple measures of influence for each observation, Cook‚Äôs Distance computes a single measure of influence for each observation. This measures the overall influence across all of the predictors rather than the influence on any one predictor. (It is probably for this reason that Cook‚Äôs Distance is favored by applied researchers.) We can, once again, create an index plot to plot the Cook‚Äôs Distance values. Within this plot, a guideline can be added to identify cases larger than the cutoff.\n\n# Add case number to data\nout_1 = out_1 |&gt;\n  mutate(case = row_number())\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .cooksd)) +\n  geom_text(aes(label = case), size = 3) +\n  xlab(\"Observation number\") +\n  ylab(\"Cook's D value\") +\n  theme_bw() +\n  geom_hline(yintercept = 4 / (97 - 3- 1), color = \"#cc79a7\")\n\n\n\n\nIndex plot of Cook‚Äôs D values for the 97 observations.\n\n\n\n\nBased on the plot, we can identify Observations 84 (Tajikistan), 53 (Maldives), and 41 (Japan) as being influential in the model."
  },
  {
    "objectID": "notes/03-regression-diagnostics-2023.html#footnotes",
    "href": "notes/03-regression-diagnostics-2023.html#footnotes",
    "title": "üìù Regression Diagnostics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen there is more than one predictor, leverage is measure of how far away an observation is from the centroid of the predictor space.‚Ü©Ô∏é\nBecause we are dividing by the standard error sometimes these are referred to as internally studentized residuals rather than standardized residuals.‚Ü©Ô∏é\nIf the sample size is large, it is better to use the heuristic that regression outliers have a standardized residual more than 3 SEs from zero.‚Ü©Ô∏é\nStudentized residuals are also sometimes referred to as: deleted studentized residuals, externally studentized residuals, and in some books and papers, even as standardized residuals. Ugh.‚Ü©Ô∏é"
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "",
    "text": "In this set of notes, we will use data from Statistics Canada‚Äôs Survey of Labour and Income Dynamics (SLID) to explain variation in the hourly wage rate of employed citizens in Ontario.\nA script file for the analyses in these notes is also available:"
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html#violating-homoskedasticity",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html#violating-homoskedasticity",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Violating Homoskedasticity",
    "text": "Violating Homoskedasticity\nViolating the distributional assumption of homoskedasticity results in:\n\nIncorrect computation of the sampling variances and covariances; and because of this\nThe OLS estimates are no longer BLUE (Best Linear Unbiased Estimator).\n\nThis means that the SEs (and resulting t- and p-values) for the coefficients are incorrect. In addition, the OLS estimators are no longer the most efficient estimators. How bad this is depends on several factors (e.g., how much the variances differ, sample sizes)."
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html#box-cox-transformation",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html#box-cox-transformation",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Box-Cox Transformation",
    "text": "Box-Cox Transformation\nIs there a power transformation that would better ‚Äúfix‚Äù the heteroskedasticity? In their seminal paper, Box & Cox (1964) proposed a series of power transformations that could be applied to data in order to better meet assumptions such as linearity, normality, and homoskedasticity. The general form of the Box-Cox model is:\n\\[\nY^{(\\lambda)}_i = \\beta_0 + \\beta_1(X1_{i}) + \\beta_2(X2_{i}) + \\ldots + \\beta_k(Xk_{i}) + \\epsilon_i\n\\]\nwhere the errors are independent and \\(\\mathcal{N}(0,\\sigma^2_{\\epsilon})\\), and\n\\[\nY^{(\\lambda)}_i = \\begin{cases}\n   \\frac{Y_i^{\\lambda}-1}{\\lambda} & \\text{for } \\lambda \\neq 0 \\\\[1em]\n   \\ln(Y_i)       & \\text{for } \\lambda = 0\n  \\end{cases}\n\\]\nThis transformation is only defined for positive values of Y.\nThe powerTransform() function from the {car} library can be used to determine the optimal value of \\(\\lambda\\).\n\n# Find optimal power transformation using Box-Cox\npowerTransform(lm.1)\n\nEstimated transformation parameter \n        Y1 \n0.08598786 \n\n\nThe output from the powerTransform() function gives the optimal power for the transformation of y, namely \\(\\lambda = 0.086\\). To actually implement the power transformation we use the transform Y based on the Box-Cox algorithm presented earlier.\n\nslid = slid %&gt;%\n  mutate(\n    bc_wages = (wages ^ 0.086 - 1) / 0.086\n  )\n\n# Fit models\nlm_bc = lm(bc_wages ~ 1 + age + education + male, data = slid)\n\nThe residual plots (shown below) indicate better behaved residuals for the main-effects model, although even this optimal transformation still shows some evidence of heteroskedasticity.\n\n\nCode\n# Examine residual plots\nresidual_plots(lm_bc)\n\n\n\n\n\nResidual plots for the main effects model that used a Box-Cox transformation on Y with \\(\\lambda=0.086\\).\n\n\n\n\nOne problem with using this transformation is that the regression coefficients do not have a direct interpretation. For example, looking at the coefficient-level output:\n\ntidy(lm_bc, conf.int = TRUE)\n\n\n\n  \n\n\n\nThe age coefficient would be interpreted as: each one-year difference in age is associated with a 0.0227-unit difference in the transformed Y, controlling for differences in education and sex. But what does a 0.227-unit difference in transformed Y mean when we translate that back to wages?"
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html#profile-plot-for-different-transformations",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html#profile-plot-for-different-transformations",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Profile Plot for Different Transformations",
    "text": "Profile Plot for Different Transformations\nMost of the power transformations under Box-Cox would produce coefficients that are difficult to interpret. The exception is when \\(\\lambda=0\\). This is the log-transformation which is directly interpretable. Since the optimal \\(\\lambda\\) value of 0.086 is quite close to 0, we might wonder whether we could just use the log-transformation (\\(\\lambda=0\\)). The Box-Cox algorithm optimizes the log-likelihood of a given model, so the statistical question is whether there is a difference in the log-likelihood produced by the optimal transformation and that for the log-transformation.\nTo evaluate this, we can plot of the log-likelihood for a given model using a set of lambda values. This is called a profile plot of the log-likelihood. The boxCox() function creates a profile plot of the log-likelihood for a defined sequence of \\(\\lambda\\) values. Here we will plot the profile of the log-likelihood for \\(-2 \\leq \\lambda \\leq 2\\).\n\n# Plot of the log-likelihood for a given model versus a sequence of lambda values\nboxCox(lm.1, lambda = seq(from = -2, to = 2, by = 0.1))\n\n\n\n\nPlot of the log-likelihood profile for a given model versus a sequence of lambda values. The lambda that produces the highest log-likelihood is 0.086, the optimal lambda value.\n\n\n\n\nThe profile plot shows that the optimal lambda value, 0.86, produces the maximum log-likelihood value for the given model. We also are shown the 95% confidence limits for lambda based on a test of the curvature of the log-likelihood function. This interval offers a range of \\(\\lambda\\) values that will give comparable transformations. Since the values associated with the confidence limits are not outputted by the boxCox() function, we may need to zoom in to determine these limits by tweaking the sequence of \\(\\lambda\\) values in the boxCox() function.\n\n# Zomm in on confidence limits\nboxCox(lm.1, lambda = seq(from = 0.03, to = 0.2, by = .001))\n\n\n\n\nPlot of the log-likelihood profile for a given model versus a narrower sequence of lambda values.\n\n\n\n\nIt looks as though \\(.03 \\leq \\lambda \\leq 0.14\\) all give comparable transformations. Unfortunately, 0 is not included in those limits. This means that the \\(\\lambda\\) value of 0.086 will produce a higher log-likelihood than the log-transformation. It is important to remember that even though the log-likelihood will be optimized, the compatibility with the assumptions may or may not be improved when we use \\(\\lambda=0.086\\) versus \\(\\lambda=0\\). The only way to evaluate this is to fit the models and check the residuals."
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html#assume-error-variances-are-known",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html#assume-error-variances-are-known",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Assume Error Variances are Known",
    "text": "Assume Error Variances are Known\nLet‚Äôs assume that each of the error variances, \\(\\sigma^2_i\\), are known. This is generally not a valid assumption, but it gives us a point to start from. If we know these values, we can modify the likelihood function from OLS by substituting these values in for the OLS error variance, \\(\\sigma^2_{\\epsilon}\\).\n\\[\n\\begin{split}\n\\mathrm{OLS:} \\qquad \\mathcal{L}(\\boldsymbol{\\beta}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2_{\\epsilon}}}\\exp\\left[-\\frac{1}{2\\sigma^2_{\\epsilon}} \\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right] \\\\[1em]\n\\mathrm{WLS:} \\qquad \\mathcal{L}(\\boldsymbol{\\beta}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2_{i}}}\\exp\\left[-\\frac{1}{2\\sigma^2_{i}} \\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right]\n\\end{split}\n\\]\nNext, we define the reciprocal of the error variances as \\(w_i\\), or weight:\n\\[\nw_i = \\frac{1}{\\sigma^2_i}\n\\]\nThis can be used to simplify the likelihood function for WLS:\n\\[\n\\begin{split}\n\\mathcal{L}(\\boldsymbol{\\beta}) &= \\bigg[\\prod_{i=1}^n \\sqrt{\\frac{w_i}{2\\pi}}\\bigg]\\exp\\left[-\\frac{1}{2} \\sum_{i=1}^n w_i\\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right]\n\\end{split}\n\\]\nWe can then find the coefficient estimates by maximizing \\(\\mathcal{L}(\\boldsymbol{\\beta})\\) with respect to each of the coefficients; these derivatives will result in k normal equations. Solving this system of normal equations we find that:\n\\[\n\\mathbf{b}_{\\mathrm{WLS}} = (\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{X})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{y}\n\\]\nwhere W is a diagonal matrix of the weights,\n\\[\n\\mathbf{W} =  \\begin{bmatrix}w_{1} & 0 & 0 & \\ldots & 0 \\\\ 0 & w_{2} & 0 & \\ldots & 0\\\\ 0 & 0 & w_{3} & \\ldots & 0\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\ldots & w_{n}\\end{bmatrix}\n\\]\nThe variance‚Äìcovariance matrix for the regression coefficients can then be computed using:\n\\[\n\\boldsymbol{\\sigma^2}(\\mathbf{B}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{X})^{-1}\n\\]\nwhere the estimate for \\(\\sigma^2_{\\epsilon}\\) is based on a weighted sum of squares:\n\\[\n\\hat\\sigma^2_{\\epsilon} = \\frac{\\sum_{i=1}^n w_i \\times \\epsilon_i^2}{n - k - 1}\n\\]\nWhich can be expressed in matrix algebra as a function of the weight matrix and residual vector as:\n\\[\n\\hat\\sigma^2_{\\epsilon} = \\frac{(\\mathbf{We})^{\\intercal}\\mathbf{e}}{n - k - 1}\n\\]\n\n\nAn Example of WLS Estimation\nTo illustrate WLS, consider the following data which includes average ACT scores for a classroom of students, ACT score for the teacher, and the standard deviation of the class ACT scores.\n\n\n\n\n\nClass Average ACT\nTeacher ACT\nClass SD\n\n\n\n\n17.3\n21\n5.99\n\n\n17.1\n20\n3.94\n\n\n16.4\n19\n1.90\n\n\n16.4\n18\n0.40\n\n\n16.1\n17\n5.65\n\n\n16.2\n16\n2.59\n\n\n\n\n\n\n\nSuppose we want to use the teacher‚Äôs ACT score to predict variation in the class average ACT score. Fitting this model using OLS, we can compute the coefficient estimates and the standard errors for each coefficient.\n\n# Enter y vector\ny = c(17.3, 17.1, 16.4, 16.4, 16.1, 16.2)\n\n# Create design matrix\nX = matrix(\n  data = c(rep(1, 6), 21, 20 , 19, 18, 17, 16),\n  ncol = 2\n)\n\n# Compute coefficients\nb = solve(t(X) %*% X) %*% t(X) %*% y\n\n# Compute SEs for coefficients\ne = y - X %*% b\nsigma2_e = t(e) %*% e / (6 - 1 - 1)\nV_b = as.numeric(sigma2_e) * solve(t(X) %*% X)\nsqrt(diag(V_b))\n\n[1] 0.98356794 0.05294073\n\n\nWe could also have used built-in R functions to obtain these values:\n\nlm.ols = lm(y ~ 1 + X[ , 2])\ntidy(lm.ols, conf.int = TRUE)\n\n\n\n  \n\n\n\nThe problem, of course, is that the variation in the residuals is not constant as the reliability for the 10 class average ACT values is not the same for each class; the standard deviations are different. Because of this, we may want to fit a WLS regression model rather than an OLS model.\n\n# Set up weight matrix, W\nclass_sd = c(5.99, 3.94, 1.90, 0.40, 5.65, 2.59)\nw_i = 1 / (class_sd ^ 2)\nW = diag(w_i)\nW\n\n          [,1]       [,2]      [,3] [,4]       [,5]      [,6]\n[1,] 0.0278706 0.00000000 0.0000000 0.00 0.00000000 0.0000000\n[2,] 0.0000000 0.06441805 0.0000000 0.00 0.00000000 0.0000000\n[3,] 0.0000000 0.00000000 0.2770083 0.00 0.00000000 0.0000000\n[4,] 0.0000000 0.00000000 0.0000000 6.25 0.00000000 0.0000000\n[5,] 0.0000000 0.00000000 0.0000000 0.00 0.03132587 0.0000000\n[6,] 0.0000000 0.00000000 0.0000000 0.00 0.00000000 0.1490735\n\n# Compute coefficients\nb_wls = solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% y\nb_wls\n\n           [,1]\n[1,] 13.4154764\n[2,]  0.1658431\n\n# Compute standard errors for coefficients\ne_wls = y - X %*% b_wls                                 # Compute errors from WLS\nmse_wls = (t(W %*% e_wls) %*% e_wls) / (6 - 1 - 1)      # Compute MSE estimate\nv_b_wls = as.numeric(mse_wls) * solve(t(X) %*% W %*% X) # Compute variance-covariance matrix for B\nsqrt(diag(v_b_wls))\n\n[1] 1.17680463 0.06527187\n\n\nThe results of fitting both the OLS and WLS models appear below. Comparing the two sets of results, there is a difference in the coefficient values and in the estimated SEs when using WLS estimation rather than OLS estimation. This would also impact any statistical inference as well.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOLS\n\n\nWLS\n\n\n\nCoefficient\nB\nSE\nB\nSE\n\n\n\n\nIntercept\n12.0905\n0.9836\n13.4155\n1.1768\n\n\nEffect of Teacher ACT Score\n0.2429\n0.0529\n0.1658\n0.0653\n\n\n\n\n\n\n\n\n\n\nFitting the WLS estimation in the lm() Function\nThe lm() function can also be used to fit a model using WLS estimation. To do this we include the weights= argument in lm(). This takes a vector of weights representing the \\(w_i\\) values for each of the n observations.\n\n# Create weights vector\nw_i = 1 / (class_sd ^ 2)\n\n# Fit WLS model\nlm_wls = lm(y ~ 1 + X[ , 2], weights = w_i)\ntidy(lm_wls, conf.int = TRUE)\n\n\n\n  \n\n\n\nNot only can we use tidy() and glance() to obtain coefficient and model-level summaries, but we can also use augment(), anova(), or any other function that takes a fitted model as its input."
  },
  {
    "objectID": "notes/06-tools-for-dealing-with-heteroskedasticity.html#what-if-error-variances-are-unknown",
    "href": "notes/06-tools-for-dealing-with-heteroskedasticity.html#what-if-error-variances-are-unknown",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "What if Error Variances are Unknown?",
    "text": "What if Error Variances are Unknown?\nThe previous example assumed that the variance‚Äìcovariance matrix of the residuals was known. In practice, this is almost never the case. When we do not know the error variances, we need to estimate them from the data.\nOne method for estimating the error variances for each observation, is:\n\nFit an OLS model to the data, and obtain the residuals.\nSquare these residuals and regress them (using OLS) on the same set of predictors.\nObtain the fitted values from Step 2.\nCreate the weights using \\(w_i = \\frac{1}{\\hat{y}_i}\\) where \\(\\hat{y}_i\\) are the fitted values from Step 3.\nFit the WLS using the weights from Step 4.\n\nThis is a two-stage process in which we (1) estimate the weights, and (2) use those weights in the WLS estimation. We will illustrate this methodology using the SLID data.\n\n# Step 1: Fit the OLS regression\nlm_step_1 = lm(wages ~ 1 + age + education + male + age:education, data = slid)\n\n# Step 2: Obtain the residuals and square them\nout_1 = augment(lm_step_1) %&gt;%\n  mutate(\n    e_sq = .resid ^ 2\n  )\n\n# Step 2: Regresss e^2 on the predictors from Step 1\nlm_step_2 = lm(e_sq ~ 1 + age + education + male + age:education, data = out_1)\n\n# Step 3: Obtain the fitted values from Step 2\ny_hat = fitted(lm_step_2)\n\n\n# Step 4: Create the weights\nw_i = 1 / (y_hat ^ 2)\n\n# Step 5: Use the fitted values as weights in the WLS\nlm_step_5 = lm(wages ~ 1 + age + education + male + age:education, data = slid, weights = w_i)\n\nBefore examining any output from this model, let‚Äôs examine the residual plots. The residual plots suggest that the homoskedasticity assumption is much more reasonably satisfied after using WLS estimation; although it is still not perfect. The normality assumption looks untenable here.\n\nOne way to proceed would be to apply a variance stabilizing transformation to y (e.g., log-transform) and then fit a WLS model. To do this you would go through the steps of estimating the weights again based on the transformed y.\n\n\n\nCode\n# Examine residual plots\nresidual_plots(lm_step_5)\n\n\n\n\n\nResidual plots for the model that includes the main effects of age, education level, and sex fitted with WLS estimation.\n\n\n\n\nThe WLS coefficient estimates, standard errors, and coefficient-level inference are presented below.\n\n# Examine coefficient-level output\ntidy(lm_step_5, conf.int = TRUE)"
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html",
    "href": "notes/07-diagnosing-collinearity.html",
    "title": "üìù Diagnosing Collinearity",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to empirical diagnostics to detect collinearity. We will use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")"
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#effects-of-collinearity",
    "href": "notes/07-diagnosing-collinearity.html#effects-of-collinearity",
    "title": "üìù Diagnosing Collinearity",
    "section": "Effects of Collinearity",
    "text": "Effects of Collinearity\nIf the design matrix is not of full rank, and \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) is singular, then the OLS normal equations do not have a unique solution. Moreover, the sampling variances for the coefficient are all infinitely large. To understand why this is the case, we can examine one formula for the sampling variance of a slope in a multiple regression:\n\\[\n\\mathrm{Var}(B_j) = \\frac{1}{1 - R^2_j} \\times \\frac{\\sigma^2_\\epsilon}{(n-1)S^2_j}\n\\]\nwhere\n\n\\(R^2_j\\) is the squared multiple correlation for the regression of \\(X_j\\) on the the other predictors;\n\\(S^2_j\\) is the sample variance of predictor \\(X_j\\) defined by \\(S^2_j = \\dfrac{\\sum(X_{ij}-\\bar{X}_j)^2}{n-1}\\);\n\\(\\sigma^2_{\\epsilon}\\) is the variance of the residuals based on regressing \\(Y\\) on all the \\(X\\)‚Äôs\n\n\nRecall that the multiple correlation is the correlation between the outcome and the predicted values.\n\nThe first term in this product is referred to as the variance inflation factor (VIF). When one of the predictors is perfectly collinear with the others, the value of \\(R^2_j\\) is 1 and the VIF is infinity. Thus the sampling variance of \\(B_j=\\infty\\)."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#perfect-collinearity-in-practice-model-mis-specification",
    "href": "notes/07-diagnosing-collinearity.html#perfect-collinearity-in-practice-model-mis-specification",
    "title": "üìù Diagnosing Collinearity",
    "section": "Perfect Collinearity in Practice: Model Mis-specification",
    "text": "Perfect Collinearity in Practice: Model Mis-specification\nIn practice, it is unlikely that you will have exact (or perfect) collinearity. When it does happen it is often the result of mis-formulating the model (e.g., including dummy variables in the model for all levels of a categorical variable, as well as the intercept). As an example of this, imagine that you were creating the design matrix for a regression model that included occupational status (employed/not employed) to predict some outcome for 5 cases.\n\n# Create design matrix\nX = data.frame(\n  b_0 = rep(1, 5),\n  employed = c(1, 1, 0, 0, 1),\n  not_employed = c(0, 0, 1, 1, 0)\n)\n\n# View design matrix\nX\n\n\n\n  \n\n\n\nThe columns in this design matrix are collinear because we can express any one of the columns as a linear combination of the others. For example,\n\\[\nb_0 = 1(\\mathrm{employed}) + 1(\\mathrm{not~employed})\n\\]\nChecking the rank of this matrix, we find that this matrix has a rank of 2. Since there are three columns, X is not full column rank; it is rank deficient.\n\nMatrix::rankMatrix(X)\n\n[1] 2\nattr(,\"method\")\n[1] \"tolNorm2\"\nattr(,\"useGrad\")\n[1] FALSE\nattr(,\"tol\")\n[1] 1.110223e-15\n\n\nIncluding all three coefficients in the model results in overparameterization. The simple solution here is to drop one of the predictors from the model. This is why we only include a single dummy variable in a model that includes an intercept for a dichotomous categorical predictor.\n\nIncluding the intercept is not imperative, although it has a useful interpretation when using dummy coding. One could also include the two dummy-coded predictors and omit the intercept. This gives the means for the two groups, but does not provide a comparison of those means.\n\n\n# Create vector of outcomes\nY = c(15, 15, 10, 15, 30)\n\n# Create data frame of Y and X\nmy_data = cbind(Y, X)\nmy_data\n\n\n\n  \n\n\n# Coefficients (including all three terms)\ncoef(lm(Y ~ 1 + employed + not_employed, data = my_data))\n\n (Intercept)     employed not_employed \n        12.5          7.5           NA \n\n# Coefficients (omitting intercept)\ncoef(lm(Y ~ -1 + employed + not_employed, data = my_data))\n\n    employed not_employed \n        20.0         12.5 \n\n\nIf you overparameterize a model with lm(), one or more of the coefficients will not be estimated (the last parameters entered in the model).\n\nConstraining some parameters is another way to produce a full rank design matrix. For example the ANOVA model has a constraint that the sum of the effect-coded variable is 0. This constraint ensures that the design matrix will be of full rank."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#non-exact-collinearity",
    "href": "notes/07-diagnosing-collinearity.html#non-exact-collinearity",
    "title": "üìù Diagnosing Collinearity",
    "section": "Non-Exact Collinearity",
    "text": "Non-Exact Collinearity\nIt is more likely, in practice, that you will have less-than-perfect collinearity, and that this will have an adverse effect on the computational estimates of the coefficients‚Äô sampling variances. Again, we look toward how the sampling variances for the coefficent‚Äôs are computed:\n\\[\n\\mathrm{Var}(B_j) = \\frac{1}{1 - R^2_j} \\times \\frac{\\sigma^2_\\epsilon}{(n-1)S^2_j}\n\\]\nWhen the predictors are completely independent, all of the columns of the design matrix will be orthogonal and the correlation between \\(X_j\\) and the other \\(X\\)s will be 0. In this situation, the VIF is 1 and the second term in the product completely defines the sampling variance. This means that the sampling variance is a function of the model‚Äôs residual variance, sample size, and the predictor‚Äôs variance‚Äîthe factors we typically think of affecting the sampling variance of a coefficient.\nIn cases where the columns in ths design matrix are not perfectly orthogonal, the correlation between \\(X_j\\) and the other \\(X\\)s is larger than 0. (Perfect collinearity results in \\(R^2_j=1\\).) For these situations, the VIF has a value that is greater than 1. When this happens the VIF acts as a multiplier of the second term, inflating the the sampling variance and reducing the precision of the estimate (i.e., increasing the uncertainty).\nHow much the uncertainty in the estimate increases is a function of how correlated the predictors are. Here we can look at various multiple correlations (\\(R_j\\)) between \\(X_j\\) and the predicted values from using the other \\(X\\)‚Äôs to predict \\(X_j\\).\n\n\n\nImpact of various Rj values on the VIF and size of the CI for Bj.\n\n\nRj\nVIF\nCI Factor\n\n\n\n\n0.0\n1.00\n1.00\n\n\n0.1\n1.01\n1.01\n\n\n0.2\n1.04\n1.02\n\n\n0.3\n1.10\n1.05\n\n\n0.4\n1.19\n1.09\n\n\n0.5\n1.33\n1.15\n\n\n0.6\n1.56\n1.25\n\n\n0.7\n1.96\n1.40\n\n\n0.8\n2.78\n1.67\n\n\n0.9\n5.26\n2.29\n\n\n1.0\nInf\nInf\n\n\n\n\n\n\n\nFor example, a multiple correlation of 0.7 results in a VIF of 1.96, which in turn means that the CI (which is based on the square root of the sampling variance) will increase by a factor of 1.4. This inflation increases the uncertainty of the estimate making it harder to make decisions or understand the effect of \\(B_j\\).\nTo sum things up, while perfect collinearity is rare in practice, less-than-perfect collinearity is common. In these cases the VIF will be less than 1, but can still have an adverse effect on the sampling variances; sometimes making them quite large."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#collinearity-diagnostics",
    "href": "notes/07-diagnosing-collinearity.html#collinearity-diagnostics",
    "title": "üìù Diagnosing Collinearity",
    "section": "Collinearity Diagnostics",
    "text": "Collinearity Diagnostics\nWe can also empirically diagnose problematic collinearity in the data (D. A. Belsley, 1991; D. Belsley, Kuh, & Welsch, 1980). Before we do, however, it is important that the functional form of the model has been correctly specified. Since, a model needs to be specified before we can estimate coefficients or their sampling variances, and collinearity produces unstable estimates of these estimates, collinearity should only be investigated after the model has been satisfactorily specified.\nBelow we will explore some of the diagnostic tools available to an applied researcher."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#high-correlations-among-predictors",
    "href": "notes/07-diagnosing-collinearity.html#high-correlations-among-predictors",
    "title": "üìù Diagnosing Collinearity",
    "section": "High Correlations among Predictors",
    "text": "High Correlations among Predictors\nCollinearity can sometimes be anticipated by examining the pairwise correlations between the predictors. If the correlation between predictors is large, this might be indicative of collinearity problems.\n\neeo %&gt;%\n  select(faculty, peer, school) %&gt;%\n  correlate()\n\n\n\n  \n\n\n\nIn this example, all three of the predictors are highly correlated with one another. This is likely a good indicator that their may be problems in the estimation of coefficients, inflated standard errors, or both; especially given that the correlations are all very high. Unfortunately the source of collinearity may be due to more than just the simple relationships among the predictors. As such, just examining the pairwise correlations is not enough to detect collinearity (although it is a good first step)."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#regress-each-predictor-on-the-other-predictors",
    "href": "notes/07-diagnosing-collinearity.html#regress-each-predictor-on-the-other-predictors",
    "title": "üìù Diagnosing Collinearity",
    "section": "Regress each Predictor on the Other Predictors",
    "text": "Regress each Predictor on the Other Predictors\nSince collinearity is defined as linear dependence within the set of predictors, a better way to diagnose collinearity than just examining the pairwise correlation coefficients is to regress each of the predictors on the remaining predictors and evaluate the \\(R^2\\) value. If all the \\(R^2\\) values are close to zero there is no collinearity problems. If one or more of the \\(R^2\\) values are close to 1, there is a collinearity problem.\n\n# Use faculty as outcome; obtain R2\nsummary(lm(faculty ~ 1 + peer + school, data = eeo))$r.squared\n\n[1] 0.9733906\n\n# Use faculty as outcome; obtain R2\nsummary(lm(peer ~ 1 + faculty + school, data = eeo))$r.squared\n\n[1] 0.9669002\n\n# Use faculty as outcome; obtain R2\nsummary(lm(school ~ 1 + faculty + peer, data = eeo))$r.squared\n\n[1] 0.9879743\n\n\nAll three \\(R^2\\) values are quite high, which is indicative of collinearity.\nOne shortcoming with this method of diagnosing collinearity is that when the predictor space is large, you would need to look at the \\(R^2\\) values from several models. And, while this could be automated in an R function, there are other common methods that allow us to diagnose collinearity.\nWe will examine three additional common methods statisticians use to empirically detect collinearity: (1) computing variance inflation factors for the coefficients; (2) examining the eigenvalues of the correlation matrix; and (3) examining the condition indices of the correlation matrix."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#variance-inflation-factor-vif",
    "href": "notes/07-diagnosing-collinearity.html#variance-inflation-factor-vif",
    "title": "üìù Diagnosing Collinearity",
    "section": "Variance Inflation Factor (VIF)",
    "text": "Variance Inflation Factor (VIF)\nPerhaps the most common method applied statisticians use to diagnose collinaerity is to compute and examine variance inflation factors. Recall that the variance inflation factor (VIF) is an indicator of the degree of collinearity, where VIF is:\n\\[\n\\mathrm{VIF} = \\frac{1}{1 - R^2_j}\n\\]\nThe VIF impacts the size of the variance estimates for the regression coefficients, and as such, can be used as a diagnostic of collinearity. In practice, since it is more conventional to use the SE to measure uncertainty, it is typical to use the square root of the VIF as a diagnostic of collinearity in practice. The square root of the VIF expresses the proportional change in the CI for the coefficients. We can use the vif() function from the car package to compute the variance inflation factors for each coefficient.\n\n# VIF\nvif(lm.1)\n\n faculty     peer   school \n37.58064 30.21166 83.15544 \n\n# Square root of VIF\nsqrt(vif(lm.1))\n\n faculty     peer   school \n6.130305 5.496513 9.118960 \n\n\nThe variances (and hence, the standard errors) for all three coefficients are inflated because of collinearity. The SEs for these coefficients are all more than five times as large as they would be if the predictors were independent.\nRemember, the VIF can range from 1 (independence among the predictors) to infinity (perfect collinearity). There is not consensus among statisticians about how high the VIF has to be to constitute a problem. Some references cite \\(\\mathrm{VIF}&gt;10\\) as problematic (which increases the size of the CI for the coefficient by a factor of over three); while others cite \\(\\mathrm{VIF}&gt;4\\) as problematic (which increases the size of the CI for the coefficient by a factor of two). As you consider what VIF value to use as an indicator of problematic inflation, it is more important to consider what introducing that much uncertainty would mean in your substantive problem. For example, would you be comfortable with tripling the uncertainty associated with the coefficient? What about doubling it? Once you make that decision, you can determine your VIF cutoff.\nThere are several situations in which high VIF values are expected and not problematic:\n\nThe variables with high VIFs are control variables, and the variables of interest do not have high VIFs. Since we would not be interested in inference around the control variables, high VIF values on those variables would not\nThe high VIFs are caused by the inclusion of powers or products of other variables. The p-value for a product term is not affected by the multicollinearity. Centering predictors prior to creating the powers or the products will reduce the correlations, but the p-value the products will be exactly the same whether or not you center. Moreover the results for the other effects will be the same in either case indicating that multicollinearity has no adverse consequences.\nThe variables with high VIFs are indicator (dummy) variables that represent a categorical variable with three or more categories. This is especially true when the reference category used has a small proportion of cases. In this case, p-values for the indicator variables may be high, but the overall test that all indicators have coefficients of zero is unaffected by the high VIFs. And nothing else in the regression is affected. To avoid the high VIF values in this situaton, just choose a reference category with a larger proportion of cases."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#eigenvalues-of-the-correlation-matrix",
    "href": "notes/07-diagnosing-collinearity.html#eigenvalues-of-the-correlation-matrix",
    "title": "üìù Diagnosing Collinearity",
    "section": "Eigenvalues of the Correlation Matrix",
    "text": "Eigenvalues of the Correlation Matrix\nA second common method of evaluating collinearity is to compute and evaluate the eigenvalues of the correlation matrix for the predictors. Recall that each square (\\(k \\times k\\)) matrix has a set of k scalars, called eigenvalues (denoted \\(\\lambda\\)) associated with it. These eigenvalues can be arranged in descending order such that,\n\\[\n\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3 \\geq \\ldots \\geq \\lambda_k\n\\]\nBecause any correlation matrix is a square matrix, we can find a corresponding set of eigenvalues for the correlation matrix. If any of these eigenvalues is exactly equal to zero, it indicates a linear dependence among the variables making up the correlation matrix.\nAs a diagnostic, rather than looking at the size of all the eigenvalues, we compute the sum of the reciprocals of the eigenvalues:\n\\[\n\\sum_{i=1}^k \\frac{1}{\\lambda_i}\n\\]\n\nIf the predictors are orthogonal to one another (independent) then \\(\\lambda_i = 1\\) and the sum of the reciprocal values will be equal to the number of predictors, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} = k\\).\nIf the predictors are collinear with one another (dependent) then \\(\\lambda_i = 0\\) and the sum of the reciprocal values will be equal to infinity, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} = \\infty\\).\nWhen there is nonperfect collinearity then \\(0 &lt; \\lambda_i &lt; 1\\), and the sum of the reciprocal values will be greater than the number of predictors, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} &gt; k\\).\n\n\nIn an orthogonal matrix, the eigenvalues are all \\(\\pm1\\), but since the correlation matrix is positive semidefinite, the eigenvalues are all \\(+1\\).\n\nLarger sums of the reciprocal values of the eigenvalues is indicative of higher degrees of collinearity. In practice, we might use some cutoff to indicate when the collinearity is problematic. One such cutoff used is, if the sum is greater than five times the number of predictors, it is a sign of collinearity.\n\\[\n\\mathrm{IF} \\quad \\sum_{i=1}^k \\frac{1}{\\lambda_i} &gt; 5k \\quad \\mathrm{THEN} \\quad \\mathrm{collnearity~is~a~problem}\n\\]\n\n\nIn practice, perfect collinearity is rare, but near perfect collinearity can exist and is indicated when at least one of the eigenvalues is near zero, and is quite a bit smaller than the others.\n\n\n\nUsing R to Compute the Eigenvalues of the Correlation Matrix\nBecause collinearity indicates dependence among the predictors, we would want to compute the eigenvalues for the correlation matrix of the predictors (do not include the outcome when computing this matrix). We can then use the eigen() function to compute the eigenvalues of a square matrix.\nIn previous classes, I have been using the correlate() function from the {corrr} package to produce correlation matrices. This function produces a formatted output that is nice for displaying the correlation matrix, but, because of its formatting, is not truly a matrix object. Instead, we will use the cor() function, which produces a matrix object, to produce the correlation matrix.\n\n# Correlation matrix of predictors\nr_xx = cor(eeo[c(\"faculty\", \"peer\", \"school\")])\nr_xx\n\n          faculty      peer    school\nfaculty 1.0000000 0.9600806 0.9856837\npeer    0.9600806 1.0000000 0.9821601\nschool  0.9856837 0.9821601 1.0000000\n\n\nOnce we have the correlation matrix, we can use the eigen() function to compute the eigenvalues (and eigenvectors) of the inputted correlation matrix.\n\n# Compute eigenvalues and eigenvectors\neigen(r_xx)\n\neigen() decomposition\n$values\n[1] 2.951993158 0.040047507 0.007959335\n\n$vectors\n           [,1]        [,2]       [,3]\n[1,] -0.5761385  0.67939712 -0.4544052\n[2,] -0.5754361 -0.73197527 -0.3648089\n[3,] -0.5804634  0.05130072  0.8126687\n\n# Sum of reciprocal of eigenvalues\nsum(1 / eigen(r_xx)$values)\n\n[1] 150.9477\n\n\nWe compare the sum of the reciprocal of the eigenvalues to five times the number of predictors; \\(5 \\times 3 =15\\). Since this sum is greater than 15, we would conclude that there is a collinearity problem for this model."
  },
  {
    "objectID": "notes/07-diagnosing-collinearity.html#condition-indices",
    "href": "notes/07-diagnosing-collinearity.html#condition-indices",
    "title": "üìù Diagnosing Collinearity",
    "section": "Condition Indices",
    "text": "Condition Indices\nA condition number for a matrix and computational task quantifies how sensitive the result is to perturbations in the input data and to roundoff errors made during the solution process. If minor changes to the matrix elements result in large differences in the computation (say of the inverse), we say that the matrix is ‚Äúill-conditioned‚Äù. It is important to note that a condition number applies not only to a particular matrix, but also to the particular computation being carried out. That is, a matrix can be ill-conditioned for inversion while the eigenvalue problem is well-conditioned.\nA third common diagnostic measure of collinearity is to compute the condition number of the correlation matrix of the model predictors. This tells us whether small changes in the data will lead to large changes in regression coefficient estimates. To compute the condition number, we need to compute the condition index for each of the eigenvalues of the correlation matrix based on the model predictors. Each eigenvalue has an associated condition index, and the jth eigenvalue‚Äôs condition index is denoted \\(\\kappa_j\\), where,\n\\[\n\\kappa_j = \\sqrt{\\frac{\\lambda_{\\mathrm{Max}}}{\\lambda_j}}\n\\]\nand \\(\\lambda_{\\mathrm{Max}}\\) is the largest eigenvalue. The largest eigenvalue will have a condition index of,\n\\[\n\\begin{split}\n\\kappa_{\\lambda_\\mathrm{Max}} &= \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Max}}} \\\\[1ex]\n&= 1\n\\end{split}\n\\]\nThe smallest eigenvalue will have a condition index of\n\\[\n\\kappa_{\\lambda_\\mathrm{Min}} = \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}}\n\\]\nThis value will be larger than 1 since \\(\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}\\) will be greater than 1. In general, the largest eigenvalue will have a condition index of 1 and the other condition indices for every other eigenvalue will be larger than one.\nThe condition number of the correlation matrix is equivalent to the condition index for the smallest eigenvalue, that is,\n\\[\n\\kappa = \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}}\n\\]\nIf the condition number is small, it indicates that the predictors are not collinear, whereas large condition numbers are evidence supporting collinearity.\nFrom empirical work, a condition number between 10 and 30 indicates the presence of multicollinearity. When the condition number is larger than 30, the multicollinearity is regarded as strong and corrective action will almost surely need to be taken. Below we compute the condition indices and the condition number for our empirical example.\n\n# Sort eigenvalues from largest to smallest\nlambda = sort(eigen(r_xx)$values, decreasing = TRUE)\n\n# View eigenvalues\nlambda\n\n[1] 2.951993158 0.040047507 0.007959335\n\n# Compute condition indices\nsqrt(max(lambda) / lambda)\n\n[1]  1.000000  8.585586 19.258359\n\n# Compute condition number directly\nsqrt(max(lambda) / min(lambda))\n\n[1] 19.25836\n\n\nThe condition number of the correlation matrix, \\(\\kappa = 19.26\\), suggests there is collinearity among the predictors."
  },
  {
    "objectID": "notes/08-pca-via-spectral-decomposition.html",
    "href": "notes/08-pca-via-spectral-decomposition.html",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to principal components analysis via spectral decomposition. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")\nThe problem we faced from the last set of notes, was that the predictors in the model were collinear, so we encountered computational issues when trying to estimate the effects and standard errors. One method to deal with collinearity among a set of predictors is to combine the predictors into a smaller subset of orthogonal measures (called principal components) that can be used instead of the original predictors. This subset of measures will not have the collinearity problems (they are orthogonal to one another), but constitute a slightly smaller amount of ‚Äúvariance accounted for‚Äù than the original set of predictors."
  },
  {
    "objectID": "notes/08-pca-via-spectral-decomposition.html#matrix-algebra-to-carry-out-the-pca-using-spectral-decomposition",
    "href": "notes/08-pca-via-spectral-decomposition.html#matrix-algebra-to-carry-out-the-pca-using-spectral-decomposition",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "Matrix Algebra to Carry Out the PCA using Spectral Decomposition",
    "text": "Matrix Algebra to Carry Out the PCA using Spectral Decomposition\nTo carry out the spectral decomposition in R, we need to create the matrix of the predictors (\\(\\mathbf{X}_p\\)), compute the \\(\\mathbf{X}_p^\\intercal\\mathbf{X}_p = \\mathbf{PDP}^\\intercal\\) matrix, and then use the eigen() function to carry out the spectral decomposition.\n\n# Create predictor matrix\nX_p = eeo %&gt;%\n  select(peer, faculty) %&gt;%\n  data.matrix()\n\n# Spectral decomposition\nspec_decomp = eigen(t(X_p) %*% X_p)\nspec_decomp\n\neigen() decomposition\n$values\n[1] 137.561000   2.724415\n\n$vectors\n          [,1]       [,2]\n[1,] 0.6469680 -0.7625172\n[2,] 0.7625172  0.6469680\n\n\nThe matrix of eigenvectors, in the $vectors component, compose the P matrix and make up the set of basis vectors for the rotated predictor space. The elements in the $values component are the diagonal elements in D and are the eigenvalues. The decomposition is:\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_p\\mathbf{X}_p &= \\mathbf{PDP}^\\intercal \\\\[1em]\n\\begin{bmatrix}59.16 & 66.52 \\\\ 66.62 & 81.12\\end{bmatrix} &= \\begin{bmatrix}0.647 & -0.763 \\\\ 0.762 & 0.647\\end{bmatrix} \\begin{bmatrix}137.561 & 0  \\\\ 0 & 2.724 \\end{bmatrix} \\begin{bmatrix}0.647 & -0.763 \\\\ 0.762 & 0.647\\end{bmatrix}^\\intercal\n\\end{split}\n\\]\nThe span of the basis vectors define the principal components, with the first eigenvector defining the first principal component and the second eigenvector defining the second principal component. (Note: There number of principal components will always be the same as the number of predictors in the \\(\\mathbf{X}_p\\) matrix.)\nWe can post-multiply the matrix of the original predictor values (in \\(\\mathbf{X}_p\\)) by this matrix of basis vectors to obtain the predictor values in the rotated space.\n\n# Matrix of basis vectors for rotated predictor space\nrot_basis = spec_decomp$vectors\n\n# Compute rotated values under the new basis\nrot_pred = X_p %*% rot_basis\nhead(rot_pred)\n\n            [,1]        [,2]\n[1,]  0.48641930  0.36669037\n[2,]  0.91525519  0.14806327\n[3,] -1.03087107 -0.06220262\n[4,] -1.74270855  0.11707722\n[5,]  0.01287131  0.25376126\n[6,]  0.23695822  0.03365744\n\n\nFor example, the first observation, has a value of 0.486 on the first principal component and a value of 0.367 on the second principal component. Similarly, the second observation has a value of 0.915 on the first principal component and a value of 0.148 on the second principal component. Each observation has a set of values on the principal components.\nThe eigenvalues are related to the variances of the principal components. Because we decomposed the \\(\\mathbf{X}_p^\\intercal\\mathbf{X}_p = \\mathbf{PDP}^\\intercal\\) matrix, the variance on each prinicpal component can be computed as:\n\\[\n\\mathrm{Var}(\\mathrm{PC}_i) = \\frac{\\lambda_i}{n-1}\n\\]\nIn our example, the variances can be computed as:\n\n# Compute variances of PCs\nvar_pc = spec_decomp$values / (70 - 1)\nvar_pc\n\n[1] 1.99363769 0.03948427\n\n\nThe first principal component has the largest variance, which will always be the case. Remember, the principal components are selected so the first component maximizes the variation in the predictor space, the second component will maximize the remaining variance (and be orthogonal to the first), etc.\nWe can use these variances to determine the proportion of variation in the predictor space that each principal component accounts for. This is often more useful to the applied data analyst than the actual variance measure itself. Since the principal components are orthogonal, we can sum the variances to obtain a total measure of variation in the original set of predictors accounted for by the principal components. Below, we compute the proportion of variance in the predictor space that each principal component in our example accounts for:\n\n# Compute proportion of variation\nvar_pc / sum(var_pc)\n\n[1] 0.98057949 0.01942051\n\n\nHere the first principal component accounts for 98.1% of the variation in the predictor space, and the second principal component accounts for the remaining 1.9% of the variation."
  },
  {
    "objectID": "notes/08-pca-via-spectral-decomposition.html#using-princomp-to-obtain-the-principal-components",
    "href": "notes/08-pca-via-spectral-decomposition.html#using-princomp-to-obtain-the-principal-components",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "Using princomp() to Obtain the Principal Components",
    "text": "Using princomp() to Obtain the Principal Components\nWe can also use the R function princomp() to obtain the principal components based on the spectral decomposition. We provide this function with a data frame of the predictors.\n\n# Select predictors\neeo_pred = eeo %&gt;%\n  select(faculty, peer)\n\n# Create princomp object\nmy_pca = princomp(eeo_pred)\n\n# View output\nsummary(my_pca, loadings = TRUE)\n\nImportance of components:\n                          Comp.1     Comp.2\nStandard deviation     1.4002088 0.19725327\nProportion of Variance 0.9805406 0.01945935\nCumulative Proportion  0.9805406 1.00000000\n\nLoadings:\n        Comp.1 Comp.2\nfaculty  0.763  0.647\npeer     0.647 -0.763\n\n\nThe values of the principal components, the rotated set of basis vectors, are given in the loadings output. Note that the signs of the principal components are arbitrary. For example, the vector associated with the first principal component could also have been \\((-0.763, -0.647)\\) and that for the second principal component could have been \\((-0.647, 0.763)\\). The variances of each component can be computed by squaring the appropriate standard deviations in the output.\n\n# Compute variance of PC1\n1.4002088 ^ 2\n\n[1] 1.960585\n\n# Compute variance of PC2\n0.19725327 ^ 2\n\n[1] 0.03890885\n\n\nWe can use the variance measures to obtain a total measure of variation in the original set of predictors accounted for by each of the principal components.\n\n# Compute total variation accounted for\ntotal_var = 1.4002088 ^ 2 + 0.19725327 ^ 2\ntotal_var\n\n[1] 1.999494\n\n# Compute variation accounted for by PC1\n(1.4002088 ^ 2) / total_var\n\n[1] 0.9805406\n\n# Compute variation accounted for by PC2\n(0.19725327 ^ 2) / total_var\n\n[1] 0.01945935\n\n\nThis suggests that the first principal component accounts for 98% of the variance in the original set of predictors and that the second principal component accounts for 2% of the variance. (Same as we computed in the matrix algebra.) Note that these values are also given in the summary() output.\nWe can also obtain the principal component scores (the values under the rotation) for each observation by accessing the scores element of the princomp object. (Below we only show the first six scores.)\n\n# Get PC scores\npc_scores = my_pca$scores\n\n# View PC scores\nhead(pc_scores)\n\n          Comp.1      Comp.2\n[1,]  0.41884376  0.37000669\n[2,]  0.84765375  0.15132881\n[3,] -1.09849740 -0.05870659\n[4,] -1.81031365  0.12065755\n[5,] -0.05471761  0.25713367\n[6,]  0.16934323  0.03700331\n\n\nThese are slightly different than the scores we obtained by multiplying the original predictor values by the new basis matrix. For example, the PC scores for the first observation were \\(-0.486\\) and \\(0.367\\). The princomp() function mean centers each variable prior to multiplying by the basis matrix.\n\n# Mimic scores from princomp()\nold = t(c(0.608 - mean(eeo$faculty), 0.0351 - mean(eeo$peer)))\n\n# Compute PC scores\nold %*% basis\n\n          [,1]      [,2]\n[1,] 0.4186997 0.3699581\n\n\n\nBecause we want the principal components to be solely functions of the predictors, we mean center them. Otherwise we would have to include a column of ones (intercept) in the \\(\\mathbf{X}_p\\) matrix. Mean centering the predictors makes each predictor orthogonal to the intercept, in which case it can be ignored. (This is similar to how mean centering predictors removes the intercept from the fitted equation.)\n\nSince we only have two principal components, we can visualize the scores using a scatterplot.\n\n# Create data frame of scores\npc_scores = pc_scores %&gt;%\n  data.frame()\n\n# Plot the scores\nggplot(data = pc_scores, aes(x = Comp.1, y = Comp.2)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"lightgrey\") +\n  geom_vline(xintercept = 0, color = \"lightgrey\") +\n  scale_x_continuous(name = \"Principal Component 1\", limits = c(-4, 4)) +\n  scale_y_continuous(name = \"Principal Component 2\", limits = c(-4, 4)) +\n  theme_bw() +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nRotated predictor space using the principal components as the new basis.\n\n\n\n\nConceptually this visualization shows the rotated predictor space after re-orienting the rotated coordinate system. From this visualization, it is also clear that there is much more variation in the values of the first principal component than in the second principal component."
  },
  {
    "objectID": "notes/09-pca-via-svd.html",
    "href": "notes/09-pca-via-svd.html",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to principal components analysis via singular value decomposition. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")"
  },
  {
    "objectID": "notes/09-pca-via-svd.html#pca-using-svd-matrix-algebra",
    "href": "notes/09-pca-via-svd.html#pca-using-svd-matrix-algebra",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "PCA using SVD: Matrix Algebra",
    "text": "PCA using SVD: Matrix Algebra\nTo carry out a principal components analysis, we need to use SVD to decompose the matrix \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\), where \\(\\mathbf{X}_{\\mathrm{Predictor}}\\) is a matrix of the predictors being used in the PCA. Below, we create the \\(\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix we use the svd() function to decompose the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix using singular value decomposition.\n\n# Create matrix of predictors\nX_p = as.matrix(eeo[ , c(\"faculty\", \"peer\", \"school\")])\n\n# SVD decomposition\nsv_decomp = svd(t(X_p) %*% X_p)\n\n# View results\nsv_decomp\n\n$d\n[1] 209.3295610   2.7303093   0.5833274\n\n$u\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n\n$v\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n\n\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[1em]\n\\begin{bmatrix}81.123 & 66.518 & 75.512 \\\\ 66.518 & 59.163 & 64.251 \\\\ 75.512 & 64.251 & 72.358\\end{bmatrix} &= \\begin{bmatrix}0.617 & 0.670 & -0.412 \\\\ -0.524 & -0.741 & -0.419 \\\\ -0.586 & -0.042 & 0.809\\end{bmatrix} \\begin{bmatrix}209.330 & 0 & 0 \\\\ 0 & 2.730 & 0 \\\\ 0 & 0 & 0.583 \\end{bmatrix} \\begin{bmatrix}-0.617 & -0.524 & -0.586 \\\\ 0.670 & -0.741 & -0.042 \\\\ -0.412 & -0.419 &  0.809 \\end{bmatrix}\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/09-pca-via-svd.html#understanding-what-the-matrix-algebra-is-doing",
    "href": "notes/09-pca-via-svd.html#understanding-what-the-matrix-algebra-is-doing",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Understanding What the Matrix Algebra is Doing",
    "text": "Understanding What the Matrix Algebra is Doing\nMathematically, since any matrix can be decomposed using SVD, we can also decompose \\(\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\\). Then we can write the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix, \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\), as:\n\\[\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})^{\\intercal} (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})\n\\]\nRe-expressing this we get:\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{V}\\mathbf{D}^{\\intercal}\\mathbf{U}^{\\intercal}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[0.5em]\n\\end{split}\n\\]\nSince D is a diagonal matrix, \\(\\mathbf{D}^{\\intercal}\\mathbf{D} = \\mathbf{D}^2\\), so reducing this expression gives:\n\\[\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{V}\\mathbf{D}^2\\mathbf{V}^{\\intercal}\n\\]\nThe matrices V and \\(\\mathbf{V}^{\\intercal}\\) are both orthogonal basis matrices that ultimately act to change the coordinate system by rotating the original basis vectors used in the predictor space. The \\(\\mathbf{D}^2\\) matrix is diagonalizing the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix which amounts to finding the the major axes in the data ellipse along which our data varies."
  },
  {
    "objectID": "notes/09-pca-via-svd.html#scaling-the-predictors",
    "href": "notes/09-pca-via-svd.html#scaling-the-predictors",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Scaling the Predictors",
    "text": "Scaling the Predictors\nIn practice, it is important to scale all the predictors used in the PCA. This is especially true when the variables are measured in different metrics or have varying degrees of magnitude. In these cases, not scaling the predictors will often result in results in which variables with large magnitudes of scale dominate the PCA. It also is helpful when the predictors are measured using qualitatively different scales (e.g., one is measured in dollars and another in years of education).\n\nRecall, the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix for a set of standardized predictors his the correlation matrix of the predictors. Thus, the SVD is actually being carried out on the correlation matrix rather than the raw \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix.\n\nWhile it isn‚Äôt necessary to also center the predictors, it is common to simply standardize the set of predictors being used in the PCA (i.e., convert them to z-scores); thus both centering and scaling them. To do this, we will pipe the selected predictors into the scale() function prior to piping into the prcomp() function.\n\n# Fit the PCA using SVD decomposition on standardized predictors\nsvd_pca_z = eeo |&gt;\n  select(faculty, peer, school) |&gt;\n  scale(center = TRUE, scale = TRUE) |&gt;\n  prcomp()\n\n# View standard deviations and rotation matrix (eigenvector matrix)\nsvd_pca_z\n\nStandard deviations (1, .., p=3):\n[1] 1.71813654 0.20011873 0.08921511\n\nRotation (n x k) = (3 x 3):\n               PC1         PC2        PC3\nfaculty -0.5761385  0.67939712 -0.4544052\npeer    -0.5754361 -0.73197527 -0.3648089\nschool  -0.5804634  0.05130072  0.8126687\n\n# tidy version of the rotation matrix (good for graphing)\nsvd_pca_z |&gt;\n  tidy(matrix = \"rotation\")\n\n\n\n  \n\n\n# View sds, variance accounted for\nsvd_pca_z |&gt;\n  tidy(matrix = \"eigenvalues\")\n\n\n\n  \n\n\n# Obtain PC scores\npc_scores = augment(svd_pca_z)\npc_scores\n\n\n\n  \n\n\n\nHere the results from using the standardized predictors are not that different from the previous results since the variables were already reported as z-scores to begin with. The variance accounted for by the principal components is comparable (within rounding); the standardization of the predictors does not change this. The actual principal components in the V (rotation) matrix are different because of the centering and scaling, but the interpretations are the same as when we used the decomposition based on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix. Similarly, because of the centering and scaling, the PC scores are different."
  },
  {
    "objectID": "notes/09-pca-via-svd.html#behind-the-scenes",
    "href": "notes/09-pca-via-svd.html#behind-the-scenes",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Behind the Scenes",
    "text": "Behind the Scenes\nBy standardizing the predictors, we are carrying out the SVD on the correlation matrix of the predictors rather than on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix. To see this, recall that the correlation matrix of the predictors (\\(\\mathbf{R_X}\\)) is based on the standardized predictors, namely,\n\nThis implies that you can also carry out PCA on summaries of the predictors (rather than the raw data) by decomposing either the covariance matrix of the predictors or the correlation matrix of the predictors. This can be useful for example, when trying to reproduce the results of a PCA from a published paper, in which authors will often report summaries of the data used (e.g., correlation matrices) but not the raw data.\n\n\\[\n\\mathbf{R_X} = \\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big)\n\\]\nThe \\(1/(n-1)\\) component is a scalar and is pulled out so that the decomposition is carried out on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\) matrix:\n\\[\n\\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big) = \\frac{1}{n-1}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\n\\]\nSimilarly, we can also decompose the covariance matrix of the predictors (\\(\\boldsymbol\\Sigma_{\\mathbf{X}}\\)), which is based on the centered predictors,\n\\[\n\\boldsymbol\\Sigma_{\\mathbf{X}} = \\frac{1}{n-1} \\big( \\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}\\big)\n\\]\nIn this case, the decomposition is carried out on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}\\) matrix. To do this using prcomp() we would change the scale= argument to FALSE in the scale() function, while still leaving center=TRUE."
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html",
    "href": "notes/10-biased-estimation-ridge-regression.html",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to ridge regression. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nAny table is essentially a rectangular layout (rows and columns) of information. Below I show two common tables of statistical output. I have also added guide-lines to show the rectangular display of information within each of these tables.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(MASS)\nlibrary(tidyverse)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)"
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#matrix-formulation-of-ridge-regression",
    "href": "notes/10-biased-estimation-ridge-regression.html#matrix-formulation-of-ridge-regression",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Matrix Formulation of Ridge Regression",
    "text": "Matrix Formulation of Ridge Regression\nRecall that the OLS estimates are given by:\n\\[\n\\mathbf{b} = (\\mathbf{X}^{\\intercal}\\mathbf{X})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{y}\n\\]\nUnder collinearity, the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix is ill-conditioned. (A matrix is said to be ill-conditioned if it has a high condition number, meaning that small changes in the data impact the regression results. This ill-conditioning results in inaccuracy when we compute the inverse of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix, which translates into bad estimates of the coefficients and standard errors.\nTo see this, consider our EEO example data. We first standardize the variables (so we can omit the ones column in the design matrix) using the scale() function. Note that the output of the scale() function is a matrix. Then, we will select the predictors using indexing and compute the condition number for the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix.\n\n# Standardize all variables in the eeo data frame\nz_eeo = eeo %&gt;% \n  scale()\n\n# Create and view the design matrix\nX = z_eeo[ , c(\"faculty\", \"peer\", \"school\")]\nhead(X)\n\n        faculty        peer     school\n[1,]  0.5158617 -0.01213684  0.1310782\n[2,]  0.6871673  0.46812962  0.4901170\n[3,] -0.8084583 -0.71996624 -0.7994390\n[4,] -1.2024935 -1.36577136 -1.0479983\n[5,]  0.1150408 -0.25030749  0.1078451\n[6,]  0.1413252  0.08793894  0.2356566\n\n# Get eigenvalues\neig_val = eigen(t(X) %*% X)$values\n\n# Compute condition number\nsqrt(max(eig_val) / min(eig_val))\n\n[1] 19.25836\n\n\nWe can inflate the diagonal elements of \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) to better condition the matrix. This, hopefully, leads to more stability in the inverse matrix and produces better (albeit biased) coefficient estimates. To do this, we can add some constant amount (\\(\\lambda\\)) to each of the diagonal elements of \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\), prior to finding the inverse. This can be expressed as:\n\\[\n\\widetilde{\\mathbf{b}} = (\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{Y}\n\\]\nwhere the tilde over b indicates that the coefficients are biased. To see how increasing the diagonal values leads to better conditioning, we will add some value (here \\(\\lambda=10\\), but it could be any value between 0 and positive infinity) to each diagonal element of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix in our example.\n\nTechnically this equation is for standardized variables; it assumes that there is no ones column in the X matrix. This is because we only want to add the \\(\\lambda\\) value to the parts of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix associated with the predictors.\n\n\n# Add 50 to each of the diagonal elements of X^T(X)\ninflated = t(X) %*% X + 10*diag(3)\n\n# Get eigenvalues\neig_val_inflated = eigen(inflated)$values\n\n# Compute condition number\nsqrt(max(eig_val_inflated) / min(eig_val_inflated))\n\n[1] 4.500699\n\n\nThe condition number has decreased from 19.26 (problematic collinearity) to 4.5 (non-collinear). Adding 10 to each diagonal element of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix resulted in a better conditioned matrix!"
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#using-an-built-in-r-function",
    "href": "notes/10-biased-estimation-ridge-regression.html#using-an-built-in-r-function",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Using an Built-In R Function",
    "text": "Using an Built-In R Function\nWe can also use the lm.ridge() function from the {MASS} package to fit a ridge regression. This function uses a formula based on variables from a data frame in the same fashion as the lm() function. It also takes the argument lambda= which specifies the values of \\(\\lambda\\) to use in the penalty term. Because the data= argument has to be a data frame (or tibble), we convert the standardized data (which is a matrix) to a data frame using the data.frame() function.\n\n# Create data frame for use in lm.ridge()\nz_data = z_eeo %&gt;%\n  data.frame()\n\n# Fit ridge regression (lambda = 0.1)\nridge_1 = lm.ridge(achievement ~ -1 + faculty + peer + school, data = z_data, lambda = 0.1)\n\n# View coefficients\ntidy(ridge_1)"
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#comparison-to-the-ols-coefficients",
    "href": "notes/10-biased-estimation-ridge-regression.html#comparison-to-the-ols-coefficients",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Comparison to the OLS Coefficients",
    "text": "Comparison to the OLS Coefficients\nHow do these biased coefficients from the ridge regression compare to the unbiased coefficients from the OLS estimation? Below, we fit a standardized OLS model to the data, and compare the coefficients to those from the ridge regression with \\(\\lambda=0.1\\).\n\n# Fit standardized OLS model\nlm.1 = lm(achievement ~ faculty + peer + school - 1, data = z_data)\n\n# Obtain coefficients\ncoef(lm.1)\n\n   faculty       peer     school \n 0.5248647  0.9449056 -1.0272986 \n\n\nComparing these coefficients from the different models:\n\n\n\nComparison of the coefficients from the OLS (Œª=0) and the ridge regression using Œª=0.1 based on the standardized data.\n\n\nPredictor\nŒª=0\nŒª=0.1\n\n\n\n\nFaculty\n0.525\n0.436\n\n\nPeer\n0.945\n0.856\n\n\nSchool\n-1.027\n-0.851\n\n\n\n\n\n\n\nBased on this comparison, the ridge regression has ‚Äúshrunk‚Äù the estimate of each coefficient toward zero. Remember, the larger the value of \\(\\lambda\\), the more the coefficient estimates will shrink toward 0. The table below shows the coefficient estimates for four different values of \\(\\lambda\\).\n\n\n\nComparison of the coefficients from the OLS (Œª=0) and three ridge regressions (using Œª=0.1, Œª=1, and Œª=10) based on the standardized data. The condition numbers for the XTX + ŒªI matrix are also provided.\n\n\nPredictor\n&lambda;=0\n&lambda;=0.1\n&lambda;=1\n&lambda;=10\n\n\n\n\nFaculty\n0.525\n0.436\n0.180\n0.114\n\n\nPeer\n0.945\n0.856\n0.537\n0.227\n\n\nSchool\n-1.027\n-0.851\n-0.283\n0.073\n\n\nCondition Number\n370.884\n313.908\n132.125\n20.256\n\n\n\n\n\n\n\nExamining these results we see that increasing the penalty (i.e., higher \\(\\lambda\\) values) better conditions the \\(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I}\\) matrix, but a higher penalty also shrinks the estimates toward zero more (increased bias). This implies that we want a \\(\\lambda\\) that is large enough so that it conditions the \\(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I}\\) matrix, but not too large because we want to introduce the least amount of bias as possible."
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#ridge-trace",
    "href": "notes/10-biased-estimation-ridge-regression.html#ridge-trace",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Ridge Trace",
    "text": "Ridge Trace\nA ridge trace computes the ridge regression coefficients for many different values of \\(\\lambda\\). A plot of this trace, can be examined to select the \\(\\lambda\\) value. To do this, we pick the smallest value for \\(\\lambda\\) that produces stable regression coefficients. Here we examine the values of \\(\\lambda\\) where \\(\\lambda = \\{ 0,0.001,0.002,0.003,\\ldots,100\\}\\).\nTo create this plot, we fit a ridge regression that includes a sequence of values in the lambda= argument of the lm.ridge() function. Then we use the tidy() function to summarize the output from this model. This output includes the coefficient estimates for each of the \\(\\lambda\\) values in our sequence. We can then create a line plot of the coefficient values versus the \\(\\lambda\\) values for each predictor.\n\n# Fit ridge model across several lambda values\nridge_models = lm.ridge(achievement ~ -1 + faculty + peer + school, data = z_data, \n                        lambda = seq(from = 0, to = 100, by = 0.01))\n\n# Get tidy() output\nridge_trace = tidy(ridge_models)\nridge_trace\n\n\n\n\n\nRidge plot showing the size of the standardized regression coefficients for \\(\\lambda\\) values between 0 (OLS) and 100.\n\n# Ridge trace\nggplot(data = ridge_trace, aes(x = lambda, y = estimate)) +\n  geom_line(aes(group = term, color = term)) +\n  theme_bw() +\n  xlab(expression(lambda)) +\n  ylab(\"Coefficient estimate\") +\n  ggsci::scale_color_d3(name = \"Predictor\")\n\n\n\n\nRidge plot showing the size of the standardized regression coefficients for \\(\\lambda\\) values between 0 (OLS) and 100.\n\n\n\n\nWe want to find the \\(\\lambda\\) value where the lines begin to flatten out; where the coefficients are no longer changing value. This is difficult to ascertain, but somewhere around \\(\\lambda=50\\), there doesn‚Äôt seem to be a lot of change in the coefficients. This suggests that a \\(\\lambda\\) value around 50 would produce stable coefficient estimates."
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#aic-value",
    "href": "notes/10-biased-estimation-ridge-regression.html#aic-value",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "AIC Value",
    "text": "AIC Value\nIt turns out that not only is it difficult to make a subjective call about where the trace lines begin to flatten, but even when people do make this determination, they often select a \\(\\lambda\\) value that is too high. A better method for obtaining \\(\\lambda\\) is to compute a model-level metric that we can then evaluate across the models produced by the different values of \\(\\lambda\\). One such metric is the Akiake Information Criteria (AIC). We can compute the AIC for a ridge regression as\n\\[\n\\mathrm{AIC} = n \\times \\ln\\big(\\mathbf{e}^{\\intercal}\\mathbf{e}\\big) + 2(\\mathit{df})\n\\]\nwhere n is the sample size, \\(\\mathbf{e}\\) is the vector of residuals from the ridge model, and df is the degrees of freedom associated with the ridge regression model, which we compute by finding the trace of the H matrix, namely,\n\\[\ntr(\\mathbf{H}_{\\mathrm{Ridge}}) =  tr(\\mathbf{X}(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^{\\intercal})\n\\]\nFor example, to compute the AIC value associated with the ridge regression estimated using a \\(\\lambda\\) value of 0.1 we can use the following syntax.\n\n# Compute coefficients for ridge model\nb = solve(t(X) %*% X + 0.1*diag(3)) %*% t(X) %*% y\n\n# Compute residual vector\ne = y - (X %*% b)\n\n# Compute H matrix\nH = X %*% solve(t(X) %*% X + 0.1*diag(3)) %*% t(X)\n\n# Compute df\ndf = sum(diag(H))\n\n# Compute AIC\naic = 70 * log(t(e) %*% e) + 2 * df\naic\n\n         [,1]\n[1,] 285.8729\n\n\nWe want to compute the AIC value for every single one of the models associated with the \\(\\lambda\\) values from our sequence we used to produce the ridge trace plot. To do this, we will create a function that will compute the AIC from a given \\(\\lambda\\) value.\n\n# Function to compute AIC based on inputted lambda value\nridge_aic = function(lambda){\n  b = solve(t(X) %*% X + lambda*diag(3)) %*% t(X) %*% y\n  e = y - (X %*% b)\n  H = X %*% solve(t(X) %*% X + lambda*diag(3)) %*% t(X)\n  df = sum(diag(H))\n  n = length(y)\n  aic = n * log(t(e) %*% e) + 2 * df\n  return(aic)\n}\n\n# Try function\nridge_aic(lambda = 0.1)\n\n         [,1]\n[1,] 285.8729\n\n\nTo be able to evaluate which \\(\\lambda\\) value is assocuated with the lowest AIC, we need to compute the AIC for many different \\(\\lambda\\) values. To do this, we will create a data frame that has a column that includes the \\(\\lambda\\) values we want to evaluate. Then we use the rowwise() and mutate() functions to apply the ridge_aic() function to each of the lambda values. Finally, we can use filter() to find the \\(\\lambda\\) value associated with the smallest AIC value.\n\n# Create data frame with column of lambda values\n# Create a new column by using the ridge_aic() function for each row\nmy_models = data.frame(\n  Lambda = seq(from = 0, to = 100, by = 0.01)\n  ) %&gt;%\n  rowwise() %&gt;%\n   mutate(\n    AIC = ridge_aic(Lambda)\n  ) %&gt;%\n  ungroup() #Turn off the rowwise() operation\n\n# Find lambda associated with smallest AIC\nmy_models %&gt;% \n  filter(AIC == min(AIC))\n\n\n\n  \n\n\n\nA \\(\\lambda\\) value of 21.77 produces the smallest AIC value, so this is the \\(\\lambda\\) value we will adopt.\n\n# Re-fit ridge regression using lambda = 21.77\nridge_smallest_aic = lm.ridge(achievement ~ -1 + faculty + peer + school, \n                              data = z_data, lambda = 21.77)\n\n# View coefficients\ntidy(ridge_smallest_aic)\n\n\n\n  \n\n\n\nBased on using \\(\\lambda=21.77\\), the fitted ridge regression model is:\n\\[\n\\hat{\\mathrm{Achievement}}^{\\star}_i = 0.115(\\mathrm{Faculty}^{\\star}_i) + 0.174(\\mathrm{Peer}^{\\star}_i) + 0.099(\\mathrm{School}^{\\star}_i)\n\\]"
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#estimating-sampling-variance",
    "href": "notes/10-biased-estimation-ridge-regression.html#estimating-sampling-variance",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Estimating Sampling Variance",
    "text": "Estimating Sampling Variance\nIn theory it is possible to obtain the sampling variances for the ridge regression coefficients using matrix algebra:\n\\[\n\\sigma^2_{\\mathbf{b}} = \\sigma^2_{e}(\\mathbf{X}^\\intercal \\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^\\intercal \\mathbf{X} (\\mathbf{X}^\\intercal \\mathbf{X} + \\lambda\\mathbf{I})^{-1}\n\\]\nwhere \\(\\sigma^2_e\\) is the the error variance estimated from the standardized OLS model.\n\n# Fit standardized model to obtain sigma^2_e\nglance(lm(achievement ~ -1 + faculty + peer + school, data = z_data))\n\n\n\n  \n\n\n# Compute sigma^2_epsilon\nresid_var = 0.9041214 ^ 2\n\n# Compute variance-covariance matrix of ridge estimates\nW = solve(t(X) %*% X + 21.77*diag(3))\nvar_b = resid_var * W %*% t(X) %*% X %*% W\n\n# Compute SEs\nsqrt(diag(var_b))\n\n   faculty       peer     school \n0.05482363 0.05670386 0.04133673 \n\n\nComparing these SEs to the SEs from the OLS regression:\n\n\n\nComparison of the standard errors from the OLS (Œª=0) and ridge regression (Œª;=21.77) based on the standardized data.\n\n\nPredictor\n&lambda;=0\n&lambda;=21.77\n\n\n\n\nFaculty\n0.667\n0.055\n\n\nPeer\n0.598\n0.057\n\n\nSchool\n0.993\n0.041\n\n\n\n\n\n\n\nBased on this comparison, we can see that the standard errors from the ridge regression are quite a bit smaller than those from the OLS. We can then use the estimates and SEs to compute t- and p-values, and confidence intervals. Here we only do it for the school facilities predictor (since it is of primary interest based on the RQ) but one could do it for all the predictors.\n\n# Compute t-value for school predictor\nt = 0.09944444 / 0.04133673 \nt\n\n[1] 2.405716\n\n# Compute df residual\nH = X %*% solve(t(X) %*% X + 21.77*diag(3)) %*% t(X)\ndf_model = sum(diag(H))\ndf_residual = 69 - df_model\n\n# Compute p-value\np = pt(-abs(t), df = df_residual) * 2\np\n\n[1] 0.01886747\n\n# Compute CI\n0.09944444 - qt(p = 0.975, df = df_residual) * 0.04133673 \n\n[1] 0.01695739\n\n0.09944444 + qt(p = 0.975, df = df_residual) * 0.04133673\n\n[1] 0.1819315\n\n\nThis suggests that after controlling for peer influence and faculty credential, there is evidence of an effect of school facilities on student achievement (\\(p=.019\\)). The uncertainty in the 95% CI suggests that the true partial effect of school facilities is between 0.017 and 0.182. The empirical evidence is pointing toward a slight positive effect of school facilities."
  },
  {
    "objectID": "notes/10-biased-estimation-ridge-regression.html#footnotes",
    "href": "notes/10-biased-estimation-ridge-regression.html#footnotes",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt least within the class of linear, unbiased estimators.‚Ü©Ô∏é"
  },
  {
    "objectID": "notes/14-cross-validation.html",
    "href": "notes/14-cross-validation.html",
    "title": "üìù Cross Validation",
    "section": "",
    "text": "In the previous activity, we examined predictors of average life expectancy in a state, using data from states-2019.csv. We used several model building strategies and performance metrics to select and evaluate predictors. Unfortunately, we were evaluating the model/predictors using the same data that we used to build the model. This has several problems in practice, especially if you are using inferential metrics (p-values) to select the predictors:\nOne set of methods for dealing with these problems is to use cross-validation. The basic idea of cross-validation is to use one set of data to fit your model(s) and a completely separate set of data to evaluate the models‚Äô performance. We will again use the states-2019.csv data to introduce methods of cross-validation. After importing the data, we will also standardize all the numeric variables.\n# Load libraries\nlibrary(modelr)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(tidymodels) # Loads broom, rsample, parsnip, recipes, workflow, tune, yardstick, and dials\n\n# Import and view data\nusa = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/states-2019.csv\")\n\n# Create standardized variables after removing state names\nz_usa = usa |&gt;\n  select(-state) |&gt;\n  scale(center = TRUE, scale = TRUE) |&gt;\n  data.frame()\n\n# View data\nz_usa\nFrom our previous notes, there were a several candidate models that we may have been considering based on their AICc values. In this set of notes we will consider the best k-predictor models that had an AICc value within four of the minimum AICc value. These candidate models include:\n\\[\n\\begin{split}\n\\mathbf{M1:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M2:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M3:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M4:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\beta_4(\\mathrm{Murder~Rate}_i) + \\epsilon_i\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/14-cross-validation.html#cross-validated-mean-square-error-cv-mse",
    "href": "notes/14-cross-validation.html#cross-validated-mean-square-error-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Cross-Validated Mean Square Error (CV-MSE)",
    "text": "Cross-Validated Mean Square Error (CV-MSE)\nOne very common metric used is the residual variance (a.k.a., mean square error). Because this is computed on the validation data rather than on the data used to fit the model, we refer to it as the Cross-Validated Mean Square Error (CV-MSE). The CV-MSE is:\n\\[\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n e_i^2\n\\]\nwhere n is the number of observations in the validation set, and \\(e_i\\) are the residuals computed on the validation set. This value summarizes the model-data misfit in the validation data. Note that because this is a residual-based measure, lower values of CV-MSE correspond to better fitting models. Because this metric is computed on the validation data (data not used to initially fit the model), it is a better measure of how the model might perform in future samples."
  },
  {
    "objectID": "notes/14-cross-validation.html#divide-the-sample-data-into-a-training-and-validation-set",
    "href": "notes/14-cross-validation.html#divide-the-sample-data-into-a-training-and-validation-set",
    "title": "üìù Cross Validation",
    "section": "Divide the Sample Data into a Training and Validation Set",
    "text": "Divide the Sample Data into a Training and Validation Set\nThere are many ways to do this, but here we will use the sample() function to randomly sample 35 cases (rows) from the z_usa data (about 2/3 of the data). These 35 cases will make up the training data. Then we will use the filter() function to select those cases. The remaining cases (those 17 observations not sampled) are put into a validation set of data.\n\n# Make the random sampling replicable\nset.seed(42)\n\n# Select the cases to be in the training set\ntraining_cases = sample(1:nrow(z_usa), size = 35, replace = FALSE)\n\n# Create training data from the sampled cases\ntrain = z_usa |&gt;\n  filter(row_number() %in% training_cases)\n\n# Create validation data from the remaining cases\nvalidate = z_usa |&gt;\n  filter(!row_number() %in% training_cases)"
  },
  {
    "objectID": "notes/14-cross-validation.html#fit-the-candidate-models-to-the-training-data",
    "href": "notes/14-cross-validation.html#fit-the-candidate-models-to-the-training-data",
    "title": "üìù Cross Validation",
    "section": "Fit the Candidate Models to the Training Data",
    "text": "Fit the Candidate Models to the Training Data\nWe now fit the four candidate models to the observations in the training data.\n\nlm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\nlm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\nlm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)"
  },
  {
    "objectID": "notes/14-cross-validation.html#use-the-coefficients-from-the-fitted-models-and-the-validation-data-to-obtain-fitted-values-residuals-and-cv-mses",
    "href": "notes/14-cross-validation.html#use-the-coefficients-from-the-fitted-models-and-the-validation-data-to-obtain-fitted-values-residuals-and-cv-mses",
    "title": "üìù Cross Validation",
    "section": "Use the Coefficients from the Fitted Models and the Validation Data to Obtain Fitted Values, Residuals, and CV-MSEs",
    "text": "Use the Coefficients from the Fitted Models and the Validation Data to Obtain Fitted Values, Residuals, and CV-MSEs\nNow we can obtain the predicted life expectancy for the observations in the validation data based on the coefficients from the models fitted to the training data. These vectors of fitted values can be used to compute the residuals for the validation observations, which in turn can be used to compute the CV-MSE.\n\n# Get the predicted values for the validation data\nyhat_1 = predict(lm.1, newdata = validate)\nyhat_2 = predict(lm.2, newdata = validate)\nyhat_3 = predict(lm.3, newdata = validate)\nyhat_4 = predict(lm.4, newdata = validate)\n\n# Compute residuals and CV-MSE\nsum((validate$life_expectancy - yhat_1) ^ 2) / nrow(validate)\n\n[1] 0.7349516\n\nsum((validate$life_expectancy - yhat_2) ^ 2) / nrow(validate)\n\n[1] 0.7483797\n\nsum((validate$life_expectancy - yhat_3) ^ 2) / nrow(validate)\n\n[1] 0.8547222\n\nsum((validate$life_expectancy - yhat_4) ^ 2) / nrow(validate)\n\n[1] 0.8968336"
  },
  {
    "objectID": "notes/14-cross-validation.html#select-candidate-model-with-the-lowest-cv-mse",
    "href": "notes/14-cross-validation.html#select-candidate-model-with-the-lowest-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Select Candidate Model with the Lowest CV-MSE",
    "text": "Select Candidate Model with the Lowest CV-MSE\nSince the CV-MSE is a measure of model misfit, the candidate model having the smallest CV-MSE is the model that should be adopted. In this case, the values for the CV-MSE suggest adopting the single predictor model.\n\n\n\nCV-MSE for four potential models based on simple cross-validation. \n\n\nModel\nCV-MSE\n\n\n\n\n1-Predictor Model\n0.735\n\n\n2-Predictor Model\n0.748\n\n\n3-Predictor Model\n0.855\n\n\n4-Predictor Model\n0.897"
  },
  {
    "objectID": "notes/14-cross-validation.html#function-to-carry-out-loocv",
    "href": "notes/14-cross-validation.html#function-to-carry-out-loocv",
    "title": "üìù Cross Validation",
    "section": "Function to Carry Out LOOCV",
    "text": "Function to Carry Out LOOCV\nTo carry out LOOCV, we will write a function that computes \\(\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i\\) for each model given a particular case.\n\n# Function to compute CV-MSE for LOOCV\ncv_mse_i = function(case_index){\n\n  # Create training and validation data sets\n  train = z_usa |&gt; filter(row_number() != case_index)\n  validate = z_usa |&gt; filter(row_number() == case_index)\n\n  # Fit models to training data\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  # Compute fitted value for validation data\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  # Compute CV-MSE_i for each model\n  cv_mse_1 = (validate$life_expectancy - yhat_1) ^ 2\n  cv_mse_2 = (validate$life_expectancy - yhat_2) ^ 2\n  cv_mse_3 = (validate$life_expectancy - yhat_3) ^ 2\n  cv_mse_4 = (validate$life_expectancy - yhat_4) ^ 2\n\n  # Output a data frame\n  return(data.frame(cv_mse_1, cv_mse_2, cv_mse_3, cv_mse_4))\n}\n\n# Test function on Case 1\ncv_mse_i(1)\n\n\n\n  \n\n\n\nThen we can use this function to compute the four \\(\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i\\) values for each case in the data. We set up a data frame that includes a column called case that has each case number in the data. Then we use rowwise() to operate on each row separately and mutate() a new column by applying our cv_mse_i() function using map(). This creates a list column where the contents of each cell in the column is actually a list; in our case a data frame of four columns. Finally, we use unnest() to take the contents of the list column and spread them out into separate columns.\n\n# Apply cv_mse_i() function to all cases\nmy_cv_mse = data.frame(case = 1:52) |&gt;\n  rowwise() |&gt;\n  mutate(\n    cv_mse = map(case, cv_mse_i) #New list column that includes the data frame of output\n  ) |&gt;\n  unnest(cols = cv_mse) #Turn list column into multiple columns\n\n# View output\nmy_cv_mse"
  },
  {
    "objectID": "notes/14-cross-validation.html#alternative-programming-use-a-for-loop",
    "href": "notes/14-cross-validation.html#alternative-programming-use-a-for-loop",
    "title": "üìù Cross Validation",
    "section": "Alternative Programming: Use a for() Loop",
    "text": "Alternative Programming: Use a for() Loop\nAlternatively, we could also have used a for() loop to carry out the LOOCV. Here is some example syntax (not run):\n\n# Set up empty vector to store results\nmse_1 = rep(NA, 52)\nmse_2 = rep(NA, 52)\nmse_3 = rep(NA, 52)\nmse_4 = rep(NA, 52)\nmse_5 = rep(NA, 52)\n\n# Loop through the cross-validation\nfor(i in 1:nrow(z_usa)){\n  train = z_usa |&gt; filter(row_number() != i)\n  validate = z_usa |&gt; filter(row_number() == i)\n\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  mse_1[i] = (validate$life_expectancy - yhat_1) ^ 2\n  mse_2[i] = (validate$life_expectancy - yhat_2) ^ 2\n  mse_3[i] = (validate$life_expectancy - yhat_3) ^ 2\n  mse_4[i] = (validate$life_expectancy - yhat_4) ^ 2\n\n} \n\n# Create data frame of results\nmy_cv_mse = data.frame(\n  case = 1:52,\n  cv_mse_1 = mse_1, \n  cv_mse_2 = mse_2,\n  cv_mse_3 = mse_3,\n  cv_mse_4 = mse_4\n  )"
  },
  {
    "objectID": "notes/14-cross-validation.html#select-model-with-lowest-cv-mse",
    "href": "notes/14-cross-validation.html#select-model-with-lowest-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Select Model with Lowest CV-MSE",
    "text": "Select Model with Lowest CV-MSE\nWe can now compute the average CV-MSE for each of the candidate models and select the candidate model with the lowest average CV-MSE.\n\n# Compute average CV-MSE\nmy_cv_mse |&gt;\n  select(-case) |&gt;\n  summarize_all(mean)\n\n\n\n  \n\n\n\nThe LOOCV results suggest that we adopt the three-predictor model; it has the smallest average CV-MSE. Since LOOCV method is less biased than simple cross-validation (it trains the models on a much larger set of observations) its results are more believable than those from the simple cross-validation. Another advantage of LOOCV is that it will always produce the same results as opposed to simple cross-validation) since there is no randomness in producing the training and validation datasets.\n\n\n\nCV-MSE for four potential models based on simple cross-validation and Leave-One-Out Cross-Validation (LOOCV). \n\n\n\n\n\n\n\n\n\nCV-MSE\n\n\n\nModel\nSimple CV\nLOOCV\n\n\n\n\n1-Predictor Model\n0.735\n0.832\n\n\n2-Predictor Model\n0.748\n0.807\n\n\n3-Predictor Model\n0.855\n0.769\n\n\n4-Predictor Model\n0.897\n1.124\n\n\n\n\n\n\n\n\n\nComputing the CV-MSE under LOOCV: A Shortcut for OLS Models\nLOOCV can be computationally expensive when you sample is very large; we have to fit the candidate models n times. It turns out, however, that models fit with OLS, can give us the LOOCV results using the following formula:\n\\[\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n \\bigg(\\frac{e_i}{1-h_{ii}}\\bigg)^2\n\\]\nwhere \\(\\hat{y}_i\\) is the ith fitted value from the original least squares fit, and \\(h_{ii}\\) is the leverage value. This is similar to the model (biased) MSE, except the ith residual is divided by \\(1 ‚àí h_{ii}\\). Below, we compute the LOOCV CV-MSE for the three-predictor candidate model\n\n# Compute CV-MSE for Candidate Model 3\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy, data = z_usa)\n\n# Augment the model to get e_i and h_ii\nout.3 = augment(lm.3)\n\n# Compute CV-MSE for best three-predictor model\n1 / 52 * sum((out.3$.resid / (1 - out.3$.hat))^2)\n\n[1] 0.7686342"
  },
  {
    "objectID": "notes/16-path-analysis.html",
    "href": "notes/16-path-analysis.html",
    "title": "üìù Path Analysis",
    "section": "",
    "text": "Path diagrams are visual depictions of the hypothesized relationships between a set of variables. In this set of notes, we will introduce some of the ideas and concepts related to path diagrams, and the estimation of effects depicted in a path diagram (i.e., path analysis).\n\n[R Script File]"
  },
  {
    "objectID": "notes/16-path-analysis.html#what-are-path-diagrams",
    "href": "notes/16-path-analysis.html#what-are-path-diagrams",
    "title": "üìù Path Analysis",
    "section": "",
    "text": "Path diagrams are visual depictions of the hypothesized relationships between a set of variables. In this set of notes, we will introduce some of the ideas and concepts related to path diagrams, and the estimation of effects depicted in a path diagram (i.e., path analysis).\n\n[R Script File]"
  },
  {
    "objectID": "notes/16-path-analysis.html#example",
    "href": "notes/16-path-analysis.html#example",
    "title": "üìù Path Analysis",
    "section": "Example",
    "text": "Example\nTo help us in this endeavor, we will consider three potential student-level variables for our path model:\n\nAchievement\nAcademic Ability\nMotivation"
  },
  {
    "objectID": "notes/16-path-analysis.html#simulating-data",
    "href": "notes/16-path-analysis.html#simulating-data",
    "title": "üìù Path Analysis",
    "section": "Simulating Data",
    "text": "Simulating Data\n\n# Load Libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(corrr)\n\n# Create correlation matrix\ncorrs = matrix(\n  data = c(\n    1.000, 0.737, 0.255,\n    0.737, 1.000, 0.205,\n    0.255, 0.205, 1.000\n  ),\n  nrow = 3\n)\n\n# Create mean vector\nmeans = c(0, 0, 0) \n\n# Set sample size\nn = 1000"
  },
  {
    "objectID": "notes/16-path-analysis.html#simulating-data-cntd.",
    "href": "notes/16-path-analysis.html#simulating-data-cntd.",
    "title": "üìù Path Analysis",
    "section": "Simulating Data (cntd.)",
    "text": "Simulating Data (cntd.)\n\n# Make simulation reproducible\nset.seed(1)\n\n\n# Simulate the data and convert to data frame\nsim_dat &lt;- data.frame(MASS::mvrnorm(n = 1000, mu = means, Sigma = corrs, empirical = TRUE)) %&gt;%\n  rename(\n    achievement = X1,\n    ability = X2, \n    motivation = X3\n  )\n\n\n# View simulated data\nhead(sim_dat)\n\n  achievement     ability  motivation\n1  -0.5157929 -0.96667633  0.95967280\n2  -0.1533491 -1.50764502  0.65576719\n3  -0.4205593  0.97389153 -0.40326809\n4   1.5952036  1.11549647  0.15201335\n5   0.2921577  0.08731381  0.03244754\n6  -0.9016836  0.15578506 -1.32479673"
  },
  {
    "objectID": "notes/16-path-analysis.html#reading-a-path-diagram",
    "href": "notes/16-path-analysis.html#reading-a-path-diagram",
    "title": "üìù Path Analysis",
    "section": "Reading a Path Diagram",
    "text": "Reading a Path Diagram\nIn a path diagram,\n\nVariables we have data on (i.e., manifest or measured variables) are represented by squares or rectangles.\nLines between the variables indicate a relationship between the two connected variables. The lines between the different variables are called paths.\n\nIf the path has an arrowhead on both sides, it indicates the two connected variables are related (i.e., correlated).\nIf the path has an arrowhead on only one side, it indicates a hypothesized causal relationship. The cause is in the direction of the arrow; that is, the hypothesized cause is at the butt end of the line, while the hypothesized effect is at the arrowhead side of the line."
  },
  {
    "objectID": "notes/16-path-analysis.html#reading-a-path-diagram-cntd.",
    "href": "notes/16-path-analysis.html#reading-a-path-diagram-cntd.",
    "title": "üìù Path Analysis",
    "section": "Reading a Path Diagram (cntd.)",
    "text": "Reading a Path Diagram (cntd.)"
  },
  {
    "objectID": "notes/16-path-analysis.html#two-example-path-diagrams",
    "href": "notes/16-path-analysis.html#two-example-path-diagrams",
    "title": "üìù Path Analysis",
    "section": "Two Example Path Diagrams",
    "text": "Two Example Path Diagrams\n\nIn both of the examples below, there are three manifest/measured variables (academic ability, motivation, and achievement) and three paths (p1, p2, and p3). The difference between the two is that in the right-hand diagram, there are hypothesized causal relationships, while in the left-hand diagram the relationships are not presumed to be causal."
  },
  {
    "objectID": "notes/16-path-analysis.html#path-diagram-1",
    "href": "notes/16-path-analysis.html#path-diagram-1",
    "title": "üìù Path Analysis",
    "section": "Path Diagram 1",
    "text": "Path Diagram 1\n\n\n\n\n\n\n\n\n\n\n\n\nThe model depicted in this path diagram posits that there are relationships between:\n\nAcademic ability and achievement (p1);\nAcademic ability and motivation (p2); and\nMotivation and achievement (p3).\n\nThe double-headed arrows on the paths indicate that the variables are related (i.e., correlated), although there is no causal direction hypothesized."
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-path-coefficients-in-path-diagram-1",
    "href": "notes/16-path-analysis.html#estimating-path-coefficients-in-path-diagram-1",
    "title": "üìù Path Analysis",
    "section": "Estimating Path Coefficients in Path Diagram 1",
    "text": "Estimating Path Coefficients in Path Diagram 1\n\nIn a path analysis, one goal is to estimate path coefficients. In this model, since the paths represent the relationship between two variables, the path coefficients are simply the bivariate correlations between each set of variables.\n\n# Compute correlations\nsim_dat %&gt;%\n  correlate()\n\n# A tibble: 3 √ó 4\n  term        achievement ability motivation\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 achievement      NA       0.737      0.255\n2 ability           0.737  NA          0.205\n3 motivation        0.255   0.205     NA"
  },
  {
    "objectID": "notes/16-path-analysis.html#weak-causal-ordering",
    "href": "notes/16-path-analysis.html#weak-causal-ordering",
    "title": "üìù Path Analysis",
    "section": "Weak Causal Ordering",
    "text": "Weak Causal Ordering\nIn path modeling, we often assert weak causal ordering on the variables in the model. With weak causal ordering, we are not saying X causes Y, but rather that if X and Y are casually related, one of these variables (typically X) is the cause of the other.\n\n\n\n\nflowchart LR\n  A[X] --&gt; B[Y]\n\n\n\n\n\nIn this model, the paths have arrows at only one end indicating the hypothesized causal relationship. The cause is in the direction of the arrow, that is the hypothesized cause is at the butt end of the line, while the hypothesized effect is at the arrowhead side of the line.\n\nAny weak causal model should be posited prior to collecting or looking at the data! Creating this model can also help you identify the data to collect."
  },
  {
    "objectID": "notes/16-path-analysis.html#path-model-2-weak-causal-ordering",
    "href": "notes/16-path-analysis.html#path-model-2-weak-causal-ordering",
    "title": "üìù Path Analysis",
    "section": "Path Model 2: Weak Causal Ordering",
    "text": "Path Model 2: Weak Causal Ordering\n\n\n\n\n\n\n\n\n\n\n\n\nThe model depicted in this path diagram posits the following causal relationships:\n\nIf academic ability and achievement are causally related, then academic ability is the cause of achievement.\nIf academic ability and motivation are causally related, then academic ability is the cause of motivation.\nIf motivation and achievement are causally related, then motivation is the cause of achievement."
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-path-coefficients-in-a-weak-causal-model",
    "href": "notes/16-path-analysis.html#estimating-path-coefficients-in-a-weak-causal-model",
    "title": "üìù Path Analysis",
    "section": "Estimating Path Coefficients in a Weak Causal Model",
    "text": "Estimating Path Coefficients in a Weak Causal Model\nAgain, we would want to estimate the path coefficients shown in the diagram for the weak causal model. In causal models, the path coefficients are not necessarily the correlations. To find the path coefficients we need to use the tracing rule. The tracing rule indicates that:\n\nThe correlation between two variables X and Y is equal to the sum of the possible products of all possible paths from each possible tracing from X to Y, with the following two exceptions:\n\nThe same variable is not entered more than once in the same tracing.\nA variable is not both entered and exited through an arrowhead."
  },
  {
    "objectID": "notes/16-path-analysis.html#example-of-the-tracing-rule",
    "href": "notes/16-path-analysis.html#example-of-the-tracing-rule",
    "title": "üìù Path Analysis",
    "section": "Example of the Tracing Rule",
    "text": "Example of the Tracing Rule\nAs an example, consider all the tracings (routes) that allow us to start at the academic ability variable and go to the achievement variable in the path diagram at right.\n\n\n\n\n\n\n\n\n\n\n\n\nThere are two possible tracings that conform to the tracing rule:\n\nStart at the academic ability variable and take p1 to the achievement variable.\nStart at the academic ability variable and take p2 to the motivation variable, then take p3 to the achievement variable."
  },
  {
    "objectID": "notes/16-path-analysis.html#example-of-the-tracing-rule-cntd.",
    "href": "notes/16-path-analysis.html#example-of-the-tracing-rule-cntd.",
    "title": "üìù Path Analysis",
    "section": "Example of the Tracing Rule (cntd.)",
    "text": "Example of the Tracing Rule (cntd.)\nSimilarly, we could have started at the achievement variable and determined the tracings to get to the academic ability variable:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStart at the achievement variable and take p1 to the academic ability variable.\nStart at the achievement variable and take p3 to the motivation variable, then take p2 to the academic ability variable."
  },
  {
    "objectID": "notes/16-path-analysis.html#important-note-regarding-the-tracing-rule",
    "href": "notes/16-path-analysis.html#important-note-regarding-the-tracing-rule",
    "title": "üìù Path Analysis",
    "section": "Important Note Regarding the Tracing Rule",
    "text": "Important Note Regarding the Tracing Rule\nNote that when we are considering tracings, we do not have to worry about the direction of the arrow, only that there is a path we can trace. The only rule regarding arrowheads is that a variable can not be both entered and exited through an arrowhead."
  },
  {
    "objectID": "notes/16-path-analysis.html#back-to-estimating-the-path-coeffients",
    "href": "notes/16-path-analysis.html#back-to-estimating-the-path-coeffients",
    "title": "üìù Path Analysis",
    "section": "Back to Estimating the Path Coeffients",
    "text": "Back to Estimating the Path Coeffients\nEach tracing yields a product of the path coefficents used in the tracing. Thus the first tracing is \\(p1\\) (there is only one path, so the product is simply the path), and the second tracing yields \\(p2 \\times p3\\). Since the tracing rule says that the correlation between academic ability and achievement is equal to the sum of the products yielded by the tracings, we know that:\n\\[\n\\begin{split}\nr_{\\mathrm{academic~ability,~ achievement}} &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + p2(p3)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/16-path-analysis.html#your-turn",
    "href": "notes/16-path-analysis.html#your-turn",
    "title": "üìù Path Analysis",
    "section": "Your Turn",
    "text": "Your Turn\nUse the tracing rule to write two more equations. The first equation should represent the correlation between motivation and achievement, and the second equation should represent the correlation between ability and motivation."
  },
  {
    "objectID": "notes/16-path-analysis.html#check-your-work",
    "href": "notes/16-path-analysis.html#check-your-work",
    "title": "üìù Path Analysis",
    "section": "Check Your Work",
    "text": "Check Your Work\n\n\n\n\n\n\n\n\n\n\n\n\nTo represent the correlation between motivation and achievement we have two potential tracings:\n\nStart at the motivation and take p3 to the achievement variable.\nStart at the motivation variable and take p2 to the academic ability variable, then take p1 to the achievement variable.\n\n\\[\n\\begin{split}\nr_{\\mathrm{motivation,~ achievement}} &= p3 + p2(p1) \\\\[1em]\n.255&= p3 + p2(p1)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/16-path-analysis.html#check-your-work-1",
    "href": "notes/16-path-analysis.html#check-your-work-1",
    "title": "üìù Path Analysis",
    "section": "Check Your Work",
    "text": "Check Your Work\n\n\n\n\n\n\n\n\n\n\n\n\nTo represent the correlation between academic ability and motivation we have one tracing:\n\nStart at the academic ability and take p2 to the motivation variable.\n\n\\[\n\\begin{split}\nr_{\\mathrm{academic~ability,~ motivation}} &= p2 \\\\[1em]\n.205&= p2\n\\end{split}\n\\]\nQUESTION: Why can‚Äôt we use the tracing that takes p1 from academic ability to achievement then takes p3 to motivation??"
  },
  {
    "objectID": "notes/16-path-analysis.html#solving-for-p1-p2-and-p3",
    "href": "notes/16-path-analysis.html#solving-for-p1-p2-and-p3",
    "title": "üìù Path Analysis",
    "section": "Solving for p1, p2, and p3",
    "text": "Solving for p1, p2, and p3\n\nEquationsp1p3Back to p1\n\n\nWe now have three equations with three unknowns. We can solve this system of equations to find p1, p2, and p3.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.255 &= p3 + p2(p1) \\\\[1em]\n.205 &= p2\n\\end{split}\n\\]\n\n\nSubstitute in .205 for p2 in the first equation and solve for p1.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + .205(p3) \\\\[1em]\np1 &= .737 - .205(p3)\n\\end{split}\n\\]\n\n\nNow substitute .205 in for p2 and \\(.737 - .205(p3)\\) in for p1 in the second equation and solve for p3.\n\\[\n\\begin{split}\n.255 &= p3 + p2(p1) \\\\[1em]\n.255 &= p3 + .205(.737 - .205(p3)) \\\\[1em]\n.255 &= p3 + 0.151085 - 0.042025(p3) \\\\[1em]\n0.103915 &= 0.957975(p3) \\\\[1em]\np3 &= .108\n\\end{split}\n\\]\n\n\nNow substitute .205 in for p2 and .108 in for p3 in the first equation and solve for p1.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + .205(.108) \\\\[1em]\n.737 &= p1 + 0.02214 \\\\[1em]\np1 &= .715\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/16-path-analysis.html#path-diagram-with-estimated-path-coefficients",
    "href": "notes/16-path-analysis.html#path-diagram-with-estimated-path-coefficients",
    "title": "üìù Path Analysis",
    "section": "Path Diagram with Estimated Path Coefficients",
    "text": "Path Diagram with Estimated Path Coefficients"
  },
  {
    "objectID": "notes/16-path-analysis.html#interpreting-path-coefficients",
    "href": "notes/16-path-analysis.html#interpreting-path-coefficients",
    "title": "üìù Path Analysis",
    "section": "Interpreting Path Coefficients",
    "text": "Interpreting Path Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\nPath coefficients are standardized coefficients which can be interpreted similar to standardized regression coefficients.\n\nGiven the adequacy of the path model, each 1-standard deviation increase in motivation increases achievement by .108 standard deviations, on average.\nGiven the adequacy of the path model, each 1-standard deviation increase in academic ability increases achievement by .715 standard deviations, on average.\nGiven the adequacy of the path model, each 1-standard deviation increase in academic ability increases motivation by .205 standard deviations, on average."
  },
  {
    "objectID": "notes/16-path-analysis.html#interpreting-path-coefficients-cntd.",
    "href": "notes/16-path-analysis.html#interpreting-path-coefficients-cntd.",
    "title": "üìù Path Analysis",
    "section": "Interpreting Path Coefficients (cntd.)",
    "text": "Interpreting Path Coefficients (cntd.)\nThere are two things to note when we interpret path coefficients that are different from when we interpret regression coefficients.\n\nWe include ‚Äúgiven the adequacy of the model‚Äù in our interpretation. This is important because the values of the path coefficients absolutely depend on the weak causal model specified (i.e., how you draw the path diagram).\nBecause we are positing a causal relationship, we can use the causal type language in our interpretation. E.g., an increase in X leads to an increase in Y.\n\nNote also that the interpretation is not controlling for anything. These are simple relationships that we are interpreting."
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-path-coefficients-via-regression",
    "href": "notes/16-path-analysis.html#estimating-path-coefficients-via-regression",
    "title": "üìù Path Analysis",
    "section": "Estimating Path Coefficients via Regression",
    "text": "Estimating Path Coefficients via Regression\n\nWe can also find the path coefficients using regression rather than algebra. To determine the path coefficients in the weak causal model, we fit a set of regression models using the ‚Äúcauses‚Äù as predictors of any particular effect.\n\n\n\n\n\n\n\n\n\n\nIn our path diagram there are two effects, so we would need to fit two separate regression models. The syntax for these models would be:\nachievement ~ 0 + ability + motivation\nmotivation ~ 0 + ability"
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-path-coefficients-via-regression-cntd.",
    "href": "notes/16-path-analysis.html#estimating-path-coefficients-via-regression-cntd.",
    "title": "üìù Path Analysis",
    "section": "Estimating Path Coefficients via Regression (cntd.)",
    "text": "Estimating Path Coefficients via Regression (cntd.)\n\n# Path coefficients for paths to achievement\ntidy(lm(achievement ~ 0 + ability + motivation, data = sim_dat))\n\n# A tibble: 2 √ó 5\n  term       estimate std.error statistic   p.value\n  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 ability       0.715    0.0216     33.1  8.26e-163\n2 motivation    0.108    0.0216      5.02 5.97e-  7\n\n\n\n\n# Path coefficient for paths to motivation\ntidy(lm(motivation ~ 0 + ability, data = sim_dat))\n\n# A tibble: 1 √ó 5\n  term    estimate std.error statistic  p.value\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 ability    0.205    0.0310      6.62 5.85e-11"
  },
  {
    "objectID": "notes/16-path-analysis.html#residual-variation",
    "href": "notes/16-path-analysis.html#residual-variation",
    "title": "üìù Path Analysis",
    "section": "Residual Variation",
    "text": "Residual Variation\nEven if the causal relationships were specified correctly, the model likely does not include ALL of the causes for motivation and achievement. There is also unaccounted for variation due to random variation and measurement error. To account for these three sources of variation in the weak causal model, we will add an error term to eavch of the effects in the path model."
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-residual-variation",
    "href": "notes/16-path-analysis.html#estimating-residual-variation",
    "title": "üìù Path Analysis",
    "section": "Estimating Residual Variation",
    "text": "Estimating Residual Variation\nWe can also estimate the path coefficients for the error terms. These path coefficients are computed as,\n\\[\n\\epsilon_k = \\sqrt{1 - R^2_k}\n\\] where, \\(R^2_k\\) is the \\(R^2\\)-value from the regression model fitted to compute the initial path coefficients."
  },
  {
    "objectID": "notes/16-path-analysis.html#estimating-residual-variation-cntd.",
    "href": "notes/16-path-analysis.html#estimating-residual-variation-cntd.",
    "title": "üìù Path Analysis",
    "section": "Estimating Residual Variation (cntd.)",
    "text": "Estimating Residual Variation (cntd.)\n\n\n\n# Path coefficients for error term on achievement\nglance(lm(achievement ~ 0 + ability + motivation, data = sim_dat))\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.554         0.554 0.668      621. 6.36e-176     2 -1014. 2034. 2049.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nsqrt(1 - .554)\n\n[1] 0.6678323\n\n\n\n\n# Path coefficient for error term on motivation\nglance(lm(motivation ~ 0 + ability, data = sim_dat))\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0420        0.0411 0.979        NA      NA    NA -1397. 2798. 2808.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nsqrt(1 - .0420)\n\n[1] 0.9787747"
  },
  {
    "objectID": "notes/16-path-analysis.html#how-do-we-draw-path-diagram",
    "href": "notes/16-path-analysis.html#how-do-we-draw-path-diagram",
    "title": "üìù Path Analysis",
    "section": "How Do We Draw Path Diagram?",
    "text": "How Do We Draw Path Diagram?\n\nTheory/prior research\nLogic/expert understanding/common sense\n\nWe also need to pay attention to time precedence. Cause does not operate backward in time. In our example, academic ability is well-documented as something that does not change after grade school. Thus, it would precede motivation and achievement in time."
  },
  {
    "objectID": "notes/16-path-analysis.html#a-little-more-about-cause",
    "href": "notes/16-path-analysis.html#a-little-more-about-cause",
    "title": "üìù Path Analysis",
    "section": "A Little More About Cause",
    "text": "A Little More About Cause\nWhat do we mean when we say ‚ÄúX causes Y‚Äù? Contrary to popular belief, we do not mean that changing X has a direct, and immediate change on Y. For example, it is now well known that smoking causes lung cancer.\n\n\n\n\n\n\n\n\n\nBut, not everyone who smokes ends up getting lung cancer."
  },
  {
    "objectID": "notes/16-path-analysis.html#a-little-more-about-cause-cntd.",
    "href": "notes/16-path-analysis.html#a-little-more-about-cause-cntd.",
    "title": "üìù Path Analysis",
    "section": "A Little More About Cause (cntd.)",
    "text": "A Little More About Cause (cntd.)\nInstead, cause is a probabilistic statement about the world. When we say smoking causes lung cancer what we mean, statistically, is that smoking increases the probability of developing lung cancer.\n\nMoreover, this increased probability is due to smoking, and not something else."
  },
  {
    "objectID": "notes/16-path-analysis.html#requirements-for-cause",
    "href": "notes/16-path-analysis.html#requirements-for-cause",
    "title": "üìù Path Analysis",
    "section": "Requirements for Cause",
    "text": "Requirements for Cause\nThere are three primary requirements for a causal relationship between X and Y.\n\nThere must be a relationship between X and Y. (Correlation is a necessary component of causation.)\nTime precedence (Causes must occur prior to effects.)\nRelationship must not be spurious."
  },
  {
    "objectID": "notes/16-path-analysis.html#including-time-precedence-in-the-path-diagram",
    "href": "notes/16-path-analysis.html#including-time-precedence-in-the-path-diagram",
    "title": "üìù Path Analysis",
    "section": "Including Time Precedence in the Path Diagram",
    "text": "Including Time Precedence in the Path Diagram\nTime precedence is often reflected in the orientation of the model. Variables that occur earlier in time are oriented further to the left side of the diagram than variables that occur later.\n\n\n\n\n\n\n\n\n\nIn the smoking example, to be considered the cause for lung cancer, smoking has to occur prior to the onset of lung cancer.1"
  },
  {
    "objectID": "notes/16-path-analysis.html#including-time-precedence-in-the-path-diagram-cntd.",
    "href": "notes/16-path-analysis.html#including-time-precedence-in-the-path-diagram-cntd.",
    "title": "üìù Path Analysis",
    "section": "Including Time Precedence in the Path Diagram (cntd.)",
    "text": "Including Time Precedence in the Path Diagram (cntd.)\nIn our path diagram relating academic ability and motivation to acheivement, academic ability is furthest to the left (it occurs earliest), followed by motivation, and then academic achievement."
  },
  {
    "objectID": "notes/16-path-analysis.html#common-cause",
    "href": "notes/16-path-analysis.html#common-cause",
    "title": "üìù Path Analysis",
    "section": "Common Cause",
    "text": "Common Cause\nA common cause is a variable that is a cause of both X and Y which accounts for the relationship between X and Y. Consider the following example where we want to look at the causal impact of participation in Head Start programs on academic achievement.\n\n\n\n\n\n\n\n\n\nIn practice, the path coefficient tends to be negative. That is Head Start participants tend to have lower academic achievement than their non-Head Start peers."
  },
  {
    "objectID": "notes/16-path-analysis.html#common-cause-cntd.",
    "href": "notes/16-path-analysis.html#common-cause-cntd.",
    "title": "üìù Path Analysis",
    "section": "Common Cause (cntd.)",
    "text": "Common Cause (cntd.)\nA common cause of both Head Start participation and academic achievement is poverty. This is shown below.\n\n\n\n\n\n\n\n\n\nOnce we include poverty as a common cause, the path coefficient between Head Start participation and academic achievement switches direction. That is, after including poverty in the path model, Head Start participants tend to have higher academic achievement than their non-Head Start peers. This is akin to how effects in a regression model might change after we control for other predictors."
  },
  {
    "objectID": "notes/16-path-analysis.html#common-cause-cntd.-1",
    "href": "notes/16-path-analysis.html#common-cause-cntd.-1",
    "title": "üìù Path Analysis",
    "section": "Common Cause (cntd.)",
    "text": "Common Cause (cntd.)\nIn order to meet the third causal requirement, we need to include ALL common causes in the model. This requirement is the hardest to prove."
  },
  {
    "objectID": "notes/16-path-analysis.html#non-recursive-models",
    "href": "notes/16-path-analysis.html#non-recursive-models",
    "title": "üìù Path Analysis",
    "section": "Non-Recursive Models",
    "text": "Non-Recursive Models\nIn the path diagrams we have looked at so far, the causal paths have gone in only one direction; there is a distinct cause and effect. The error terms on the effect variables are also all uncorrelated. These are called recursive models. It is possible for variables to effect each other (e.g., predator‚Äìprey relationships), or for the error terms to be correlated. This is called a non-recursive model."
  },
  {
    "objectID": "notes/16-path-analysis.html#under-identified-models",
    "href": "notes/16-path-analysis.html#under-identified-models",
    "title": "üìù Path Analysis",
    "section": "Under-Identified Models",
    "text": "Under-Identified Models\nThe problem with estimating the path coefficients in the non-recursive model is it is under-identified. In our predator‚Äìprey model, we need to estimate four path coefficients, but only have three correlations (equations) from which to do so. We can‚Äôt solve this without adding additional constraints!\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{split}\nr_{\\mathrm{H,W}} &= p1 + p2(p4) \\\\[1em]\nr_{\\mathrm{H,R}} &= p2 + p1(p3) \\\\[1em]\nr_{\\mathrm{H,W}} &= p3 + p4 + p1(p2)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/16-path-analysis.html#over-identified-models",
    "href": "notes/16-path-analysis.html#over-identified-models",
    "title": "üìù Path Analysis",
    "section": "Over-Identified Models",
    "text": "Over-Identified Models"
  },
  {
    "objectID": "notes/16-path-analysis.html#footnotes",
    "href": "notes/16-path-analysis.html#footnotes",
    "title": "üìù Path Analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that the top‚Äìbottom orientation typically doesn‚Äôt mean anything‚Äîit is just used for aesthetics in the layout.‚Ü©Ô∏é"
  },
  {
    "objectID": "notes/17-more-path-analysis.html",
    "href": "notes/17-more-path-analysis.html",
    "title": "üìù More Path Analysis",
    "section": "",
    "text": "In this set of notes, we will use the data from path-model-achievement.csv to fit a path model to explain effects on high school achievement. The data were simulated to include attributes for 1000 students from information provided by Keith (2015).\n\n[CSV]\n[R Script File]\n\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(lavaan)\n\n# Import data\nkeith = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/path-model-achievement.csv\")\nkeith\n\n\n\n  \n\n\n\n\n\nHypothesized Path Model\nThe hypothesized path model is shown below. This model was based on previous literature related to student achievement and on Keith‚Äôs experiences as an educator and educational researcher.\n\n\n\n\n\nHypothesized path model for several predictors of high school achievement.\n\n\n\n\n\n\n\nEstimating the Path Coefficients\nWe need to estimate 10 path coefficients between the measured variables and four additional paths between unmeasured variables and each of the measured effects. To do this we can use a regression model that includes the hypothesized causes to predict variation in each of the effects. The regression coefficients obtained are the path coefficients between each of the hypothesized causes and effect.\nFor example, the variable high school motivation is an effect in our model (i.e., it has arrows going into it). The hypothesized causes of high school motivation are family background, and academic ability. To obtain those two path coefficients:\n\n# Fit model\nlm.motivation = lm(motivation ~ 1 + fam_back + ability, data = keith)\n\n# Obtain path coefficients\ntidy(lm.motivation)\n\n\n\n  \n\n\n\nThe path coefficient for the path from family background to high school motivation (p4) is 0.127, and that for the path from academic ability to high school motivation (p7) is 0.152. These represent the direct effects of family background and academic ability on high school motivation, respectively. Here we interpret the direct effect of academic ability on high school motivation:\n\nGiven the adequacy of our model, academic ability has a small positive effect on high school motivation. Each one-standard deviation increase in academic ability will result in a 0.127-standard deviation unit change on high school motivation, on average.\n\nWe can also estimate the path between the unmeasured variables (\\(d_2\\)) and high school motivation. This is computed as:\n\\[\n\\sqrt{1-R^2}\n\\]\nwhere \\(R^2\\) is the coefficient of determination from the fitted regression. In our example\n\n# Obtain R2\nglance(lm.motivation)\n\n\n\n  \n\n\n# Compute path\nsqrt(1 - 0.0552)\n\n[1] 0.9720082\n\n\nThe path between \\(d_2\\) and high school motivation is 0.972. This represents the effects of all other causes of high school motivation that we did not include in our hypothesized path model. This suggests that many of the influences of high school motivation are unaccounted for by the path model. Presumably, these are not important in positing the causal model. (Note if they are important, they should be included as measured variables in the path model.) The regression models to estimate the remaining paths are provided below (output not given), as well as the path estimates for the hypothesized path model.\n\n# Effect: Academic Ability\nlm.abilty = lm(ability ~ 1 + fam_back, data = sim_dat)\ntidy(lm.abilty)\nglance(lm.abilty)\nsqrt(1 - 0.174)\n\n# Effect: High School Coursework\nlm.coursework = lm(coursework ~ 1 + fam_back + ability + motivation, data = sim_dat)\ntidy(lm.coursework)\nglance(lm.coursework)\nsqrt(1 - 0.348)\n\n# Effect: High School Achievement\nlm.achieve = lm(achieve ~ 1 + fam_back + ability + motivation + coursework, data = sim_dat)\ntidy(achieve)\nglance(lm.achieve)\nsqrt(1 - 0.629)\n\n\n\n\n\n\nHypothesized path model for several predictors of high school achievement. The path estimates are also included.\n\n\n\n\n\n\n\nEstimating Effects\nWe can now use the path coefficients to estimate the effects on high school achievement. Based on the hypothesized path model, each of the measured variables has a direct effect on high school achievement.\n\nThe direct effect of family background on high school achievement is 0.069.\nThe direct effect of academic ability on high school achievement is 0.551.\nThe direct effect of high school motivation on high school achievement is 0.013.\nThe direct effect of high school coursework on high school achievement is 0.310.\n\nThere are also indirect effects of these four causes of high school achievement. For example high school motivation not only directly influences high school achievement, but also influences it by influencing high school coursework (i.e., more motivated students take higher level courses which results in higher achievement).\nEach indirect effect is computed as the product of the path coefficients connecting the potential cause and effect. For example, the indirect effect of high school motivation on high school achievement via high school coursework is:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effect} &= 0.267 \\times 0.310 \\\\[1em]\n&= 0.083\n\\end{split}\n\\]\nFor some of these measured variables there are multiple indirect effects on achievement. The overall indirect effects are computed as the sum of each of the indirect effects. For example the indirect effects of academic ability on high school achievement are:\n\nAcademic ability influences high school coursework which, in turn, influences high school achievement. This indirect effect is \\(0.374 \\times 0.310 = 0.083\\)\nAcademic ability influences high school motivation which, in turn, influences high school achievement. This indirect effect is \\(0.152 \\times 0.013 = 0.002\\)\nAcademic ability influences high school motivation which, in turn, influences high school coursework, which then influences high school achievement. This indirect effect is \\(0.152 \\times 0.267 \\times 0.310 = 0.013\\)\n\nThus the overall indirect effects of academic ability on high school achievement is:\n\\[\n\\begin{split}\n\\mathrm{All~Indirect~Effects} &=  (0.374 \\times 0.310) + (0.152 \\times 0.013) + (0.152 \\times 0.267 \\times 0.310) \\\\[1em]\n&= 0.130\n\\end{split}\n\\]\nThe sum total of the direct and indirect effects give us the total effect of each hypothesized cause. For example, the total effect of academic ability on high school achievement is:\n\\[\n\\begin{split}\n\\mathrm{Total~Effects} &=  0.551 + 0.130 \\\\[1em]\n&= 0.681\n\\end{split}\n\\]\nPutting all of this together,\n\nGiven the adequacy of our model, academic ability has a fairly large, positive effect on high school achievement. Each one-standard deviation increase in academic ability will result in a 0.681-standard deviation unit change in high school achievement, on average. Much of that influence is from the direct effect of academic ability on high school achievement (\\(\\hat\\beta=0.551\\)). A small part of academic ability‚Äôs effect on high school achievement is due to its influence on other factors (e.g., motivation) which, in turn, effect high school achievement.\n\nThe table below gives the direct, indirect, and total effects for each of the hypothesized causes of high school achievement.\n\n\n\nStandardized direct, indirect, and total effects of substantive predictors influencing high school achievment. \n\n\n\n\n\n\n\n\n\n\nEffect\n\n\n\nMeasure\nDirect\nIndirect\nTotal\n\n\n\n\nFamily Background\n0.069\n0.348\n0.417\n\n\nAcademic Ability\n0.551\n0.131\n0.682\n\n\nHigh School Motivation\n0.013\n0.083\n0.096\n\n\nHigh School Coursework\n0.310\n---\n0.310\n\n\n\n\n\n\n\nThe largest direct influences of high school achievement are from high school coursework and academic ability. Family background also has a large influence on high school achievement, but primarily indirectly. Lastly, high school motivation has a small effect both directly and indirectly on high school achievement.\n\n\n\nFitting the Path Model with lavaan\nThe {lavaan} package includes the sem() function, which can estimate coefficients in a path model. To use this function, we define the path model by identifying each of the effects on a separate line in a character string. This string takes the model formula from each of the lm() functions we fitted earlier. We can also include the path names as multipliers of the influences in this model formula. Here we use the paths from our hypothesized path model to define the effects in the path model:\n\n# Define path model\npath.model = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n\"\n\nThen we can give this model as input to the sem() function along with the data frame that includes the data to estimate the model. We assign this to an object and use summary() to obtain the results. The rsquare=TRUE argument in summary() print the \\(R^2\\) values, the latter of which we can use to estimate the paths from the unmeasured variables to the respective effects. You can also include other options to output additional estimates (e.g., ci = TRUE for confidence intervals). See here for additional information.\n\n# Fit model\npm.1 = sem(path.model, data = keith)\n\n# Results\nsummary(pm.1, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\n\nWe can also estimate and obtain tests for the indirect effects as well. To do this we need to add model syntax defining each indirect effect we wish to include. This model syntax uses the path names to define how to compute that effect. For example to include the indirect effect of academic ability on high school achievement via high school motivation we would add the following line into our character string:\nindirect_ability_via_motivation := p7*p8\nThe path model would then be defined and fitted:\n\n# Define path model\npath.model.2 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_ability_via_motivation := p7*p8\n\"\n\n# Fit model\npm.2 = sem(path.model.2, data = keith)\n\n# Results\nsummary(pm.2, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indrct_blty_v_    0.002    0.003    0.599    0.549\n\n\nHere the indirect effect of academic ability on high school achievement via high school motivation is not statistically significant. This is likely because the direct effect of high school motivation on high school achievement is also not statistically significant (i.e., if that path is 0 then the product we get when computing the indirect effect will also be 0).\nHere we define and compute the overall indirect effects for each of the hypothesized causes:\n\n# Define path model\npath.model.3 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p8 + p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n\"\n\n# Fit model\npm.3 = sem(path.model.3, data = keith)\n\n# Results\nsummary(pm.2, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indrct_blty_v_    0.002    0.003    0.599    0.549\n\n\nFinally, we can fit a path model and estimate the direct, indirect, and total effects.\n\n# Define path model\npath.model.4 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p8 + p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n  total_fam_back := p3 + p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  total_ability := p6 + p7*p8 + p7*p9*p10 + p5*p10\n  total_motivation := p8 + p9*p10\n  total_coursework := p10\n\"\n\n# Fit model\npm.4 = sem(path.model.4, data = keith)\n\n# Results\nsummary(pm.4, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indirct_fm_bck    0.348    0.024   14.751    0.000\n    indirect_ablty    0.131    0.013    9.868    0.000\n    indirect_mtvtn    0.083    0.010    8.003    0.000\n    total_fam_back    0.417    0.029   14.508    0.000\n    total_ability     0.682    0.023   29.460    0.000\n    total_motivatn    0.095    0.021    4.448    0.000\n    total_courswrk    0.310    0.024   12.996    0.000\n\n\n\n\n\nEmpirically Reducing the Model\nThe path between high school motivation and and high school achievement was not statistically significant (p = 0.546). This suggests that the effect we saw in the data may be attributable to sampling variation. One possibility is to reduce the model by removing this path.\n\n\n\n\n\nReduced path model for several predictors of high school achievement. In this model the direct effect between high school motivation and high school achievement was removed (path p8).\n\n\n\n\nNote that removing a path can change both direct and indirect effects. In our path model, we would need to remove any path that traverses through path p8. There are two approaches to doing this:\nOne approach is to remove the path and use the original estimates to re-compute the direct, indirect, and total effects. For example, to compute the indirect effects of academic ability on high school achievement we would use:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effects} &=  (0.374 \\times 0.310)  + (0.152 \\times 0.267 \\times 0.310) \\\\[1em]\n&= 0.128521\n\\end{split}\n\\]\nA second approach is to re-fit the model to the empirical data. The fitted path model is shown below.\n\n# Define path model\npath.model.5 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6  + p1*p7*p9*p10 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n  total_fam_back := p3 + p1*p5*p10 + p1*p6  + p1*p7*p9*p10 + p4*p9*p10 + p2*p10\n  total_ability := p6 + p7*p9*p10 + p5*p10\n  total_coursework := p10\n\"\n\n# Fit model\npm.5 = sem(path.model.5, data = keith)\n\n# Results\nsummary(pm.5, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.365\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.546\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.070    0.022    3.240    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    courswrk (p10)    0.314    0.023   13.841    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indirct_fm_bck    0.347    0.024   14.740    0.000\n    indirect_ablty    0.130    0.013    9.866    0.000\n    indirect_mtvtn    0.084    0.010    8.189    0.000\n    total_fam_back    0.417    0.029   14.508    0.000\n    total_ability     0.682    0.023   29.460    0.000\n    total_courswrk    0.314    0.023   13.841    0.000\n\n\nComputing the indirect effects of academic ability on high school achievement for this re-fitted model we would use:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effects} &=  (0.374 \\times 0.314)  + (0.152 \\times 0.267 \\times 0.314) \\\\[1em]\n&= 0.1301794\n\\end{split}\n\\]\nOr, we could extract the estimate for indirect_ablty from the output. To get these results to more decimal places, we can use the parameterEstimates() function, which outputs a data frame of the results. We want to extract the est column, which includes the estimates. Note that the indirect effects of academic ability on high school achievement is the 16th element of the est vector.\n\n# Data frame of parameter estimates\nparameterEstimates(pm.5)\n\n\n\n  \n\n\n# Estimates column\nparameterEstimates(pm.5)$est\n\n [1] 0.41700000 0.12651448 0.15224346 0.16516282 0.37442021 0.26686292\n [7] 0.07021160 0.55114506 0.31441104 0.82528489 0.94380759 0.65137255\n[13] 0.37079389 0.99900000 0.34678840 0.13049578 0.08390465 0.41700000\n[19] 0.68164084 0.31441104\n\n# Indirect effects of academic ability on high school achievement\nparameterEstimates(pm.5)$est[16]\n\n[1] 0.1304958\n\n\nWhether you reduce the model and re-fit it to the data, or use the estimates from the original fitted model and set non-significant effects to zero, the differences are minimal; in this case only one of the path coefficients changed when rounded to three decimal places.\n\n\n\n\n\nReferences\n\nKeith, T. V. (2015). Multiple regression and beyond: An introduction to multiple regression and structural equation modeling (2nd ed.). New York: Routledge."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#what-are-path-diagrams",
    "href": "notes/03-02-path-analysis.html#what-are-path-diagrams",
    "title": "üé∂ Path Analysis",
    "section": "What are Path Diagrams?",
    "text": "What are Path Diagrams?\nPath diagrams are visual depictions of the hypothesized relationships between a set of variables. In this set of notes, we will introduce some of the ideas and concepts related to path diagrams, and the estimation of effects depicted in a path diagram (i.e., path analysis).\n\n[R Script File]"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#example",
    "href": "notes/03-02-path-analysis.html#example",
    "title": "üé∂ Path Analysis",
    "section": "Example",
    "text": "Example\nTo help us in this endeavor, we will consider three potential student-level variables for our path model:\n\nAchievement\nAcademic Ability\nMotivation"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#simulating-data",
    "href": "notes/03-02-path-analysis.html#simulating-data",
    "title": "üé∂ Path Analysis",
    "section": "Simulating Data",
    "text": "Simulating Data\n\n# Load Libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(corrr)\n\n# Create correlation matrix\ncorrs = matrix(\n  data = c(\n    1.000, 0.737, 0.255,\n    0.737, 1.000, 0.205,\n    0.255, 0.205, 1.000\n  ),\n  nrow = 3\n)\n\n# Create mean vector\nmeans = c(0, 0, 0) \n\n# Set sample size\nn = 1000"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#simulating-data-cntd.",
    "href": "notes/03-02-path-analysis.html#simulating-data-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Simulating Data (cntd.)",
    "text": "Simulating Data (cntd.)\n\n# Make simulation reproducible\nset.seed(1)\n\n\n# Simulate the data and convert to data frame\nsim_dat &lt;- data.frame(MASS::mvrnorm(n = 1000, mu = means, Sigma = corrs, empirical = TRUE)) |&gt;\n  rename(\n    achievement = X1,\n    ability = X2, \n    motivation = X3\n  )\n\n\n# View simulated data\nhead(sim_dat)\n\n  achievement     ability  motivation\n1  -0.5157929 -0.96667633  0.95967280\n2  -0.1533491 -1.50764502  0.65576719\n3  -0.4205593  0.97389153 -0.40326809\n4   1.5952036  1.11549647  0.15201335\n5   0.2921577  0.08731381  0.03244754\n6  -0.9016836  0.15578506 -1.32479673"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#reading-a-path-diagram",
    "href": "notes/03-02-path-analysis.html#reading-a-path-diagram",
    "title": "üé∂ Path Analysis",
    "section": "Reading a Path Diagram",
    "text": "Reading a Path Diagram\nIn a path diagram,\n\nVariables we have data on (i.e., manifest or measured variables) are represented by squares or rectangles.\nLines between the variables indicate a relationship between the two connected variables. The lines between the different variables are called paths.\n\nIf the path has an arrowhead on both sides, it indicates the two connected variables are related (i.e., correlated).\nIf the path has an arrowhead on only one side, it indicates a hypothesized causal relationship. The cause is in the direction of the arrow; that is, the hypothesized cause is at the butt end of the line, while the hypothesized effect is at the arrowhead side of the line."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#reading-a-path-diagram-cntd.",
    "href": "notes/03-02-path-analysis.html#reading-a-path-diagram-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Reading a Path Diagram (cntd.)",
    "text": "Reading a Path Diagram (cntd.)"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#two-example-path-diagrams",
    "href": "notes/03-02-path-analysis.html#two-example-path-diagrams",
    "title": "üé∂ Path Analysis",
    "section": "Two Example Path Diagrams",
    "text": "Two Example Path Diagrams\n\nIn both of the examples below, there are three manifest/measured variables (academic ability, motivation, and achievement) and three paths (p1, p2, and p3). The difference between the two is that in the right-hand diagram, there are hypothesized causal relationships, while in the left-hand diagram the relationships are not presumed to be causal."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#path-diagram-1",
    "href": "notes/03-02-path-analysis.html#path-diagram-1",
    "title": "üé∂ Path Analysis",
    "section": "Path Diagram 1",
    "text": "Path Diagram 1\n\n\n\n\n\n\n\n\n\n\n\n\nThe model depicted in this path diagram posits that there are relationships between:\n\nAcademic ability and achievement (p1);\nAcademic ability and motivation (p2); and\nMotivation and achievement (p3).\n\nThe double-headed arrows on the paths indicate that the variables are related (i.e., correlated), although there is no causal direction hypothesized."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-path-coefficients-in-path-diagram-1",
    "href": "notes/03-02-path-analysis.html#estimating-path-coefficients-in-path-diagram-1",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Path Coefficients in Path Diagram 1",
    "text": "Estimating Path Coefficients in Path Diagram 1\n\nIn a path analysis, one goal is to estimate path coefficients. In this model, since the paths represent the relationship between two variables, the path coefficients are simply the bivariate correlations between each set of variables.\n\n# Compute correlations\nsim_dat |&gt;\n  correlate()\n\n# A tibble: 3 √ó 4\n  term        achievement ability motivation\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 achievement      NA       0.737      0.255\n2 ability           0.737  NA          0.205\n3 motivation        0.255   0.205     NA"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#weak-causal-ordering",
    "href": "notes/03-02-path-analysis.html#weak-causal-ordering",
    "title": "üé∂ Path Analysis",
    "section": "Weak Causal Ordering",
    "text": "Weak Causal Ordering\nIn path modeling, we often assert weak causal ordering on the variables in the model. With weak causal ordering, we are not saying X causes Y, but rather that if X and Y are casually related, one of these variables (typically X) is the cause of the other.\n\n\n\n\nflowchart LR\n  A[X] --&gt; B[Y]\n\n\n\n\n\nIn this model, the paths have arrows at only one end indicating the hypothesized causal relationship. The cause is in the direction of the arrow, that is the hypothesized cause is at the butt end of the line, while the hypothesized effect is at the arrowhead side of the line.\n\nAny weak causal model should be posited prior to collecting or looking at the data! Creating this model can also help you identify the data to collect."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#path-model-2-weak-causal-ordering",
    "href": "notes/03-02-path-analysis.html#path-model-2-weak-causal-ordering",
    "title": "üé∂ Path Analysis",
    "section": "Path Model 2: Weak Causal Ordering",
    "text": "Path Model 2: Weak Causal Ordering\n\n\n\n\n\n\n\n\n\n\n\n\nThe model depicted in this path diagram posits the following causal relationships:\n\nIf academic ability and achievement are causally related, then academic ability is the cause of achievement.\nIf academic ability and motivation are causally related, then academic ability is the cause of motivation.\nIf motivation and achievement are causally related, then motivation is the cause of achievement."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-path-coefficients-in-a-weak-causal-model",
    "href": "notes/03-02-path-analysis.html#estimating-path-coefficients-in-a-weak-causal-model",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Path Coefficients in a Weak Causal Model",
    "text": "Estimating Path Coefficients in a Weak Causal Model\nAgain, we would want to estimate the path coefficients shown in the diagram for the weak causal model. In causal models, the path coefficients are not necessarily the correlations. To find the path coefficients we need to use the tracing rule. The tracing rule indicates that:\n\nThe correlation between two variables X and Y is equal to the sum of the possible products of all possible paths from each possible tracing from X to Y, with the following two exceptions:\n\nThe same variable is not entered more than once in the same tracing.\nA variable is not both entered and exited through an arrowhead."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#example-of-the-tracing-rule",
    "href": "notes/03-02-path-analysis.html#example-of-the-tracing-rule",
    "title": "üé∂ Path Analysis",
    "section": "Example of the Tracing Rule",
    "text": "Example of the Tracing Rule\nAs an example, consider all the tracings (routes) that allow us to start at the academic ability variable and go to the achievement variable in the path diagram at right.\n\n\n\n\n\n\n\n\n\n\n\n\nThere are two possible tracings that conform to the tracing rule:\n\nStart at the academic ability variable and take p1 to the achievement variable.\nStart at the academic ability variable and take p2 to the motivation variable, then take p3 to the achievement variable."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#example-of-the-tracing-rule-cntd.",
    "href": "notes/03-02-path-analysis.html#example-of-the-tracing-rule-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Example of the Tracing Rule (cntd.)",
    "text": "Example of the Tracing Rule (cntd.)\nSimilarly, we could have started at the achievement variable and determined the tracings to get to the academic ability variable:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStart at the achievement variable and take p1 to the academic ability variable.\nStart at the achievement variable and take p3 to the motivation variable, then take p2 to the academic ability variable."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#important-note-regarding-the-tracing-rule",
    "href": "notes/03-02-path-analysis.html#important-note-regarding-the-tracing-rule",
    "title": "üé∂ Path Analysis",
    "section": "Important Note Regarding the Tracing Rule",
    "text": "Important Note Regarding the Tracing Rule\nNote that when we are considering tracings, we do not have to worry about the direction of the arrow, only that there is a path we can trace. The only rule regarding arrowheads is that a variable can not be both entered and exited through an arrowhead."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#back-to-estimating-the-path-coeffients",
    "href": "notes/03-02-path-analysis.html#back-to-estimating-the-path-coeffients",
    "title": "üé∂ Path Analysis",
    "section": "Back to Estimating the Path Coeffients",
    "text": "Back to Estimating the Path Coeffients\nEach tracing yields a product of the path coefficents used in the tracing. Thus the first tracing is \\(p1\\) (there is only one path, so the product is simply the path), and the second tracing yields \\(p2 \\times p3\\). Since the tracing rule says that the correlation between academic ability and achievement is equal to the sum of the products yielded by the tracings, we know that:\n\\[\n\\begin{split}\nr_{\\mathrm{academic~ability,~ achievement}} &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + p2(p3)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#your-turn",
    "href": "notes/03-02-path-analysis.html#your-turn",
    "title": "üé∂ Path Analysis",
    "section": "Your Turn",
    "text": "Your Turn\nUse the tracing rule to write two more equations. The first equation should represent the correlation between motivation and achievement, and the second equation should represent the correlation between ability and motivation."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#check-your-work",
    "href": "notes/03-02-path-analysis.html#check-your-work",
    "title": "üé∂ Path Analysis",
    "section": "Check Your Work",
    "text": "Check Your Work\n\n\n\n\n\n\n\n\n\n\n\n\nTo represent the correlation between motivation and achievement we have two potential tracings:\n\nStart at the motivation and take p3 to the achievement variable.\nStart at the motivation variable and take p2 to the academic ability variable, then take p1 to the achievement variable.\n\n\\[\n\\begin{split}\nr_{\\mathrm{motivation,~ achievement}} &= p3 + p2(p1) \\\\[1em]\n.255&= p3 + p2(p1)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#check-your-work-1",
    "href": "notes/03-02-path-analysis.html#check-your-work-1",
    "title": "üé∂ Path Analysis",
    "section": "Check Your Work",
    "text": "Check Your Work\n\n\n\n\n\n\n\n\n\n\n\n\nTo represent the correlation between academic ability and motivation we have one tracing:\n\nStart at the academic ability and take p2 to the motivation variable.\n\n\\[\n\\begin{split}\nr_{\\mathrm{academic~ability,~ motivation}} &= p2 \\\\[1em]\n.205&= p2\n\\end{split}\n\\]\nQUESTION: Why can‚Äôt we use the tracing that takes p1 from academic ability to achievement then takes p3 to motivation??"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#solving-for-p1-p2-and-p3",
    "href": "notes/03-02-path-analysis.html#solving-for-p1-p2-and-p3",
    "title": "üé∂ Path Analysis",
    "section": "Solving for p1, p2, and p3",
    "text": "Solving for p1, p2, and p3\n\nEquationsp1p3Back to p1\n\n\nWe now have three equations with three unknowns. We can solve this system of equations to find p1, p2, and p3.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.255 &= p3 + p2(p1) \\\\[1em]\n.205 &= p2\n\\end{split}\n\\]\n\n\nSubstitute in .205 for p2 in the first equation and solve for p1.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + .205(p3) \\\\[1em]\np1 &= .737 - .205(p3)\n\\end{split}\n\\]\n\n\nNow substitute .205 in for p2 and \\(.737 - .205(p3)\\) in for p1 in the second equation and solve for p3.\n\\[\n\\begin{split}\n.255 &= p3 + p2(p1) \\\\[1em]\n.255 &= p3 + .205(.737 - .205(p3)) \\\\[1em]\n.255 &= p3 + 0.151085 - 0.042025(p3) \\\\[1em]\n0.103915 &= 0.957975(p3) \\\\[1em]\np3 &= .108\n\\end{split}\n\\]\n\n\nNow substitute .205 in for p2 and .108 in for p3 in the first equation and solve for p1.\n\\[\n\\begin{split}\n.737 &= p1 + p2(p3) \\\\[1em]\n.737 &= p1 + .205(.108) \\\\[1em]\n.737 &= p1 + 0.02214 \\\\[1em]\np1 &= .715\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#path-diagram-with-estimated-path-coefficients",
    "href": "notes/03-02-path-analysis.html#path-diagram-with-estimated-path-coefficients",
    "title": "üé∂ Path Analysis",
    "section": "Path Diagram with Estimated Path Coefficients",
    "text": "Path Diagram with Estimated Path Coefficients"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#interpreting-path-coefficients",
    "href": "notes/03-02-path-analysis.html#interpreting-path-coefficients",
    "title": "üé∂ Path Analysis",
    "section": "Interpreting Path Coefficients",
    "text": "Interpreting Path Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\nPath coefficients are standardized coefficients which can be interpreted similar to standardized regression coefficients.\n\nGiven the adequacy of the path model, each 1-standard deviation increase in motivation increases achievement by .108 standard deviations, on average.\nGiven the adequacy of the path model, each 1-standard deviation increase in academic ability increases achievement by .715 standard deviations, on average.\nGiven the adequacy of the path model, each 1-standard deviation increase in academic ability increases motivation by .205 standard deviations, on average."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#interpreting-path-coefficients-cntd.",
    "href": "notes/03-02-path-analysis.html#interpreting-path-coefficients-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Interpreting Path Coefficients (cntd.)",
    "text": "Interpreting Path Coefficients (cntd.)\nThere are two things to note when we interpret path coefficients that are different from when we interpret regression coefficients.\n\nWe include ‚Äúgiven the adequacy of the model‚Äù in our interpretation. This is important because the values of the path coefficients absolutely depend on the weak causal model specified (i.e., how you draw the path diagram).\nBecause we are positing a causal relationship, we can use the causal type language in our interpretation. E.g., an increase in X leads to an increase in Y.\n\nNote also that the interpretation is not controlling for anything. These are simple relationships that we are interpreting."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-path-coefficients-via-regression",
    "href": "notes/03-02-path-analysis.html#estimating-path-coefficients-via-regression",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Path Coefficients via Regression",
    "text": "Estimating Path Coefficients via Regression\n\nWe can also find the path coefficients using regression rather than algebra. To determine the path coefficients in the weak causal model, we fit a set of regression models using the ‚Äúcauses‚Äù as predictors of any particular effect.\n\n\n\n\n\n\n\n\n\n\nIn our path diagram there are two effects, so we would need to fit two separate regression models. The syntax for these models would be:\nachievement ~ 0 + ability + motivation\nmotivation ~ 0 + ability"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-path-coefficients-via-regression-cntd.",
    "href": "notes/03-02-path-analysis.html#estimating-path-coefficients-via-regression-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Path Coefficients via Regression (cntd.)",
    "text": "Estimating Path Coefficients via Regression (cntd.)\n\n# Path coefficients for paths to achievement\ntidy(lm(achievement ~ 0 + ability + motivation, data = sim_dat))\n\n# A tibble: 2 √ó 5\n  term       estimate std.error statistic   p.value\n  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 ability       0.715    0.0216     33.1  8.26e-163\n2 motivation    0.108    0.0216      5.02 5.97e-  7\n\n\n\n\n# Path coefficient for paths to motivation\ntidy(lm(motivation ~ 0 + ability, data = sim_dat))\n\n# A tibble: 1 √ó 5\n  term    estimate std.error statistic  p.value\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 ability    0.205    0.0310      6.62 5.85e-11"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#residual-variation",
    "href": "notes/03-02-path-analysis.html#residual-variation",
    "title": "üé∂ Path Analysis",
    "section": "Residual Variation",
    "text": "Residual Variation\nEven if the causal relationships were specified correctly, the model likely does not include ALL of the causes for motivation and achievement. There is also unaccounted for variation due to random variation and measurement error. To account for these three sources of variation in the weak causal model, we will add an error term to eavch of the effects in the path model."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-residual-variation",
    "href": "notes/03-02-path-analysis.html#estimating-residual-variation",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Residual Variation",
    "text": "Estimating Residual Variation\nWe can also estimate the path coefficients for the error terms. These path coefficients are computed as,\n\\[\n\\epsilon_k = \\sqrt{1 - R^2_k}\n\\] where, \\(R^2_k\\) is the \\(R^2\\)-value from the regression model fitted to compute the initial path coefficients."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#estimating-residual-variation-cntd.",
    "href": "notes/03-02-path-analysis.html#estimating-residual-variation-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Estimating Residual Variation (cntd.)",
    "text": "Estimating Residual Variation (cntd.)\n\n\n\n# Path coefficients for error term on achievement\nglance(lm(achievement ~ 0 + ability + motivation, data = sim_dat))\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.554         0.554 0.668      621. 6.36e-176     2 -1014. 2034. 2049.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nsqrt(1 - .554)\n\n[1] 0.6678323\n\n\n\n\n# Path coefficient for error term on motivation\nglance(lm(motivation ~ 0 + ability, data = sim_dat))\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0420        0.0411 0.979        NA      NA    NA -1397. 2798. 2808.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nsqrt(1 - .0420)\n\n[1] 0.9787747"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#how-do-we-draw-path-diagram",
    "href": "notes/03-02-path-analysis.html#how-do-we-draw-path-diagram",
    "title": "üé∂ Path Analysis",
    "section": "How Do We Draw Path Diagram?",
    "text": "How Do We Draw Path Diagram?\n\nTheory/prior research\nLogic/expert understanding/common sense\n\nWe also need to pay attention to time precedence. Cause does not operate backward in time. In our example, academic ability is well-documented as something that does not change after grade school. Thus, it would precede motivation and achievement in time."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#a-little-more-about-cause",
    "href": "notes/03-02-path-analysis.html#a-little-more-about-cause",
    "title": "üé∂ Path Analysis",
    "section": "A Little More About Cause",
    "text": "A Little More About Cause\nWhat do we mean when we say ‚ÄúX causes Y‚Äù? Contrary to popular belief, we do not mean that changing X has a direct, and immediate change on Y. For example, it is now well known that smoking causes lung cancer.\n\nBut, not everyone who smokes ends up getting lung cancer."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#a-little-more-about-cause-cntd.",
    "href": "notes/03-02-path-analysis.html#a-little-more-about-cause-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "A Little More About Cause (cntd.)",
    "text": "A Little More About Cause (cntd.)\nInstead, cause is a probabilistic statement about the world. When we say smoking causes lung cancer what we mean, statistically, is that smoking increases the probability of developing lung cancer.\n\nMoreover, this increased probability is due to smoking, and not something else."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#requirements-for-cause",
    "href": "notes/03-02-path-analysis.html#requirements-for-cause",
    "title": "üé∂ Path Analysis",
    "section": "Requirements for Cause",
    "text": "Requirements for Cause\nThere are three primary requirements for a causal relationship between X and Y.\n\nThere must be a relationship between X and Y. (Correlation is a necessary component of causation.)\nTime precedence (Causes must occur prior to effects.)\nRelationship must not be spurious."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#including-time-precedence-in-the-path-diagram",
    "href": "notes/03-02-path-analysis.html#including-time-precedence-in-the-path-diagram",
    "title": "üé∂ Path Analysis",
    "section": "Including Time Precedence in the Path Diagram",
    "text": "Including Time Precedence in the Path Diagram\nTime precedence is often reflected in the orientation of the model. Variables that occur earlier in time are oriented further to the left side of the diagram than variables that occur later.\n\n\n\n\n\n\n\n\n\nIn the smoking example, to be considered the cause for lung cancer, smoking has to occur prior to the onset of lung cancer.1\nNote that the top‚Äìbottom orientation typically doesn‚Äôt mean anything‚Äîit is just used for aesthetics in the layout."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#including-time-precedence-in-the-path-diagram-cntd.",
    "href": "notes/03-02-path-analysis.html#including-time-precedence-in-the-path-diagram-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Including Time Precedence in the Path Diagram (cntd.)",
    "text": "Including Time Precedence in the Path Diagram (cntd.)\nIn our path diagram relating academic ability and motivation to acheivement, academic ability is furthest to the left (it occurs earliest), followed by motivation, and then academic achievement."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#common-cause",
    "href": "notes/03-02-path-analysis.html#common-cause",
    "title": "üé∂ Path Analysis",
    "section": "Common Cause",
    "text": "Common Cause\nA common cause is a variable that is a cause of both X and Y which accounts for the relationship between X and Y. Consider the following example where we want to look at the causal impact of participation in Head Start programs on academic achievement.\n\nIn practice, the path coefficient tends to be negative. That is Head Start participants tend to have lower academic achievement than their non-Head Start peers."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#common-cause-cntd.",
    "href": "notes/03-02-path-analysis.html#common-cause-cntd.",
    "title": "üé∂ Path Analysis",
    "section": "Common Cause (cntd.)",
    "text": "Common Cause (cntd.)\nA common cause of both Head Start participation and academic achievement is poverty. This is shown below.\n\nOnce we include poverty as a common cause, the path coefficient between Head Start participation and academic achievement switches direction. That is, after including poverty in the path model, Head Start participants tend to have higher academic achievement than their non-Head Start peers. This is akin to how effects in a regression model might change after we control for other predictors."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#common-cause-cntd.-1",
    "href": "notes/03-02-path-analysis.html#common-cause-cntd.-1",
    "title": "üé∂ Path Analysis",
    "section": "Common Cause (cntd.)",
    "text": "Common Cause (cntd.)\nIn order to meet the third causal requirement, we need to include ALL common causes in the model. This requirement is the hardest to prove."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#non-recursive-models",
    "href": "notes/03-02-path-analysis.html#non-recursive-models",
    "title": "üé∂ Path Analysis",
    "section": "Non-Recursive Models",
    "text": "Non-Recursive Models\nIn the path diagrams we have looked at so far, the causal paths have gone in only one direction; there is a distinct cause and effect. The error terms on the effect variables are also all uncorrelated. These are called recursive models. It is possible for variables to effect each other (e.g., predator‚Äìprey relationships), or for the error terms to be correlated. This is called a non-recursive model."
  },
  {
    "objectID": "notes/03-02-path-analysis.html#under-identified-models",
    "href": "notes/03-02-path-analysis.html#under-identified-models",
    "title": "üé∂ Path Analysis",
    "section": "Under-Identified Models",
    "text": "Under-Identified Models\nThe problem with estimating the path coefficients in the non-recursive model is it is under-identified. In our predator‚Äìprey model, we need to estimate four path coefficients, but only have three correlations (equations) from which to do so. We can‚Äôt solve this without adding additional constraints!\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{split}\nr_{\\mathrm{H,W}} &= p1 + p2(p4) \\\\[1em]\nr_{\\mathrm{H,R}} &= p2 + p1(p3) \\\\[1em]\nr_{\\mathrm{H,W}} &= p3 + p4 + p1(p2)\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/03-02-path-analysis.html#over-identified-models",
    "href": "notes/03-02-path-analysis.html#over-identified-models",
    "title": "üé∂ Path Analysis",
    "section": "Over-Identified Models",
    "text": "Over-Identified Models"
  },
  {
    "objectID": "notes/03-03-more-path-analysis.html",
    "href": "notes/03-03-more-path-analysis.html",
    "title": "üìù More Path Analysis",
    "section": "",
    "text": "In this set of notes, we will use the data from path-model-achievement.csv to fit a path model to explain effects on high school achievement. The data were simulated to include attributes for 1000 students from information provided by Keith (2015).\n\n[CSV]\n[R Script File]\n\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(lavaan)\n\n# Import data\nkeith = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/path-model-achievement.csv\")\nkeith\n\n\n\n  \n\n\n\n\n\nHypothesized Path Model\nThe hypothesized path model is shown below. This model was based on previous literature related to student achievement and on Keith‚Äôs experiences as an educator and educational researcher.\n\n\n\n\n\nFigure¬†1: Hypothesized path model for several predictors of high school achievement.\n\n\n\n\n\n\n\nEstimating the Path Coefficients\nWe need to estimate 10 path coefficients between the measured variables and four additional paths between unmeasured variables and each of the measured effects. To do this we can use a regression model that includes the hypothesized causes to predict variation in each of the effects. The regression coefficients obtained are the path coefficients between each of the hypothesized causes and effect.\nFor example, the variable high school motivation is an effect in our model (i.e., it has arrows going into it). The hypothesized causes of high school motivation are family background, and academic ability. To obtain those two path coefficients:\n\n# Fit model\nlm.motivation = lm(motivation ~ 1 + fam_back + ability, data = keith)\n\n# Obtain path coefficients\ntidy(lm.motivation)\n\n\n\n  \n\n\n\nThe path coefficient for the path from family background to high school motivation (p4) is 0.127, and that for the path from academic ability to high school motivation (p7) is 0.152. These represent the direct effects of family background and academic ability on high school motivation, respectively. Here we interpret the direct effect of academic ability on high school motivation:\n\nGiven the adequacy of our model, academic ability has a small positive effect on high school motivation. Each one-standard deviation increase in academic ability will result in a 0.127-standard deviation unit change on high school motivation, on average.\n\nWe can also estimate the path between the unmeasured variables (\\(d_2\\)) and high school motivation. This is computed as:\n\\[\n\\sqrt{1-R^2}\n\\]\nwhere \\(R^2\\) is the coefficient of determination from the fitted regression. In our example\n\n# Obtain R2\nglance(lm.motivation)\n\n\n\n  \n\n\n# Compute path\nsqrt(1 - 0.0552)\n\n[1] 0.9720082\n\n\nThe path between \\(d_2\\) and high school motivation is 0.972. This represents the effects of all other causes of high school motivation that we did not include in our hypothesized path model. This suggests that many of the influences of high school motivation are unaccounted for by the path model. Presumably, these are not important in positing the causal model. (Note if they are important, they should be included as measured variables in the path model.) The regression models to estimate the remaining paths are provided below (output not given), as well as the path estimates for the hypothesized path model.\n\n# Effect: Academic Ability\nlm.abilty = lm(ability ~ 1 + fam_back, data = sim_dat)\ntidy(lm.abilty)\nglance(lm.abilty)\nsqrt(1 - 0.174)\n\n# Effect: High School Coursework\nlm.coursework = lm(coursework ~ 1 + fam_back + ability + motivation, data = sim_dat)\ntidy(lm.coursework)\nglance(lm.coursework)\nsqrt(1 - 0.348)\n\n# Effect: High School Achievement\nlm.achieve = lm(achieve ~ 1 + fam_back + ability + motivation + coursework, data = sim_dat)\ntidy(achieve)\nglance(lm.achieve)\nsqrt(1 - 0.629)\n\n\n\n\n\n\nFigure¬†2: Hypothesized path model for several predictors of high school achievement. The path estimates are also included.\n\n\n\n\n\n\n\nEstimating Effects\nWe can now use the path coefficients to estimate the effects on high school achievement. Based on the hypothesized path model, each of the measured variables has a direct effect on high school achievement.\n\nThe direct effect of family background on high school achievement is 0.069.\nThe direct effect of academic ability on high school achievement is 0.551.\nThe direct effect of high school motivation on high school achievement is 0.013.\nThe direct effect of high school coursework on high school achievement is 0.310.\n\nThere are also indirect effects of these four causes of high school achievement. For example high school motivation not only directly influences high school achievement, but also influences it by influencing high school coursework (i.e., more motivated students take higher level courses which results in higher achievement).\nEach indirect effect is computed as the product of the path coefficients connecting the potential cause and effect. For example, the indirect effect of high school motivation on high school achievement via high school coursework is:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effect} &= 0.267 \\times 0.310 \\\\[1em]\n&= 0.083\n\\end{split}\n\\]\nFor some of these measured variables there are multiple indirect effects on achievement. The overall indirect effects are computed as the sum of each of the indirect effects. For example the indirect effects of academic ability on high school achievement are:\n\nAcademic ability influences high school coursework which, in turn, influences high school achievement. This indirect effect is \\(0.374 \\times 0.310 = 0.083\\)\nAcademic ability influences high school motivation which, in turn, influences high school achievement. This indirect effect is \\(0.152 \\times 0.013 = 0.002\\)\nAcademic ability influences high school motivation which, in turn, influences high school coursework, which then influences high school achievement. This indirect effect is \\(0.152 \\times 0.267 \\times 0.310 = 0.013\\)\n\nThus the overall indirect effects of academic ability on high school achievement is:\n\\[\n\\begin{split}\n\\mathrm{All~Indirect~Effects} &=  (0.374 \\times 0.310) + (0.152 \\times 0.013) + (0.152 \\times 0.267 \\times 0.310) \\\\[1em]\n&= 0.130\n\\end{split}\n\\]\nThe sum total of the direct and indirect effects give us the total effect of each hypothesized cause. For example, the total effect of academic ability on high school achievement is:\n\\[\n\\begin{split}\n\\mathrm{Total~Effects} &=  0.551 + 0.130 \\\\[1em]\n&= 0.681\n\\end{split}\n\\]\nPutting all of this together,\n\nGiven the adequacy of our model, academic ability has a fairly large, positive effect on high school achievement. Each one-standard deviation increase in academic ability will result in a 0.681-standard deviation unit change in high school achievement, on average. Much of that influence is from the direct effect of academic ability on high school achievement (\\(\\hat\\beta=0.551\\)). A small part of academic ability‚Äôs effect on high school achievement is due to its influence on other factors (e.g., motivation) which, in turn, effect high school achievement.\n\nThe table below gives the direct, indirect, and total effects for each of the hypothesized causes of high school achievement.\n\n\n\nStandardized direct, indirect, and total effects of substantive predictors influencing high school achievment. \n\n\n\n\n\n\n\n\n\n\nEffect\n\n\n\nMeasure\nDirect\nIndirect\nTotal\n\n\n\n\nFamily Background\n0.069\n0.348\n0.417\n\n\nAcademic Ability\n0.551\n0.131\n0.682\n\n\nHigh School Motivation\n0.013\n0.083\n0.096\n\n\nHigh School Coursework\n0.310\n---\n0.310\n\n\n\n\n\n\n\nThe largest direct influences of high school achievement are from high school coursework and academic ability. Family background also has a large influence on high school achievement, but primarily indirectly. Lastly, high school motivation has a small effect both directly and indirectly on high school achievement.\n\n\n\nFitting the Path Model with lavaan\nThe {lavaan} package includes the sem() function, which can estimate coefficients in a path model. To use this function, we define the path model by identifying each of the effects on a separate line in a character string. This string takes the model formula from each of the lm() functions we fitted earlier. We can also include the path names as multipliers of the influences in this model formula. Here we use the paths from our hypothesized path model to define the effects in the path model:\n\n# Define path model\npath.model = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n\"\n\nThen we can give this model as input to the sem() function along with the data frame that includes the data to estimate the model. We assign this to an object and use summary() to obtain the results. The rsquare=TRUE argument in summary() print the \\(R^2\\) values, the latter of which we can use to estimate the paths from the unmeasured variables to the respective effects. You can also include other options to output additional estimates (e.g., ci = TRUE for confidence intervals). See here for additional information.\n\n# Fit model\npm.1 = sem(path.model, data = keith)\n\n# Results\nsummary(pm.1, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\n\nWe can also estimate and obtain tests for the indirect effects as well. To do this we need to add model syntax defining each indirect effect we wish to include. This model syntax uses the path names to define how to compute that effect. For example to include the indirect effect of academic ability on high school achievement via high school motivation we would add the following line into our character string:\nindirect_ability_via_motivation := p7*p8\nThe path model would then be defined and fitted:\n\n# Define path model\npath.model.2 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_ability_via_motivation := p7*p8\n\"\n\n# Fit model\npm.2 = sem(path.model.2, data = keith)\n\n# Results\nsummary(pm.2, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indrct_blty_v_    0.002    0.003    0.599    0.549\n\n\nHere the indirect effect of academic ability on high school achievement via high school motivation is not statistically significant. This is likely because the direct effect of high school motivation on high school achievement is also not statistically significant (i.e., if that path is 0 then the product we get when computing the indirect effect will also be 0).\nHere we define and compute the overall indirect effects for each of the hypothesized causes:\n\n# Define path model\npath.model.3 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p8 + p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n\"\n\n# Fit model\npm.3 = sem(path.model.3, data = keith)\n\n# Results\nsummary(pm.2, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indrct_blty_v_    0.002    0.003    0.599    0.549\n\n\nFinally, we can fit a path model and estimate the direct, indirect, and total effects.\n\n# Define path model\npath.model.4 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p8*motivation + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p8 + p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n  total_fam_back := p3 + p1*p5*p10 + p1*p6 + p1*p7*p8 + p1*p7*p9*p10 + p4*p8 + p4*p9*p10 + p2*p10\n  total_ability := p6 + p7*p8 + p7*p9*p10 + p5*p10\n  total_motivation := p8 + p9*p10\n  total_coursework := p10\n\"\n\n# Fit model\npm.4 = sem(path.model.4, data = keith)\n\n# Results\nsummary(pm.4, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.069    0.022    3.202    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    motivatn  (p8)    0.013    0.021    0.604    0.546\n    courswrk (p10)    0.310    0.024   12.996    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indirct_fm_bck    0.348    0.024   14.751    0.000\n    indirect_ablty    0.131    0.013    9.868    0.000\n    indirect_mtvtn    0.083    0.010    8.003    0.000\n    total_fam_back    0.417    0.029   14.508    0.000\n    total_ability     0.682    0.023   29.460    0.000\n    total_motivatn    0.095    0.021    4.448    0.000\n    total_courswrk    0.310    0.024   12.996    0.000\n\n\n\n\n\nEmpirically Reducing the Model\nThe path between high school motivation and and high school achievement was not statistically significant (p = 0.546). This suggests that the effect we saw in the data may be attributable to sampling variation. One possibility is to reduce the model by removing this path.\n\n\n\n\n\nReduced path model for several predictors of high school achievement. In this model the direct effect between high school motivation and high school achievement was removed (path p8).\n\n\n\n\nNote that removing a path can change both direct and indirect effects. In our path model, we would need to remove any path that traverses through path p8. There are two approaches to doing this:\nOne approach is to remove the path and use the original estimates to re-compute the direct, indirect, and total effects. For example, to compute the indirect effects of academic ability on high school achievement we would use:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effects} &=  (0.374 \\times 0.310)  + (0.152 \\times 0.267 \\times 0.310) \\\\[1em]\n&= 0.128521\n\\end{split}\n\\]\nA second approach is to re-fit the model to the empirical data. The fitted path model is shown below.\n\n# Define path model\npath.model.5 = \"\n  ability ~ p1*fam_back\n  motivation ~ p4*fam_back + p7*ability\n  coursework ~ p2*fam_back + p5*ability + p9*motivation\n  achieve ~ p3*fam_back + p6*ability + p10*coursework\n  indirect_fam_back := p1*p5*p10 + p1*p6  + p1*p7*p9*p10 + p4*p9*p10 + p2*p10\n  indirect_ability := p7*p9*p10 + p5*p10\n  indirect_motivation := p9*p10\n  total_fam_back := p3 + p1*p5*p10 + p1*p6  + p1*p7*p9*p10 + p4*p9*p10 + p2*p10\n  total_ability := p6 + p7*p9*p10 + p5*p10\n  total_coursework := p10\n\"\n\n# Fit model\npm.5 = sem(path.model.5, data = keith)\n\n# Results\nsummary(pm.5, rsquare = TRUE)\n\nlavaan 0.6.15 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.365\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.546\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ability ~                                           \n    fam_back  (p1)    0.417    0.029   14.508    0.000\n  motivation ~                                        \n    fam_back  (p4)    0.127    0.034    3.741    0.000\n    ability   (p7)    0.152    0.034    4.502    0.000\n  coursework ~                                        \n    fam_back  (p2)    0.165    0.028    5.838    0.000\n    ability   (p5)    0.374    0.028   13.194    0.000\n    motivatn  (p9)    0.267    0.026   10.158    0.000\n  achieve ~                                           \n    fam_back  (p3)    0.070    0.022    3.240    0.001\n    ability   (p6)    0.551    0.023   23.758    0.000\n    courswrk (p10)    0.314    0.023   13.841    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ability           0.825    0.037   22.361    0.000\n   .motivation        0.944    0.042   22.361    0.000\n   .coursework        0.651    0.029   22.361    0.000\n   .achieve           0.371    0.017   22.361    0.000\n\nR-Square:\n                   Estimate\n    ability           0.174\n    motivation        0.055\n    coursework        0.348\n    achieve           0.629\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    indirct_fm_bck    0.347    0.024   14.740    0.000\n    indirect_ablty    0.130    0.013    9.866    0.000\n    indirect_mtvtn    0.084    0.010    8.189    0.000\n    total_fam_back    0.417    0.029   14.508    0.000\n    total_ability     0.682    0.023   29.460    0.000\n    total_courswrk    0.314    0.023   13.841    0.000\n\n\nComputing the indirect effects of academic ability on high school achievement for this re-fitted model we would use:\n\\[\n\\begin{split}\n\\mathrm{Indirect~Effects} &=  (0.374 \\times 0.314)  + (0.152 \\times 0.267 \\times 0.314) \\\\[1em]\n&= 0.1301794\n\\end{split}\n\\]\nOr, we could extract the estimate for indirect_ablty from the output. To get these results to more decimal places, we can use the parameterEstimates() function, which outputs a data frame of the results. We want to extract the est column, which includes the estimates. Note that the indirect effects of academic ability on high school achievement is the 16th element of the est vector.\n\n# Data frame of parameter estimates\nparameterEstimates(pm.5)\n\n\n\n  \n\n\n# Estimates column\nparameterEstimates(pm.5)$est\n\n [1] 0.41700000 0.12651448 0.15224346 0.16516282 0.37442021 0.26686292\n [7] 0.07021160 0.55114506 0.31441104 0.82528489 0.94380759 0.65137255\n[13] 0.37079389 0.99900000 0.34678840 0.13049578 0.08390465 0.41700000\n[19] 0.68164084 0.31441104\n\n# Indirect effects of academic ability on high school achievement\nparameterEstimates(pm.5)$est[16]\n\n[1] 0.1304958\n\n\nWhether you reduce the model and re-fit it to the data, or use the estimates from the original fitted model and set non-significant effects to zero, the differences are minimal; in this case only one of the path coefficients changed when rounded to three decimal places.\n\n\n\n\n\nReferences\n\nKeith, T. V. (2015). Multiple regression and beyond: An introduction to multiple regression and structural equation modeling (2nd ed.). New York: Routledge."
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html",
    "href": "notes/04-01-regression-diagnostics.html",
    "title": "üìù Regression Diagnostics",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to empirical diagnostics to detect extreme observations. We will use the contraception.csv data to evaluate the effect of female education level on contraception rates.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Import data\ncontraception = read_csv(file = \"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/contraception.csv\")\n\n# View data\ncontraception"
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html#identifying-high-leverage-observations-in-the-contraception-example",
    "href": "notes/04-01-regression-diagnostics.html#identifying-high-leverage-observations-in-the-contraception-example",
    "title": "üìù Regression Diagnostics",
    "section": "Identifying High Leverage Observations in the Contraception Example",
    "text": "Identifying High Leverage Observations in the Contraception Example\nIn practice, we can use the augment() function from the {broom} package to obtain the leverage values for each observation for a fitted model. These values are provided in the .hat column. Previously, we had assigned the augment output for lm.1 to an object called out_1.\n\n# View augmented data\nout_1\n\n\n\n  \n\n\n\nHere, for example, we can see that the leverage value for the first observation is 0.0875. To determine which observations have high leverage, we will create an index plot of the leverage values.\n\n# Add case number to the augmented data\nout_1 = out_1 |&gt;\n  mutate(\n    case = row_number()\n    )\n\n# View augmented data\nout_1\n\n\n\n  \n\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_point(size = 4) +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\n\n\n\n\nWhile it seems we may be able to identify observations with high leverage in this plot, sometimes this can be difficult depending on the data. For example, the two highest observations seem like they probably have high leverage relative to the others, but what about the four observations with leverage values between 0.10 and 0.12?\nOne criterion that applied researchers use is that an observation has high leverage if:\n\\[\nh_{ii} &gt; \\frac{2p}{n}\n\\]\nwhere p is the trace of H, which also happens to be the sum of the \\(h_{ii}\\) values. This implies that,\n\\[\n\\begin{split}\nh_{ii} &&gt; \\frac{2p}{n} \\\\[1em]\n&&gt; \\frac{2\\sum h_{ii}}{n} \\\\[1em]\n&&gt; 2 \\bar{h}\n\\end{split}\n\\]\nwhere \\(\\bar{h}\\) is the average leverage value. Thus, we are identifying observations with a leverage value greater than twice the average value, and those are the observations we are saying have high leverage. It is often useful to draw a horizontal line in the index plot at this value. Below we add in this line, and also plot the observations‚Äô case value rather than plotting points. This helps us identify the cases with high leverage.\n\n# Compute cutoff\ncutoff = 2 * mean(out_1$.hat)\ncutoff\n\n[1] 0.08247423\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_text(aes(label = case)) +\n  geom_hline(yintercept = cutoff, color = \"#cc79a7\") +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their case value. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value.\n\n\n\n\nBased on this criterion, there are several observations that have high leverage values in this model. Since these observations represent countries, and we have country names in the original data, we could also create this index plot using country names to label the observations instead of case numbers.\n\n# Add country names to augmented data\nout_1 = out_1 |&gt;\n  mutate(\n    country = contraception$country\n  )\n\n# View data\nout_1\n\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their country name. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value.\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .hat)) +\n  geom_text(aes(label = country)) +\n  geom_hline(yintercept = cutoff, color = \"#cc79a7\") +\n  theme_bw() +\n  xlab(\"Observation number\") +\n  ylab(\"Leverage value\")\n\n\n\n\nIndex plot of the leverage values from Model 1. Observations are identified by their country name. The reddish-purple line demarcates observations with a leverage value greater than two times the average leverage value."
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html#statistical-test-for-identifying-observations-with-large-residuals",
    "href": "notes/04-01-regression-diagnostics.html#statistical-test-for-identifying-observations-with-large-residuals",
    "title": "üìù Regression Diagnostics",
    "section": "Statistical Test for Identifying Observations with Large Residuals",
    "text": "Statistical Test for Identifying Observations with Large Residuals\nSome educational scientists evaluate whether a particular observation is a regression outlier, by using a hypothesis test to determine whether its residual differs statistically from 0. To do this, we can use a t-test where we evaluate the standardized residual,\n\\[\ne^*_i = \\frac{e_i}{\\mathrm{SE}(e_i)}\n\\]\nThis is evaluated in a t-distribution with df equivalent to the residual degrees-of-freedom from the model. The t-value here looks a lot like the formula we used to compute the standardized residual.\nUnfortunately, we cannot use the standardized residual here since, if we do, the numerator and denominator are not independent (the term \\(s^2_e\\) in the denominator is a function of \\(e_i\\).). This would mean that the resulting statistic is not t-distributed. To fix this problem, we can compute an estimate of \\(s^2_e\\) that is computed based on the regression deleting the ith observation. That is,\n\\[\nt_i = \\frac{e_i}{\\sqrt{s^2_{e(-i)} (1 - h_{ii})}}\n\\] To differentiate this change in the standard error, sometimes statisticians refer to this value as a studentized residual rather than a standardized residual.4\n\n\nComputing the Studentized Residual\nAll of the components to compute the stuentized residuals are provided in the augment() output.\n\n# View augmented output\nout_1\n\n\n\n  \n\n\n\nThe values in the .sigma column are estimates of \\(s_e\\) computed based on the regression deleting the ith observation. That is, they are \\(s_{e(-i)}\\). To compute the studentized residual for Observation 1,\n\\[\n\\begin{split}\nt_1 &= \\frac{e_i}{s_{e(-i)}\\sqrt{(1 - h_{ii})}} \\\\[1em]\n&= \\frac{1.34}{14.5\\sqrt{1 - .0875}} \\\\[1em]\n&= 0.09674318\n\\end{split}\n\\] We can also use this formula to compute the studentized residual for each observation in the augmented() output.\n\n# Compute studentized residuals\nout_1 = out_1 |&gt;\n  mutate(\n    t_i = .resid / (.sigma * sqrt(1 - .hat))\n  )\n\n# View output\nout_1\n\n\n\n  \n\n\n\nAlternatively, we can also use the rstudent() function to compute the studentized residuals directly. This function takes the model object as its input.\n\n# Compute studentized residuals\nout_1 = out_1 |&gt;\n  mutate(\n    t_i = rstudent(lm.1)\n  )\n\n# View output\nout_1\n\n\n\n  \n\n\n\n\n\n\nTesting Observations for Outlyingness\nNow that we have the t-value for each of the residuals, we can evaluate each residual for outlyingness by evaluating each t-statistics in the t-distribution with df equivalent to the residual degrees-of-freedom from the model. In our case,\n\\[\n\\mathit{df} = 93\n\\] Thus, to evaluate whethe the first observation is a regression outlier, we would evaluate\n\\[\nt(93) = 0.097\n\\] to determine if the residual is statistically different than 0. Below, we compute the p-value associated with the first observation.\n\n# Compute p-value for Obs. 1\n2 * pt(-0.097, df = 93)\n\n[1] 0.9229351\n\n\nBecause we need to carry out this test for each of the 97 observations, we need to adjust each p-value based on the number of comparisons. This is typically done by using a Bonferroni adjustment.\n\n# Bonferroni adjustment for Obs. 1\n0.9229351 * 97\n\n[1] 89.5247\n\n\nSince this results in a value greater than 1, and p-values need to be between 0 and 1, we report this p-value as 1. Since this is not statistically significant (at the \\(\\alpha = 0.05\\) level), Observation 1 is not considered a regression outlier. Below is the syntax I use to compute the Bonferroni adjusted p-values for each of the 97 observations.\n\n# Bonferroni adjustment for all observations\nout_1 = out_1 |&gt;\n  mutate(\n    p = 2 * pt(-abs(t_i), df = 97),\n    p_adj = p.adjust(p, method = \"bonferroni\")\n  )\n\n# Order data by adjusted p-values\narrange(out_1, p_adj)\n\n\n\n  \n\n\n\nThese results indicate that none of the observations are more extreme than would be expected given the sample size. In other words, the test would not identify any observations as regression outliers."
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html#dfbetas",
    "href": "notes/04-01-regression-diagnostics.html#dfbetas",
    "title": "üìù Regression Diagnostics",
    "section": "DFBETAS",
    "text": "DFBETAS\nThe most direct way to measure the influence of an observation is to drop that observation from the dataset and measure the difference in regression coefficients. We can define this difference as \\(d_{ij}\\) (the difference between the jth regression coefficient when the ith observation is dropped) as:\n\\[\nd_{ij} = \\hat{\\beta}_j - \\hat{\\beta}_{j(-i)}\n\\]\nThese are referred to as DFBETAs following the naming convention set by Belsley, Kuh, & Welsch (1980). The dfbeta() function computes the DFBETA values for each coefficient for all observations. This function takes the fitted model object as its input. (Here we pipe this output into a data frame for better screen printing in the notes.)\n\ndfbeta(lm.1) |&gt;\n  data.frame()\n\n\n\n  \n\n\n\nPositive DFBETA values indicate that removing the observation results in a lower regression coefficient value, while a negative DFBETA value would indicate that removing the observation results in a higher regression coefficient value. For example, focusing on the interaction term, we see that removing Observation 1 would result in a higher value on the interaction coefficient by .0299 units.\nBecause the DFBETA values are in the same unit as the coefficients, it can sometimes be difficult to assess whether those values are indicative of a small or large amount of influence. To remedy this, the DFBETA values are typically scaled. To do this, the DFBETA value is divided by a scaled RMSE estimate,\n\\[\nd^*_{ij} = \\frac{d_{ij}}{s_{e(-i)}\\sqrt{c_{jj}}}\n\\]\nwhere \\(s_{e(-i)}\\) is the RMSE estimate when the ith observation is deleted from the model, and \\(c_{jj}\\) is the jth diagonal element of the \\((\\mathbf{XX}^\\intercal)^{-1}\\) matrix corresponding to the appropriate regression coefficient. For example, here we compute the \\((\\mathbf{XX}^\\intercal)^{-1}\\) matrix for the fitted model.\n\nX = model.matrix(lm.1)\nsolve(t(X) %*% X)\n\n                     (Intercept)  educ_female    high_gni educ_female:high_gni\n(Intercept)           0.07946790 -0.013509292 -0.07946790          0.013509292\neduc_female          -0.01350929  0.003068899  0.01350929         -0.003068899\nhigh_gni             -0.07946790  0.013509292  0.62476222         -0.070745716\neduc_female:high_gni  0.01350929 -0.003068899 -0.07074572          0.009320611\n\n\nThe \\(c_{jj}\\) value corresponding to the interaction term is 0.009320611.\nAgain, using the .sigma value from the augmented output to obtain \\(s_{e(-i)}\\), we can compute the scaled DFBETA value for the interaction term based on the first observation as:\n\n#Compute scaled DFBETA for interaction term (Obs. 1)\n-0.0299422430 / (14.5 * sqrt(0.009320611))\n\n[1] -0.02138918\n\n\nRemoving Observation 1 would result in a higher value on the interaction coefficient by .0214 standard deviation units. We can use the dfbetas() function to compute all the scaled DFBETA values. (Here we pipe this output into a data frame for better screen printing in the notes.)\n\n# Get scaled DFBETA values\ndfbetas(lm.1) |&gt;\n  data.frame()\n\n\n\n  \n\n\n\nAs with our other measures, it is useful to create an index plot of the scaled DFBETA values. Typically you would create separate index plots for each of the coefficients. Below, I include the scaled DFBETA values in a data frame, and create the index plots. Because we are interested in large scaled DFBETA values regardless of sign, I plot the absolute value of the scaled DFBETA values in each case plot. Here I focus on the index plot associated with the interaction term since that is the primary effect of interests in an interaction model.\n\n# Set up data with case number and scaled DFBETA values\nscl_dfbeta = data.frame(\n  case = 1:97\n) |&gt;\n  cbind(dfbetas(lm.1))\n\n\n# Create index plots\nggplot(data = scl_dfbeta, aes(x = case, y = abs(`educ_female:high_gni`))) +\n  geom_text(aes(label = case), size = 3) +\n  xlab(\"Observation number\") +\n  ylab(\"Scaled DFBETA value\") +\n  theme_bw() +\n  geom_hline(yintercept = 2 / sqrt(97), color = \"#cc79a7\")\n\n\n\n\nIndex plot of the absolute value of the standardized DFBETA values for the interaction effect between female education level and high GNI.\n\n\n\n\nNote that because the variable name included a colon (which is a special character in R syntax), we had to enclose the variable name educ_female:high_gni in back ticks in the ggplot() syntax. We also add a guideline to demarcate observations where \\(\\vert d^*_{ij}\\vert &gt; \\frac{2}{\\sqrt{n}}\\).\nWe want to use the plot to identify cases that have an absolute scaled DFBETA value that is substantially higher than most other observations‚Äô absolute scaled DFBETA values. (The guideline can help us identify these cases.) Observations 53 (Maldives), 84 (Tajikistan), and 41 (Japan) seem to have influence on the interaction coefficient of interest. Observation 19 (Colombia) also may have a modest amount of influence on the interaction term."
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html#cooks-distance",
    "href": "notes/04-01-regression-diagnostics.html#cooks-distance",
    "title": "üìù Regression Diagnostics",
    "section": "Cook‚Äôs Distance",
    "text": "Cook‚Äôs Distance\nWhile the DFBETA and scaled DFBETA values directly measure the impact of an observation on each of the coefficients, these measures of influence are not commonly used in practice. Instead, Cook‚Äôs Distance (Cook, 1977) is a more commonly used measure of influence by applied researchers. This measure is computed as:\n\\[\nD_i = \\frac{(e^*_i)^2}{p + 1} \\times \\frac{h_{ii}}{1 - h_{ii}}\n\\]\nwhere \\(e^*_i\\) is the standardized residual for the ith observation, p is the number of predictors in the fitted model, and \\(h_{ii}\\) is the leverage value for the ith observation. Below we compute Cook‚Äôs Distance for Observation 1 using values obtained from the augment() output.\n\n# Compute D_i for Obs. 1\n0.0976^2 / (3 + 1) * 0.0875 / (1 - 0.0875)\n\n[1] 0.0002283573\n\n\nThe Cook‚Äôs Distance values are also generated in the .cooksd column of the augment() output.\n\n# View augmented output\nout_1\n\n\n\n  \n\n\n\nObservations with a Cook‚Äôs Distance such that \\(D_i &gt; \\frac{4}{n-p-1}\\) are considered influential. In this case, Observation 1 would not be considered influential as its Cook‚Äôs Distance of 0.0002 is not larger than the cutoff of 0.043.\nUnlike the DFBETA measures which computes multiple measures of influence for each observation, Cook‚Äôs Distance computes a single measure of influence for each observation. This measures the overall influence across all of the predictors rather than the influence on any one predictor. (It is probably for this reason that Cook‚Äôs Distance is favored by applied researchers.) We can, once again, create an index plot to plot the Cook‚Äôs Distance values. Within this plot, a guideline can be added to identify cases larger than the cutoff.\n\n# Add case number to data\nout_1 = out_1 |&gt;\n  mutate(case = row_number())\n\n# Create index plot\nggplot(data = out_1, aes(x = case, y = .cooksd)) +\n  geom_text(aes(label = case), size = 3) +\n  xlab(\"Observation number\") +\n  ylab(\"Cook's D value\") +\n  theme_bw() +\n  geom_hline(yintercept = 4 / (97 - 3- 1), color = \"#cc79a7\")\n\n\n\n\nIndex plot of Cook‚Äôs D values for the 97 observations.\n\n\n\n\nBased on the plot, we can identify Observations 84 (Tajikistan), 53 (Maldives), and 41 (Japan) as being influential in the model."
  },
  {
    "objectID": "notes/04-01-regression-diagnostics.html#footnotes",
    "href": "notes/04-01-regression-diagnostics.html#footnotes",
    "title": "üìù Regression Diagnostics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen there is more than one predictor, leverage is measure of how far away an observation is from the centroid of the predictor space.‚Ü©Ô∏é\nBecause we are dividing by the standard error sometimes these are referred to as internally studentized residuals rather than standardized residuals.‚Ü©Ô∏é\nIf the sample size is large, it is better to use the heuristic that regression outliers have a standardized residual more than 3 SEs from zero.‚Ü©Ô∏é\nStudentized residuals are also sometimes referred to as: deleted studentized residuals, externally studentized residuals, and in some books and papers, even as standardized residuals. Ugh.‚Ü©Ô∏é"
  },
  {
    "objectID": "assignments/assignment-01.html",
    "href": "assignments/assignment-01.html",
    "title": "Assignment 01",
    "section": "",
    "text": "The goal of this assignment is to give you experience using matrix algebra to compute various analytic output for regression. In this assignment, you will use the data given below that includes measurements for 10 countries on: infant mortality rate per 1000 live births (infant), the per-capita income (pci) and world region (region) of the country.\n\n\n\n\n\ncountry\ninfant\npci\nregion\n\n\n\n\nAlgeria\n86.3\n400\nAfrica\n\n\nBolivia\n60.4\n200\nAmericas\n\n\nBurundi\n150.0\n68\nAfrica\n\n\nDominican Republic\n48.8\n406\nAmericas\n\n\nKenya\n55.0\n169\nAfrica\n\n\nMalawi\n148.3\n130\nAfrica\n\n\nNicaragua\n46.0\n507\nAmericas\n\n\nParaguay\n38.6\n347\nAmericas\n\n\nRwanda\n132.9\n61\nAfrica\n\n\nTrinidad & Tobago\n26.2\n732\nAmericas\n\n\n\n\n\n\n\n\n\n\n\n\nInstructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 20 points.\n\n\n\nUnstandardized Regression\nYou will be fitting the model lm(infant ~ 1 + pci + region + pci:region). Within this model, use dummy coding to encode the region predictor and make Americas the reference group.\n\nWrite out the elements of the matrix \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\), where \\(\\mathbf{X}\\) is the design matrix.\nDoes \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) have an inverse? Explain.\nCompute (using matrix algebra) and report the vector of coefficients, b for the OLS regression.\nCompute (using matrix algebra) and report the variance‚Äìcovariance matrix of the coefficients.\nUse the values from b (Question 3) and from the variance‚Äìcovariance matrix you reported in the previous question to find the 95% CI for the coefficient associated with the main-effect of PCI. (Hint: If you need to refresh yourself on how CIs are computed, see here.)\nCompute (using matrix algebra) and report the hat-matrix, H. Also show how you would use the values in the hat-matrix to find \\(\\hat{y}_1\\) (the predicted value for Algeria).\nCompute (using matrix algebra) and report the vector of residuals, e.\nCompute (using matrix algebra) and report the estimated value for the RMSE.\nGiven the assumptions of the OLS model and the RMSE estimate you computed in the previous question, compute and report the variance‚Äìcovariance matrix of the residuals.\n\n\n\n\nANOVA Decomposition\nIn this section you will be re-creating the output from the ANOVA decomposition for the model fitted in the previous section.\n\nCompute (using matrix algebra) and report the model, residual, and total sum of squares terms in the ANOVA decomposition table. (2pts)\nCompute (using matrix algebra) and report the model, residual, and total degrees of freedom terms in the ANOVA decomposition table. (2pts)\nUse the values you obtained in Questions 11 and 12 to compute the model and residual mean square terms.\nUse the mean square terms you found in Question 13 to compute the F-value for the model (i.e., to test \\(H_0:\\rho^2=0\\)). Also compute the p-value associated with this F-value. (Hint: If you need to refresh yourself on how F-values or p-values are computed, see here.)\n\n\n\n\nRegression: Effects Coding\nNow consider fitting the model to the data to examine whether there is an effect of region (no other predictors) on infant mortality. In this model, we will use effects coding to encode the region variable (see here). In effects coding, rather than using 0 and 1 (dummy coding), we use +1 and \\(-1\\) to code the different categories.\n\nWrite out the design matrix that would be used to fit this model.\nCompute (using matrix algebra) and report the vector of coefficients, b, from the OLS regression.\nCompute (using matrix algebra) and report the variance‚Äìcovariance matrix for the coefficients.\nExplain why the sampling variances for the coefficients are the same and why the sampling covariance is zero by referring to computations produced in the matrix algebra. (2pts)"
  },
  {
    "objectID": "notes/05-regression-diagnostics.html",
    "href": "notes/05-regression-diagnostics.html",
    "title": "r paste(emo::ji('memo'), 'Regression Diagnostics')",
    "section": "",
    "text": "Here are links to several script files and handouts that we will use in class:\n\nSlides is a set of slides we will cover in class.\nScript File is a script file that provides syntax for generating data from a given population regression model."
  },
  {
    "objectID": "assignments/assignment-02.html",
    "href": "assignments/assignment-02.html",
    "title": "Assignment 02",
    "section": "",
    "text": "The goal of this assignment is to give you experience using simulation to explore properties of the regression model.\n\n\n\n\n\n\nInstructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 16 points.\n\n\n\nSimulation 1: Modeling Heteroskedasticity\nIn this simulation, you will explore what happens to the regression estimates when the assumption of homoskedasticity is violated. For this simulation use a sample size of 200.\n\nCreate the fixed X values you will use in each trial of the simulation. To do this, draw \\(n=200\\) X-values from a uniform distribution with a minimum of \\(-2\\) and a maximum of \\(+2\\). Prior to drawing these values, set your starting seed to 678910. Report the syntax you used, and the first six X values.\nCreate a the Y-values for the first trial of the simulation by using the model:\n\n\\[\n\\begin{split}\ny_i &= -3.2 + 1.75(x_i) + \\epsilon_i \\\\[2ex]\n\\epsilon_i &\\overset{i.i.d.}{\\sim} \\mathcal{N}(0, \\sigma)\n\\end{split}\n\\]\n\nwhere\n\n\\[\n\\begin{split}\n\\sigma &= e^{\\gamma(x_i)}\\\\[2ex]\ne &\\mathrm{~is~Euhler's~constant~}(\\approx2.718282) \\\\[2ex]\n\\gamma &= 1.5\n\\end{split}\n\\]\n\nHere the variation in the random error is a function of X and random noise. Report the syntax you used, and the first six Y values.\n\n\nCreate and report the scatterplot of the Y-values versus the X-values for this first trial of the simulation.\nDescribe the pattern of heteroscedasticity.\nDoes the pattern of heteroscedasticity you described in Question 4 make sense given how the error term was created. Explain.\n\nCarry out 1000 trials of the simulation. (Reminder: Be sure to use these same X values in each trial of the simulation; they are fixed.) For each trial, collect: (a) the estimate of the intercept, (b) the estimate of the slope, and (c) the estimate of the residual standard error.\n\nCompute and report the mean value for the residual standard error.\n\n\n\n\nSimulation 2: Homoskedastic Model\nTo evaluate the different estimates from the heteroskedasticity model, we need to compare them to estimates drawn from a homoskedastic model with the same population coefficients. To make the comparisons ‚Äúfair‚Äù, so that we are only evaluating the effects of the heteroskedasticity, we also need to run this simulation using a residual standard error that is equal to the mean from the heteroskedastic simulation (i.e., \\(\\mathtt{sd\\neq1}\\) in the rnorm() function).\n\nCarry out 1000 trials of the simulation for the appropriate homoskedastic model. (Reminder: Be sure to use these same X values in this simulation as in the previous simulation.) For each trial, collect: (a) the estimate of the intercept, (b) the estimate of the slope, and (c) the estimate of the residual standard error. Report your syntax.\n\n\n\n\nComparing Results from the Two Simulations: Evaluating the Effects of Hetroskedasticity\n\nCreate a density plot of the distribution of intercept estimates. Show the density curve for both models on the same plot, differentiating the curves using color, linetype, or both. Also add a vertical line to this plot at the population value of the intercept.\nBased on your responses to Question 8, does the intercept estimate seem to be biased under heteroskedasticity? Explain.\nBased on your responses to Question 8, does the intercept estimate seem to be less efficient under heteroskedasticity? Explain.\nCreate a density plot of the distribution of slope estimates. Show the density curve for both models on the same plot, differentiating the curves using color, linetype, or both. Also add a vertical line to this plot at the population value of the slope\nBased on your responses to Question 11, does the slope estimate seem to be biased under heteroskedasticity? Explain.\nBased on your responses to Question 11, does the slope estimate seem to be less efficient under heteroskedasticity? Explain.\nCreate a density plot of the distribution of residual standard error estimates. Show the density curve for both models on the same plot, differentiating the curves using color, linetype, or both. Also add a vertical line to this plot at the population value of the residual standard error\nBased on your responses to Question 14, does the residual standard error estimate seem to be biased under heteroskedasticity? Explain.\nBased on your responses to Question 14, does the residual standard error estimate seem to be less efficient under heteroskedasticity? Explain."
  },
  {
    "objectID": "assignments/assignment-03.html",
    "href": "assignments/assignment-03.html",
    "title": "Assignment 03",
    "section": "",
    "text": "Submit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\nAll path models should be created digitally (e.g., using Keynote, Powerpoint, Word; No need to use R.)\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 14 points."
  },
  {
    "objectID": "assignments/assignment-03.html#footnotes",
    "href": "assignments/assignment-03.html#footnotes",
    "title": "Assignment 03",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLuik, P., & Taimalu, M. (2021). Predicting the intention to use technology in education among student teachers: A path analysis. Education Sciences, 11(9), 564. https://doi.org/10.3390/educsci11090564‚Ü©Ô∏é"
  },
  {
    "objectID": "assignments/assignment-04.html",
    "href": "assignments/assignment-04.html",
    "title": "Assignment 04",
    "section": "",
    "text": "There is a hypothesis in political science that suggests that income inequality is a function of the democratic experience and economic development of a country. In this assignment, you are going to examine whether this hypothesis is supported by empirical evidence by using the data provided in the file stack-1979.csv. In particular, you are going to regress income inequality on voter turnout (democratic experience) and energy consumption (economic development).\n\n[CSV]\n[Data Codebook]\n\n\n\nInstructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 16 points.\n\n\n\nExploratory Analysis\n\nStart by creating scatterplots to examine the relationship between each of the predictors and the outcome. Are there observations that look problematic in these plots? If so, identify the country(ies).\nFit the regression model (specified in the introduction) to the data. Report the fitted equation.\nCreate and include a set of plots that allow you to examine the assumptions for linear regression. Based on these plots, comment on the tenability of these assumptions.\n\n\n\n\nOutliers, Leverage, and Influence\n\nCompute the externally studentized residuals for the observations based on the fitted regression. Based on these values, identify any countries that you would consider as regression outliers. Explain why you identified these countries as regression outliers.\nFit a mean-shift model that will allow you to test whether the observation with the largest absolute studentized residual is statistically different from zero. Report the coefficient-level output (B, SE, t, and p) for this model.\nFind (and report) the Bonferroni adjusted p-value for the observation with the largest absolute studentized residual. Based on this p-value, is there statistical evidence to call this observation a regression outlier? Explain.\nCreate and include an index plot of the leverage values. Include a line in this plot that displays the cutpoint for ‚Äúhigh‚Äù leverage. Based on this plot, identify any countries with large leverage values.\nBased on the evidence you have looked at in Questions #4‚Äì7, do you suspect that any of the countries might influence the regression coefficients? Explain.\n\n\n\n\nInfluence Measures\n\nFor each of the influence measures listed below, create and include an index plot of the influence measure. For each plot, also include a line that displays the cutpoint for ‚Äúhigh‚Äù influence. (2pts)\n\nScaled (standardized) DFBETA values\nCook‚Äôs D\nDFFITS\nCOVRATIO\n\nShow how the Cook‚Äôs D value for the country with the largest Cook‚Äôs D value is calculated using the country‚Äôs leverage value and standardized residual.\n\n\n\n\nRemove and Refit\n\nBased on all of the evidence from the different influence measures you examined, identify and report the country(ies) that are influential. Explain how you decided on this set of observations.\nRemove the observations you identified in Question #12 from the data and refit the regression model omitting these observations. Report the fitted equation.\nCreate and include a set of plots that allow you to examine the assumptions for linear regression. Based on these plots, comment on the tenability of these assumptions.\nCompare and contrast the coefficient-level inferences from the model fitted with the full data and that fitted with the omitted observations.\nCompare and contrast the model-level summaries, namely \\(R^2\\) and the RMSE, from the model fitted with the full data and that fitted with the omitted observations."
  },
  {
    "objectID": "assignments/assignment-05.html",
    "href": "assignments/assignment-05.html",
    "title": "Assignment 05",
    "section": "",
    "text": "The goal of this assignment is to give you experience using methods for estimating regression results under violation of homoskedasticity. You will again use the data from the file stack-1979.csv to evaluate the hypothesis from political science that suggests that countries that have a stronger Socialist party have less income inequality.\n\n[CSV]\n[Data Codebook]\n\n\n\nInstructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 20 points.\n\n\n\nExploratory Analysis\n\nStart by creating a scatterplot to examine the relationship between socialist party strength (predictor) and income inequality (outcome).\nAre there observations that look problematic in this plot? If so, identify the country(ies).\nFit a linear model regressing income inequality on socialist party strength. Examine and report a set of regression diagnostics that allow you to identify any observations that are regression outliers.\n\n\n\n\nWeighted Least Squares Estimation\nRather than removing regression outliers from the data, we can instead fit a model that accounts for these observations. For example, fitting a model that allows for higher variance at x-values that have outliers. With higher variances, we would expect more extreme observations because of the increased variance. The WLS model allows for heteroskedasticity and can be used to model data that have extreme observations.\n\nCompute the empirical weights that you will use in the WLS estimation. Report the weight for the United States. (Hint: We do not know the true variances in the population.)\nFit the WLS model. Report the fitted equation.\nBased on the model results, what is suggested about the research hypothesis that countries with more socialist tendencies have less income inequality?\nCreate a scatterplot that shows the relationship between socialist party strength and income inequality. Include the country names as labels (or instead of the points). Include both the OLS and WLS regression lines on this plot.\nBased on the plot, comment on how the residuals from the WLS model compare to the residuals from the OLS model.\nBased on your response to Question #8, how will the model-level \\(R^2\\) value from the WLS model compare to the model-level \\(R^2\\) from the OLS model. Explain.\nThe mathematical formulaa for computing the studentized residuals for both the OLS and WLS models is given below. Compute and report the studentized residuals, using this formula, from both the OLS and WLS models for any regression outliers you identified in Question #2. (Hint: Remember that in an OLS regression the weight is 1 for each observation.)\n\n\\[\ne^{\\prime}_i = \\frac{e_i}{s_{e(-i)}\\sqrt{1-h_{ii}}} \\times \\sqrt{w_i}\n\\]\n\nBased on the values of the studentized residuals in the WLS model, are the observations you identified as regression outliers from the OLS model still regression outliers in the WLS model? Why or why not?\nExplain why the is the case by referring to the formula.\nCreate and report residual plots of the studentized residuals versus the fitted values for the OLS and WLS models. Comment on which model better fits the assumptions.\n\n\n\n\nIncluding Covariates\nNow include the energy covariate into the model to examine the effect of socialist strength after controlling for economic development. Since the model has changed, we need to re-compute the weights and re-carry out the WLS analysis.\n\nUse matrix algebra to compute the empirical weights based on the two-predictor model and report the weight for the United States. (That is use matrix algebra to carry out the steps in the 5-step process of computing weights when error variances are unknown for the WLS.)\nFit the two-predictor WLS model using matrix algebra. Report the fitted equation.\nCompute and report the standard errors of the two-predictor WLS model using matrix algebra.\nUsing your results from Questions #14 and #15, compute and report the t-values and p-values. While you can use the output of the tidy(), summary(), or other functions that automatically compute p-values to check your work, use the pt() function to answer this question. (Show your work or syntax for full credit.)\nBased on the two-predictor WLS model results, what is suggested about the research hypothesis that countries with more socialist tendencies have less income inequality?\nBased on the two-predictor OLS model results, what is suggested about the research hypothesis that countries with more socialist tendencies have less income inequality?\nWhich set of the model results should we trust. Explain by referring to the tenability of the assumptions."
  },
  {
    "objectID": "assignments/assignment-06.html",
    "href": "assignments/assignment-06.html",
    "title": "Assignment 06",
    "section": "",
    "text": "In 2018, Iowa attorneys rated the 64 judges who were up for election on 12 different attributes in a Judicial Performance Review. They also indicated whether or not the judge should be retained. In this assignment, you are going to examine whether those ratings we can explain variation in the percentage of attorneys who endorsed retention using the data provided in the file iowa-judges.csv.\n\n[CSV]\n[Data Codebook]\n\n\n\nInstructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 18 points.\n\n\n\nExploratory Analysis\n\nCompute and report the correlation matrix of the 12 predictors.\nBased on the correlations, comment on whether there may be any potential collinearity problems. Explain.\nCompute and report the eigenvalues for the correlation matrix you created in Question 1.\nBased on the eigenvalues, comment on whether there may be any potential collinearity problems. Explain.\n\n\n\n\nInitial Model\nSince the ratings are assigned based on different numbers of attorneys, use a weight equal to the number of respondents to fit a WLS model that regresses the standardized retention percentage on the 12 standardized predictors.\n\nReport the coefficient-level output, including the estimated coefficients (beta weights), standard errors, t-values, and p-values.\nBased on the VIF values, comment on whether there may be any potential collinearity problems. Explain.\nUsing the predictor with the largest VIF value, use the VIF value to indicate how the standard error for this predictor will be impacted by the collinearity.\n\n\n\n\nPrincipal Components Analysis\nIn this section you are going to carry out the principal components analysis by using singular value decomposition on the correlation matrix of the predictors.\n\nCompute the composite score based on the first principal component for the first observation (Judge John J. Bauercamper). Show your work in an equation.\n\nRead the section on scree plots (Section 4) in this web article.\n\nCreate a scree plot showing the eigenvalues for the 12 principal components from the previous analysis.\nUsing the ‚Äúelbow criterion‚Äù, how many principal components are sufficient to describe the data? Explain by referring to your scree plot.\nUsing the ‚ÄúKaiser criterion‚Äù, how many principal components are sufficient to describe the data? Explain.\nUsing the ‚Äú80% proportion of variance criterion‚Äù, how many principal components are sufficient to describe the data? Explain.\n\n\n\n\nRevisit the Regression Analysis\nThe evidence from the previous section suggests that the first two principal components are sufficient to explain the variation in the predictor space.\n\nBy examining the pattern of correlations (size and directions) in the first two principal components, identify the construct defined by the composites of these two components. Explain.\nFit the regression analysis using the first two principal components as predictors of retention percentage. (Don‚Äôt forget your weights.) Create and report the plot of the residuals vs.¬†fitted values. What does this suggest about the validity of the linearity assumption?\nAgain, fit the same regression model using the first two principal components as predictors of retention percentage, but this time also include a quadratic effect of the first principal component. Create and report the plot of the residuals vs.¬†fitted values. What does this suggest about the validity of the linearity assumption?\nInterpret the quadratic effect of the first principal component from this model. (It may be helpful to create a plot of the effect to guide your interpretation.)\n\n\n\n\nInfluential Values\n\nBased on Cook‚Äôs D, identify the name of any judges (and their Cook‚Äôs D value) that are influential observations.\nRemove any influential observations identified in Question 17. Re-fit the same model. Based on comparing the model- and coefficient-level output for this model and the model which included all the observations, comment on how these observations were influencing the \\(R^2\\) value, the estimate of the quadratic effect of PC1, and the effect of PC2."
  },
  {
    "objectID": "assignments/assignment-07.html",
    "href": "assignments/assignment-07.html",
    "title": "Assignment 07",
    "section": "",
    "text": "The goal of the analysis you are going to undertake in this assignment is to build a model that predicts customers‚Äô credit card balance. To do this you will use the data provided in the file credit.csv. The six predictors included in the dataset have all been previously shown to predict credit card balance."
  },
  {
    "objectID": "assignments/assignment-07.html#model-level-summaries",
    "href": "assignments/assignment-07.html#model-level-summaries",
    "title": "Assignment 07",
    "section": "Model-Level Summaries",
    "text": "Model-Level Summaries\n\nCompute and report the model-level \\(R^2\\) for the ridge regression model. (Hint: Remember that the model-level \\(R^2\\) is the squared correlation between the observed and predicted values of the outcome.) Show your work. How does this compare to the \\(R^2\\) from the OLS model?\nCompute and report the F-value associated with the \\(R^2\\) value you computed in Question #18.\nCompute and report the p-value associated with the test of whether \\(\\rho^2=0\\)."
  },
  {
    "objectID": "assignments/assignment-08.html",
    "href": "assignments/assignment-08.html",
    "title": "Assignment 08",
    "section": "",
    "text": "Instructions\nSubmit a printed document of your responses to the following questions. Please adhere to the following guidelines for further formatting your assignment:\n\nAll plots should be resized so that they do not take up more room than necessary.\nAll figures and tables should have a name (e.g., Figure 1) and an appropriate caption.\n\nIn questions that ask you to ‚Äúuse matrix algebra‚Äù to solve the problem, you can either show your syntax and output from carrying out the matrix operations, or you can use Equation Editor to input the matrices involved in your calculations.\nThis assignment is worth 20 points.\n\n\n\nPart I: Minneapolis Violent Crime\nFor the first part of this assignment, you will use the data provided in the file mpls-violent-crime.csv to build a model that examines the trend in violent crime rate over time.\n\n[CSV]\n[Data Codebook]\n\n\n\nPreparation\nCreate a variable that indicates the number of years since 2000. Use this variable in all analyses for Part I rather than the year variable.\n\n\n\nDescription\n\nCreate a scatterplot showing the violent crime rate as a function of time.\nBased on the plot, describe the trend in violent crime rate over time.\nIf you were going to fit a polynomial model to these data, what degree polynomial would you fit? Explain.\n\n\n\n\nUse p-Value methods for Model Selection\n\nFit a series of polynomial models starting with a linear model, and then models that also include higher order polynomials that allow you to evaluate your response to Question #3. Be sure to fit models up to degree \\(k+1\\), where \\(k\\) is the degree you hypothesized in Question #3. Analyze each of the polynomial terms (including the linear term) by using a series of nested F-tests. Report these results in an ANOVA table. (Note: If you need a refresher on fitting polynomial models and carrying out a nested F-test, see the Polynomial Regression notes from EPsy 8252.) (2pts.)\nBased on these results, which polynomial model would you adopt? Explain.\n\n\n\n\nUsing LOOCV for Model Selection\nIn this section of the assignment, you are going to use LOOCV to evaluate the MSE for the same set of polynomial models you evaluated in Question #4.\n\nWrite and include syntax that will carry out the LOOCV.\nReport the cross-validated MSE for each of the models in your set of polynomial models.\nBased on these results, which degree polynomial model should be adopted? Explain.\n\n\n\n\n\nPart II: Course Evaluations\nFor the second part of this assignment, you will use the data provided in the file evaluations.csv to build a model that predicts variation in course evaluation scores.\n\n[CSV]\n[Data Codebook]\n\n\n\nPreparation\nBegin by fitting a model that predicts average course evaluation score using the following predictors: beauty, number of courses for which the professor has evaluations, whether the professor is a native English speaker, and whether the professor is female.\n\n\n\nDescription\n\nUsing average course evaluation scores (y), compute the total sum of squares (SST). Show your work.\nUsing average course evaluation scores (y) and the predicted values from the model (\\(\\hat{y}\\)), compute the sum of squared errors (SSE). Show your work.\nCompute the model \\(R^2\\) value using the formula: \\(1 - \\frac{\\mathrm{SSE}}{\\mathrm{SST}}\\).\n\n\n\n\nUsing k-Fold Cross-Validation to Estimate \\(R^2\\)\nAs we know, the estimate for \\(R^2\\) is biased. We can obtain a better estimate of \\(R^2\\) by using cross-validation. You will use 5-fold cross-validation to estimate the \\(R^2\\) value. The algorithm for this will be:\n\nRandomly divide the evaluations data into 5 folds.\nHold out 1 fold as your validation data and use the remaining 4 folds as your training data.\n\nFit the model to the training data.\nUse the estimated coefficients from those fits to compute \\(\\hat{y}\\) values using the validation data.\nCompute the SST and SSE values for the validation data, and use those to compute \\(R^2\\) based on the formula \\(1 - \\frac{\\mathrm{SSE}}{\\mathrm{SST}}\\). (Note that sometimes the \\(R^2\\) may be negative when we compte it in this manner.)\n\nRepeat for each fold.\nCompute the cross-validated \\(R^2\\) by finding the mean of the five \\(R^2\\) from the cross-validations.\n\n\nWrite and include syntax that will carry out the 5-fold cross-validation. In this syntax use set.seed(1000) so that you and the answer key will get the same results. (This website may be useful in using the purrr package to obtain the y- and \\(\\hat{y}\\)-values in order to compute the SST and SSE values: https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom)\nReport the five \\(R^2\\) values from your analysis and the cross-validated \\(R^2\\) value.\nHow does this value compare to the \\(R^2\\) value you computed in Question #11, based on the data.\nExplain why the cross-validated estimate of \\(R^2\\) is a better estimate than the data-based \\(R^2\\).\n\n\n\n\n\nPart III: Credit Balance\nFor the third part of this assignment, you will again use the file the data provided in the file credit.csv to build a model that predicts customers‚Äô credit card balance. Do not forget to standardize all the variables.\n\n[CSV]\n[Data Codebook]\n\n\n\nUse the lm.ridge() function to fit the same sequence of \\(\\lambda\\) values you used in Question #7 from Assignment 6. Running select() on this output, provides \\(\\lambda\\) values based on different criteria. Report the \\(\\lambda\\) value associated with the generalized cross-validation (GCV) metric.\nRe-do Question #7 from Assignment 6, except this time, select the optimal \\(\\lambda\\) value based on using the AICc. How does this compare to the \\(\\lambda\\) value you found using the GCV metric from the previous question? (Show your syntax.)\nCompute the coefficients, standard errors based on the ridge regression model based on the \\(\\lambda\\) value you identified in Question #17. Also compute the t-values, and p-values for each coefficient. Report all of these in a coefficient table. (2pts.)"
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "",
    "text": "In this set of notes, we will use data from Statistics Canada‚Äôs Survey of Labour and Income Dynamics (SLID) to explain variation in the hourly wage rate of employed citizens in Ontario.\nA script file for the analyses in these notes is also available:"
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#violating-homoskedasticity",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#violating-homoskedasticity",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Violating Homoskedasticity",
    "text": "Violating Homoskedasticity\nViolating the distributional assumption of homoskedasticity results in:\n\nIncorrect computation of the sampling variances and covariances; and because of this\nThe OLS estimates are no longer BLUE (Best Linear Unbiased Estimator).\n\nThis means that the SEs (and resulting t- and p-values) for the coefficients are incorrect. In addition, the OLS estimators are no longer the most efficient estimators. How bad this is depends on several factors (e.g., how much the variances differ, sample sizes)."
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#box-cox-transformation",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#box-cox-transformation",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Box-Cox Transformation",
    "text": "Box-Cox Transformation\nIs there a power transformation that would better ‚Äúfix‚Äù the heteroskedasticity? In their seminal paper, Box & Cox (1964) proposed a series of power transformations that could be applied to data in order to better meet assumptions such as linearity, normality, and homoskedasticity. The general form of the Box-Cox model is:\n\\[\nY^{(\\lambda)}_i = \\beta_0 + \\beta_1(X1_{i}) + \\beta_2(X2_{i}) + \\ldots + \\beta_k(Xk_{i}) + \\epsilon_i\n\\]\nwhere the errors are independent and \\(\\mathcal{N}(0,\\sigma^2_{\\epsilon})\\), and\n\\[\nY^{(\\lambda)}_i = \\begin{cases}\n   \\frac{Y_i^{\\lambda}-1}{\\lambda} & \\text{for } \\lambda \\neq 0 \\\\[1em]\n   \\ln(Y_i)       & \\text{for } \\lambda = 0\n  \\end{cases}\n\\]\nThis transformation is only defined for positive values of Y.\nThe powerTransform() function from the {car} library can be used to determine the optimal value of \\(\\lambda\\).\n\n# Find optimal power transformation using Box-Cox\npowerTransform(lm.1)\n\nEstimated transformation parameter \n        Y1 \n0.08598786 \n\n\nThe output from the powerTransform() function gives the optimal power for the transformation of y, namely \\(\\lambda = 0.086\\). To actually implement the power transformation we use the transform Y based on the Box-Cox algorithm presented earlier.\n\nslid = slid |&gt;\n  mutate(\n    bc_wages = (wages ^ 0.086 - 1) / 0.086\n  )\n\n# Fit models\nlm_bc = lm(bc_wages ~ 1 + age + education + male, data = slid)\n\nThe residual plots (shown below) indicate better behaved residuals for the main-effects model, although even this optimal transformation still shows some evidence of heteroskedasticity.\n\n\nCode\n# Examine residual plots\nresidual_plots(lm_bc)\n\n\n\n\n\nResidual plots for the main effects model that used a Box-Cox transformation on Y with \\(\\lambda=0.086\\).\n\n\n\n\nOne problem with using this transformation is that the regression coefficients do not have a direct interpretation. For example, looking at the coefficient-level output:\n\ntidy(lm_bc, conf.int = TRUE)\n\n\n\n  \n\n\n\nThe age coefficient would be interpreted as: each one-year difference in age is associated with a 0.0227-unit difference in the transformed Y, controlling for differences in education and sex. But what does a 0.227-unit difference in transformed Y mean when we translate that back to wages?"
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#profile-plot-for-different-transformations",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#profile-plot-for-different-transformations",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Profile Plot for Different Transformations",
    "text": "Profile Plot for Different Transformations\nMost of the power transformations under Box-Cox would produce coefficients that are difficult to interpret. The exception is when \\(\\lambda=0\\). This is the log-transformation which is directly interpretable. Since the optimal \\(\\lambda\\) value of 0.086 is quite close to 0, we might wonder whether we could just use the log-transformation (\\(\\lambda=0\\)). The Box-Cox algorithm optimizes the log-likelihood of a given model, so the statistical question is whether there is a difference in the log-likelihood produced by the optimal transformation and that for the log-transformation.\nTo evaluate this, we can plot of the log-likelihood for a given model using a set of lambda values. This is called a profile plot of the log-likelihood. The boxCox() function creates a profile plot of the log-likelihood for a defined sequence of \\(\\lambda\\) values. Here we will plot the profile of the log-likelihood for \\(-2 \\leq \\lambda \\leq 2\\).\n\n# Plot of the log-likelihood for a given model versus a sequence of lambda values\nboxCox(lm.1, lambda = seq(from = -2, to = 2, by = 0.1))\n\n\n\n\nPlot of the log-likelihood profile for a given model versus a sequence of lambda values. The lambda that produces the highest log-likelihood is 0.086, the optimal lambda value.\n\n\n\n\nThe profile plot shows that the optimal lambda value, 0.86, produces the maximum log-likelihood value for the given model. We also are shown the 95% confidence limits for lambda based on a test of the curvature of the log-likelihood function. This interval offers a range of \\(\\lambda\\) values that will give comparable transformations. Since the values associated with the confidence limits are not outputted by the boxCox() function, we may need to zoom in to determine these limits by tweaking the sequence of \\(\\lambda\\) values in the boxCox() function.\n\n# Zomm in on confidence limits\nboxCox(lm.1, lambda = seq(from = 0.03, to = 0.2, by = .001))\n\n\n\n\nPlot of the log-likelihood profile for a given model versus a narrower sequence of lambda values.\n\n\n\n\nIt looks as though \\(.03 \\leq \\lambda \\leq 0.14\\) all give comparable transformations. Unfortunately, 0 is not included in those limits. This means that the \\(\\lambda\\) value of 0.086 will produce a higher log-likelihood than the log-transformation. It is important to remember that even though the log-likelihood will be optimized, the compatibility with the assumptions may or may not be improved when we use \\(\\lambda=0.086\\) versus \\(\\lambda=0\\). The only way to evaluate this is to fit the models and check the residuals."
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#assume-error-variances-are-known",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#assume-error-variances-are-known",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "Assume Error Variances are Known",
    "text": "Assume Error Variances are Known\nLet‚Äôs assume that each of the error variances, \\(\\sigma^2_i\\), are known. This is generally not a valid assumption, but it gives us a point to start from. If we know these values, we can modify the likelihood function from OLS by substituting these values in for the OLS error variance, \\(\\sigma^2_{\\epsilon}\\).\n\\[\n\\begin{split}\n\\mathrm{OLS:} \\qquad \\mathcal{L}(\\boldsymbol{\\beta}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2_{\\epsilon}}}\\exp\\left[-\\frac{1}{2\\sigma^2_{\\epsilon}} \\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right] \\\\[1em]\n\\mathrm{WLS:} \\qquad \\mathcal{L}(\\boldsymbol{\\beta}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2_{i}}}\\exp\\left[-\\frac{1}{2\\sigma^2_{i}} \\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right]\n\\end{split}\n\\]\nNext, we define the reciprocal of the error variances as \\(w_i\\), or weight:\n\\[\nw_i = \\frac{1}{\\sigma^2_i}\n\\]\nThis can be used to simplify the likelihood function for WLS:\n\\[\n\\begin{split}\n\\mathcal{L}(\\boldsymbol{\\beta}) &= \\bigg[\\prod_{i=1}^n \\sqrt{\\frac{w_i}{2\\pi}}\\bigg]\\exp\\left[-\\frac{1}{2} \\sum_{i=1}^n w_i\\big(Y_i-\\beta_0 - \\beta_1X_{1i} - \\beta_2X_{2i} - \\ldots - \\beta_kX_{ki}\\big)^2\\right]\n\\end{split}\n\\]\nWe can then find the coefficient estimates by maximizing \\(\\mathcal{L}(\\boldsymbol{\\beta})\\) with respect to each of the coefficients; these derivatives will result in k normal equations. Solving this system of normal equations we find that:\n\\[\n\\mathbf{b}_{\\mathrm{WLS}} = (\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{X})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{y}\n\\]\nwhere W is a diagonal matrix of the weights,\n\\[\n\\mathbf{W} =  \\begin{bmatrix}w_{1} & 0 & 0 & \\ldots & 0 \\\\ 0 & w_{2} & 0 & \\ldots & 0\\\\ 0 & 0 & w_{3} & \\ldots & 0\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\ldots & w_{n}\\end{bmatrix}\n\\]\nThe variance‚Äìcovariance matrix for the regression coefficients can then be computed using:\n\\[\n\\boldsymbol{\\sigma^2}(\\mathbf{B}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^{\\intercal}\\mathbf{W}\\mathbf{X})^{-1}\n\\]\nwhere the estimate for \\(\\sigma^2_{\\epsilon}\\) is based on a weighted sum of squares:\n\\[\n\\hat\\sigma^2_{\\epsilon} = \\frac{\\sum_{i=1}^n w_i \\times \\epsilon_i^2}{n - k - 1}\n\\]\nWhich can be expressed in matrix algebra as a function of the weight matrix and residual vector as:\n\\[\n\\hat\\sigma^2_{\\epsilon} = \\frac{(\\mathbf{We})^{\\intercal}\\mathbf{e}}{n - k - 1}\n\\]\n\n\nAn Example of WLS Estimation\nTo illustrate WLS, consider the following data which includes average ACT scores for a classroom of students, ACT score for the teacher, and the standard deviation of the class ACT scores.\n\n\n\n\n\nClass Average ACT\nTeacher ACT\nClass SD\n\n\n\n\n17.3\n21\n5.99\n\n\n17.1\n20\n3.94\n\n\n16.4\n19\n1.90\n\n\n16.4\n18\n0.40\n\n\n16.1\n17\n5.65\n\n\n16.2\n16\n2.59\n\n\n\n\n\n\n\nSuppose we want to use the teacher‚Äôs ACT score to predict variation in the class average ACT score. Fitting this model using OLS, we can compute the coefficient estimates and the standard errors for each coefficient.\n\n# Enter y vector\ny = c(17.3, 17.1, 16.4, 16.4, 16.1, 16.2)\n\n# Create design matrix\nX = matrix(\n  data = c(rep(1, 6), 21, 20 , 19, 18, 17, 16),\n  ncol = 2\n)\n\n# Compute coefficients\nb = solve(t(X) %*% X) %*% t(X) %*% y\n\n# Compute SEs for coefficients\ne = y - X %*% b\nsigma2_e = t(e) %*% e / (6 - 1 - 1)\nV_b = as.numeric(sigma2_e) * solve(t(X) %*% X)\nsqrt(diag(V_b))\n\n[1] 0.98356794 0.05294073\n\n\nWe could also have used built-in R functions to obtain these values:\n\nlm.ols = lm(y ~ 1 + X[ , 2])\ntidy(lm.ols, conf.int = TRUE)\n\n\n\n  \n\n\n\nThe problem, of course, is that the variation in the residuals is not constant as the reliability for the 10 class average ACT values is not the same for each class; the standard deviations are different. Because of this, we may want to fit a WLS regression model rather than an OLS model.\n\n# Set up weight matrix, W\nclass_sd = c(5.99, 3.94, 1.90, 0.40, 5.65, 2.59)\nw_i = 1 / (class_sd ^ 2)\nW = diag(w_i)\nW\n\n          [,1]       [,2]      [,3] [,4]       [,5]      [,6]\n[1,] 0.0278706 0.00000000 0.0000000 0.00 0.00000000 0.0000000\n[2,] 0.0000000 0.06441805 0.0000000 0.00 0.00000000 0.0000000\n[3,] 0.0000000 0.00000000 0.2770083 0.00 0.00000000 0.0000000\n[4,] 0.0000000 0.00000000 0.0000000 6.25 0.00000000 0.0000000\n[5,] 0.0000000 0.00000000 0.0000000 0.00 0.03132587 0.0000000\n[6,] 0.0000000 0.00000000 0.0000000 0.00 0.00000000 0.1490735\n\n# Compute coefficients\nb_wls = solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% y\nb_wls\n\n           [,1]\n[1,] 13.4154764\n[2,]  0.1658431\n\n# Compute standard errors for coefficients\ne_wls = y - X %*% b_wls                                 # Compute errors from WLS\nmse_wls = (t(W %*% e_wls) %*% e_wls) / (6 - 1 - 1)      # Compute MSE estimate\nv_b_wls = as.numeric(mse_wls) * solve(t(X) %*% W %*% X) # Compute variance-covariance matrix for B\nsqrt(diag(v_b_wls))\n\n[1] 1.17680463 0.06527187\n\n\nThe results of fitting both the OLS and WLS models appear below. Comparing the two sets of results, there is a difference in the coefficient values and in the estimated SEs when using WLS estimation rather than OLS estimation. This would also impact any statistical inference as well.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOLS\n\n\nWLS\n\n\n\nCoefficient\nB\nSE\nB\nSE\n\n\n\n\nIntercept\n12.0905\n0.9836\n13.4155\n1.1768\n\n\nEffect of Teacher ACT Score\n0.2429\n0.0529\n0.1658\n0.0653\n\n\n\n\n\n\n\n\n\n\nFitting the WLS estimation in the lm() Function\nThe lm() function can also be used to fit a model using WLS estimation. To do this we include the weights= argument in lm(). This takes a vector of weights representing the \\(w_i\\) values for each of the n observations.\n\n# Create weights vector\nw_i = 1 / (class_sd ^ 2)\n\n# Fit WLS model\nlm_wls = lm(y ~ 1 + X[ , 2], weights = w_i)\ntidy(lm_wls, conf.int = TRUE)\n\n\n\n  \n\n\n\nNot only can we use tidy() and glance() to obtain coefficient and model-level summaries, but we can also use augment(), anova(), or any other function that takes a fitted model as its input."
  },
  {
    "objectID": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#what-if-error-variances-are-unknown",
    "href": "notes/05-01-tools-for-dealing-with-heteroskedasticity.html#what-if-error-variances-are-unknown",
    "title": "üìù Tools for Dealing with Heteroskedasticity",
    "section": "What if Error Variances are Unknown?",
    "text": "What if Error Variances are Unknown?\nThe previous example assumed that the variance‚Äìcovariance matrix of the residuals was known. In practice, this is almost never the case. When we do not know the error variances, we need to estimate them from the data.\nOne method for estimating the error variances for each observation, is:\n\nFit an OLS model to the data, and obtain the residuals.\nSquare these residuals and regress them (using OLS) on the same set of predictors.\nObtain the fitted values from Step 2.\nCreate the weights using \\(w_i = \\frac{1}{\\hat{y}_i}\\) where \\(\\hat{y}_i\\) are the fitted values from Step 3.\nFit the WLS using the weights from Step 4.\n\nThis is a two-stage process in which we (1) estimate the weights, and (2) use those weights in the WLS estimation. We will illustrate this methodology using the SLID data.\n\n# Step 1: Fit the OLS regression\nlm_step_1 = lm(wages ~ 1 + age + education + male + age:education, data = slid)\n\n# Step 2: Obtain the residuals and square them\nout_1 = augment(lm_step_1) |&gt;\n  mutate(\n    e_sq = .resid ^ 2\n  )\n\n# Step 2: Regresss e^2 on the predictors from Step 1\nlm_step_2 = lm(e_sq ~ 1 + age + education + male + age:education, data = out_1)\n\n# Step 3: Obtain the fitted values from Step 2\ny_hat = fitted(lm_step_2)\n\n\n# Step 4: Create the weights\nw_i = 1 / (y_hat ^ 2)\n\n# Step 5: Use the fitted values as weights in the WLS\nlm_step_5 = lm(wages ~ 1 + age + education + male + age:education, data = slid, weights = w_i)\n\nBefore examining any output from this model, let‚Äôs examine the residual plots. The residual plots suggest that the homoskedasticity assumption is much more reasonably satisfied after using WLS estimation; although it is still not perfect. The normality assumption looks untenable here.\n\nOne way to proceed would be to apply a variance stabilizing transformation to y (e.g., log-transform) and then fit a WLS model. To do this you would go through the steps of estimating the weights again based on the transformed y.\n\n\n\nCode\n# Examine residual plots\nresidual_plots(lm_step_5)\n\n\n\n\n\nResidual plots for the model that includes the main effects of age, education level, and sex fitted with WLS estimation.\n\n\n\n\nThe WLS coefficient estimates, standard errors, and coefficient-level inference are presented below.\n\n# Examine coefficient-level output\ntidy(lm_step_5, conf.int = TRUE)"
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html",
    "href": "notes/06-01-diagnosing-collinearity.html",
    "title": "üìù Diagnosing Collinearity",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to empirical diagnostics to detect collinearity. We will use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")"
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#effects-of-collinearity",
    "href": "notes/06-01-diagnosing-collinearity.html#effects-of-collinearity",
    "title": "üìù Diagnosing Collinearity",
    "section": "Effects of Collinearity",
    "text": "Effects of Collinearity\nIf the design matrix is not of full rank, and \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) is singular, then the OLS normal equations do not have a unique solution. Moreover, the sampling variances for the coefficient are all infinitely large. To understand why this is the case, we can examine one formula for the sampling variance of a slope in a multiple regression:\n\\[\n\\mathrm{Var}(B_j) = \\frac{1}{1 - R^2_j} \\times \\frac{\\sigma^2_\\epsilon}{(n-1)S^2_j}\n\\]\nwhere\n\n\\(R^2_j\\) is the squared multiple correlation for the regression of \\(X_j\\) on the the other predictors;\n\\(S^2_j\\) is the sample variance of predictor \\(X_j\\) defined by \\(S^2_j = \\dfrac{\\sum(X_{ij}-\\bar{X}_j)^2}{n-1}\\);\n\\(\\sigma^2_{\\epsilon}\\) is the variance of the residuals based on regressing \\(Y\\) on all the \\(X\\)‚Äôs\n\n\nRecall that the multiple correlation is the correlation between the outcome and the predicted values.\n\nThe first term in this product is referred to as the variance inflation factor (VIF). When one of the predictors is perfectly collinear with the others, the value of \\(R^2_j\\) is 1 and the VIF is infinity. Thus the sampling variance of \\(B_j=\\infty\\)."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#perfect-collinearity-in-practice-model-mis-specification",
    "href": "notes/06-01-diagnosing-collinearity.html#perfect-collinearity-in-practice-model-mis-specification",
    "title": "üìù Diagnosing Collinearity",
    "section": "Perfect Collinearity in Practice: Model Mis-specification",
    "text": "Perfect Collinearity in Practice: Model Mis-specification\nIn practice, it is unlikely that you will have exact (or perfect) collinearity. When it does happen it is often the result of mis-formulating the model (e.g., including dummy variables in the model for all levels of a categorical variable, as well as the intercept). As an example of this, imagine that you were creating the design matrix for a regression model that included occupational status (employed/not employed) to predict some outcome for 5 cases.\n\n# Create design matrix\nX = data.frame(\n  b_0 = rep(1, 5),\n  employed = c(1, 1, 0, 0, 1),\n  not_employed = c(0, 0, 1, 1, 0)\n)\n\n# View design matrix\nX\n\n\n\n  \n\n\n\nThe columns in this design matrix are collinear because we can express any one of the columns as a linear combination of the others. For example,\n\\[\nb_0 = 1(\\mathrm{employed}) + 1(\\mathrm{not~employed})\n\\]\nChecking the rank of this matrix, we find that this matrix has a rank of 2. Since there are three columns, X is not full column rank; it is rank deficient.\n\nMatrix::rankMatrix(X)\n\n[1] 2\nattr(,\"method\")\n[1] \"tolNorm2\"\nattr(,\"useGrad\")\n[1] FALSE\nattr(,\"tol\")\n[1] 1.110223e-15\n\n\nIncluding all three coefficients in the model results in overparameterization. The simple solution here is to drop one of the predictors from the model. This is why we only include a single dummy variable in a model that includes an intercept for a dichotomous categorical predictor.\n\nIncluding the intercept is not imperative, although it has a useful interpretation when using dummy coding. One could also include the two dummy-coded predictors and omit the intercept. This gives the means for the two groups, but does not provide a comparison of those means.\n\n\n# Create vector of outcomes\nY = c(15, 15, 10, 15, 30)\n\n# Create data frame of Y and X\nmy_data = cbind(Y, X)\nmy_data\n\n\n\n  \n\n\n# Coefficients (including all three terms)\ncoef(lm(Y ~ 1 + employed + not_employed, data = my_data))\n\n (Intercept)     employed not_employed \n        12.5          7.5           NA \n\n# Coefficients (omitting intercept)\ncoef(lm(Y ~ -1 + employed + not_employed, data = my_data))\n\n    employed not_employed \n        20.0         12.5 \n\n\nIf you overparameterize a model with lm(), one or more of the coefficients will not be estimated (the last parameters entered in the model).\n\nConstraining some parameters is another way to produce a full rank design matrix. For example the ANOVA model has a constraint that the sum of the effect-coded variable is 0. This constraint ensures that the design matrix will be of full rank."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#non-exact-collinearity",
    "href": "notes/06-01-diagnosing-collinearity.html#non-exact-collinearity",
    "title": "üìù Diagnosing Collinearity",
    "section": "Non-Exact Collinearity",
    "text": "Non-Exact Collinearity\nIt is more likely, in practice, that you will have less-than-perfect collinearity, and that this will have an adverse effect on the computational estimates of the coefficients‚Äô sampling variances. Again, we look toward how the sampling variances for the coefficent‚Äôs are computed:\n\\[\n\\mathrm{Var}(B_j) = \\frac{1}{1 - R^2_j} \\times \\frac{\\sigma^2_\\epsilon}{(n-1)S^2_j}\n\\]\nWhen the predictors are completely independent, all of the columns of the design matrix will be orthogonal and the correlation between \\(X_j\\) and the other \\(X\\)s will be 0. In this situation, the VIF is 1 and the second term in the product completely defines the sampling variance. This means that the sampling variance is a function of the model‚Äôs residual variance, sample size, and the predictor‚Äôs variance‚Äîthe factors we typically think of affecting the sampling variance of a coefficient.\nIn cases where the columns in ths design matrix are not perfectly orthogonal, the correlation between \\(X_j\\) and the other \\(X\\)s is larger than 0. (Perfect collinearity results in \\(R^2_j=1\\).) For these situations, the VIF has a value that is greater than 1. When this happens the VIF acts as a multiplier of the second term, inflating the the sampling variance and reducing the precision of the estimate (i.e., increasing the uncertainty).\nHow much the uncertainty in the estimate increases is a function of how correlated the predictors are. Here we can look at various multiple correlations (\\(R_j\\)) between \\(X_j\\) and the predicted values from using the other \\(X\\)‚Äôs to predict \\(X_j\\).\n\n\n\nImpact of various Rj values on the VIF and size of the CI for Bj.\n\n\nRj\nVIF\nCI Factor\n\n\n\n\n0.0\n1.00\n1.00\n\n\n0.1\n1.01\n1.01\n\n\n0.2\n1.04\n1.02\n\n\n0.3\n1.10\n1.05\n\n\n0.4\n1.19\n1.09\n\n\n0.5\n1.33\n1.15\n\n\n0.6\n1.56\n1.25\n\n\n0.7\n1.96\n1.40\n\n\n0.8\n2.78\n1.67\n\n\n0.9\n5.26\n2.29\n\n\n1.0\nInf\nInf\n\n\n\n\n\n\n\nFor example, a multiple correlation of 0.7 results in a VIF of 1.96, which in turn means that the CI (which is based on the square root of the sampling variance) will increase by a factor of 1.4. This inflation increases the uncertainty of the estimate making it harder to make decisions or understand the effect of \\(B_j\\).\nTo sum things up, while perfect collinearity is rare in practice, less-than-perfect collinearity is common. In these cases the VIF will be less than 1, but can still have an adverse effect on the sampling variances; sometimes making them quite large."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#collinearity-diagnostics",
    "href": "notes/06-01-diagnosing-collinearity.html#collinearity-diagnostics",
    "title": "üìù Diagnosing Collinearity",
    "section": "Collinearity Diagnostics",
    "text": "Collinearity Diagnostics\nWe can also empirically diagnose problematic collinearity in the data (D. A. Belsley, 1991; D. Belsley, Kuh, & Welsch, 1980). Before we do, however, it is important that the functional form of the model has been correctly specified. Since, a model needs to be specified before we can estimate coefficients or their sampling variances, and collinearity produces unstable estimates of these estimates, collinearity should only be investigated after the model has been satisfactorily specified.\nBelow we will explore some of the diagnostic tools available to an applied researcher."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#high-correlations-among-predictors",
    "href": "notes/06-01-diagnosing-collinearity.html#high-correlations-among-predictors",
    "title": "üìù Diagnosing Collinearity",
    "section": "High Correlations among Predictors",
    "text": "High Correlations among Predictors\nCollinearity can sometimes be anticipated by examining the pairwise correlations between the predictors. If the correlation between predictors is large, this might be indicative of collinearity problems.\n\neeo |&gt;\n  select(faculty, peer, school) |&gt;\n  correlate()\n\n\n\n  \n\n\n\nIn this example, all three of the predictors are highly correlated with one another. This is likely a good indicator that their may be problems in the estimation of coefficients, inflated standard errors, or both; especially given that the correlations are all very high. Unfortunately the source of collinearity may be due to more than just the simple relationships among the predictors. As such, just examining the pairwise correlations is not enough to detect collinearity (although it is a good first step)."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#regress-each-predictor-on-the-other-predictors",
    "href": "notes/06-01-diagnosing-collinearity.html#regress-each-predictor-on-the-other-predictors",
    "title": "üìù Diagnosing Collinearity",
    "section": "Regress each Predictor on the Other Predictors",
    "text": "Regress each Predictor on the Other Predictors\nSince collinearity is defined as linear dependence within the set of predictors, a better way to diagnose collinearity than just examining the pairwise correlation coefficients is to regress each of the predictors on the remaining predictors and evaluate the \\(R^2\\) value. If all the \\(R^2\\) values are close to zero there is no collinearity problems. If one or more of the \\(R^2\\) values are close to 1, there is a collinearity problem.\n\n# Use faculty as outcome; obtain R2\nsummary(lm(faculty ~ 1 + peer + school, data = eeo))$r.squared\n\n[1] 0.9733906\n\n# Use faculty as outcome; obtain R2\nsummary(lm(peer ~ 1 + faculty + school, data = eeo))$r.squared\n\n[1] 0.9669002\n\n# Use faculty as outcome; obtain R2\nsummary(lm(school ~ 1 + faculty + peer, data = eeo))$r.squared\n\n[1] 0.9879743\n\n\nAll three \\(R^2\\) values are quite high, which is indicative of collinearity.\nOne shortcoming with this method of diagnosing collinearity is that when the predictor space is large, you would need to look at the \\(R^2\\) values from several models. And, while this could be automated in an R function, there are other common methods that allow us to diagnose collinearity.\nWe will examine three additional common methods statisticians use to empirically detect collinearity: (1) computing variance inflation factors for the coefficients; (2) examining the eigenvalues of the correlation matrix; and (3) examining the condition indices of the correlation matrix."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#variance-inflation-factor-vif",
    "href": "notes/06-01-diagnosing-collinearity.html#variance-inflation-factor-vif",
    "title": "üìù Diagnosing Collinearity",
    "section": "Variance Inflation Factor (VIF)",
    "text": "Variance Inflation Factor (VIF)\nPerhaps the most common method applied statisticians use to diagnose collinaerity is to compute and examine variance inflation factors. Recall that the variance inflation factor (VIF) is an indicator of the degree of collinearity, where VIF is:\n\\[\n\\mathrm{VIF} = \\frac{1}{1 - R^2_j}\n\\]\nThe VIF impacts the size of the variance estimates for the regression coefficients, and as such, can be used as a diagnostic of collinearity. In practice, since it is more conventional to use the SE to measure uncertainty, it is typical to use the square root of the VIF as a diagnostic of collinearity in practice. The square root of the VIF expresses the proportional change in the CI for the coefficients. We can use the vif() function from the car package to compute the variance inflation factors for each coefficient.\n\n# VIF\nvif(lm.1)\n\n faculty     peer   school \n37.58064 30.21166 83.15544 \n\n# Square root of VIF\nsqrt(vif(lm.1))\n\n faculty     peer   school \n6.130305 5.496513 9.118960 \n\n\nThe variances (and hence, the standard errors) for all three coefficients are inflated because of collinearity. The SEs for these coefficients are all more than five times as large as they would be if the predictors were independent.\nRemember, the VIF can range from 1 (independence among the predictors) to infinity (perfect collinearity). There is not consensus among statisticians about how high the VIF has to be to constitute a problem. Some references cite \\(\\mathrm{VIF}&gt;10\\) as problematic (which increases the size of the CI for the coefficient by a factor of over three); while others cite \\(\\mathrm{VIF}&gt;4\\) as problematic (which increases the size of the CI for the coefficient by a factor of two). As you consider what VIF value to use as an indicator of problematic inflation, it is more important to consider what introducing that much uncertainty would mean in your substantive problem. For example, would you be comfortable with tripling the uncertainty associated with the coefficient? What about doubling it? Once you make that decision, you can determine your VIF cutoff.\nThere are several situations in which high VIF values are expected and not problematic:\n\nThe variables with high VIFs are control variables, and the variables of interest do not have high VIFs. Since we would not be interested in inference around the control variables, high VIF values on those variables would not\nThe high VIFs are caused by the inclusion of powers or products of other variables. The p-value for a product term is not affected by the multicollinearity. Centering predictors prior to creating the powers or the products will reduce the correlations, but the p-value the products will be exactly the same whether or not you center. Moreover the results for the other effects will be the same in either case indicating that multicollinearity has no adverse consequences.\nThe variables with high VIFs are indicator (dummy) variables that represent a categorical variable with three or more categories. This is especially true when the reference category used has a small proportion of cases. In this case, p-values for the indicator variables may be high, but the overall test that all indicators have coefficients of zero is unaffected by the high VIFs. And nothing else in the regression is affected. To avoid the high VIF values in this situaton, just choose a reference category with a larger proportion of cases."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#eigenvalues-of-the-correlation-matrix",
    "href": "notes/06-01-diagnosing-collinearity.html#eigenvalues-of-the-correlation-matrix",
    "title": "üìù Diagnosing Collinearity",
    "section": "Eigenvalues of the Correlation Matrix",
    "text": "Eigenvalues of the Correlation Matrix\nA second common method of evaluating collinearity is to compute and evaluate the eigenvalues of the correlation matrix for the predictors. Recall that each square (\\(k \\times k\\)) matrix has a set of k scalars, called eigenvalues (denoted \\(\\lambda\\)) associated with it. These eigenvalues can be arranged in descending order such that,\n\\[\n\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3 \\geq \\ldots \\geq \\lambda_k\n\\]\nBecause any correlation matrix is a square matrix, we can find a corresponding set of eigenvalues for the correlation matrix. If any of these eigenvalues is exactly equal to zero, it indicates a linear dependence among the variables making up the correlation matrix.\nAs a diagnostic, rather than looking at the size of all the eigenvalues, we compute the sum of the reciprocals of the eigenvalues:\n\\[\n\\sum_{i=1}^k \\frac{1}{\\lambda_i}\n\\]\n\nIf the predictors are orthogonal to one another (independent) then \\(\\lambda_i = 1\\) and the sum of the reciprocal values will be equal to the number of predictors, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} = k\\).\nIf the predictors are collinear with one another (dependent) then \\(\\lambda_i = 0\\) and the sum of the reciprocal values will be equal to infinity, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} = \\infty\\).\nWhen there is nonperfect collinearity then \\(0 &lt; \\lambda_i &lt; 1\\), and the sum of the reciprocal values will be greater than the number of predictors, \\(\\sum_{i=1}^k \\frac{1}{\\lambda_i} &gt; k\\).\n\n\nIn an orthogonal matrix, the eigenvalues are all \\(\\pm1\\), but since the correlation matrix is positive semidefinite, the eigenvalues are all \\(+1\\).\n\nLarger sums of the reciprocal values of the eigenvalues is indicative of higher degrees of collinearity. In practice, we might use some cutoff to indicate when the collinearity is problematic. One such cutoff used is, if the sum is greater than five times the number of predictors, it is a sign of collinearity.\n\\[\n\\mathrm{IF} \\quad \\sum_{i=1}^k \\frac{1}{\\lambda_i} &gt; 5k \\quad \\mathrm{THEN} \\quad \\mathrm{collnearity~is~a~problem}\n\\]\n\n\nIn practice, perfect collinearity is rare, but near perfect collinearity can exist and is indicated when at least one of the eigenvalues is near zero, and is quite a bit smaller than the others.\n\n\n\nUsing R to Compute the Eigenvalues of the Correlation Matrix\nBecause collinearity indicates dependence among the predictors, we would want to compute the eigenvalues for the correlation matrix of the predictors (do not include the outcome when computing this matrix). We can then use the eigen() function to compute the eigenvalues of a square matrix.\nIn previous classes, I have been using the correlate() function from the {corrr} package to produce correlation matrices. This function produces a formatted output that is nice for displaying the correlation matrix, but, because of its formatting, is not truly a matrix object. Instead, we will use the cor() function, which produces a matrix object, to produce the correlation matrix.\n\n# Correlation matrix of predictors\nr_xx = cor(eeo[c(\"faculty\", \"peer\", \"school\")])\nr_xx\n\n          faculty      peer    school\nfaculty 1.0000000 0.9600806 0.9856837\npeer    0.9600806 1.0000000 0.9821601\nschool  0.9856837 0.9821601 1.0000000\n\n\nOnce we have the correlation matrix, we can use the eigen() function to compute the eigenvalues (and eigenvectors) of the inputted correlation matrix.\n\n# Compute eigenvalues and eigenvectors\neigen(r_xx)\n\neigen() decomposition\n$values\n[1] 2.951993158 0.040047507 0.007959335\n\n$vectors\n           [,1]        [,2]       [,3]\n[1,] -0.5761385  0.67939712 -0.4544052\n[2,] -0.5754361 -0.73197527 -0.3648089\n[3,] -0.5804634  0.05130072  0.8126687\n\n# Sum of reciprocal of eigenvalues\nsum(1 / eigen(r_xx)$values)\n\n[1] 150.9477\n\n\nWe compare the sum of the reciprocal of the eigenvalues to five times the number of predictors; \\(5 \\times 3 =15\\). Since this sum is greater than 15, we would conclude that there is a collinearity problem for this model."
  },
  {
    "objectID": "notes/06-01-diagnosing-collinearity.html#condition-indices",
    "href": "notes/06-01-diagnosing-collinearity.html#condition-indices",
    "title": "üìù Diagnosing Collinearity",
    "section": "Condition Indices",
    "text": "Condition Indices\nA condition number for a matrix and computational task quantifies how sensitive the result is to perturbations in the input data and to roundoff errors made during the solution process. If minor changes to the matrix elements result in large differences in the computation (say of the inverse), we say that the matrix is ‚Äúill-conditioned‚Äù. It is important to note that a condition number applies not only to a particular matrix, but also to the particular computation being carried out. That is, a matrix can be ill-conditioned for inversion while the eigenvalue problem is well-conditioned.\nA third common diagnostic measure of collinearity is to compute the condition number of the correlation matrix of the model predictors. This tells us whether small changes in the data will lead to large changes in regression coefficient estimates. To compute the condition number, we need to compute the condition index for each of the eigenvalues of the correlation matrix based on the model predictors. Each eigenvalue has an associated condition index, and the jth eigenvalue‚Äôs condition index is denoted \\(\\kappa_j\\), where,\n\\[\n\\kappa_j = \\sqrt{\\frac{\\lambda_{\\mathrm{Max}}}{\\lambda_j}}\n\\]\nand \\(\\lambda_{\\mathrm{Max}}\\) is the largest eigenvalue. The largest eigenvalue will have a condition index of,\n\\[\n\\begin{split}\n\\kappa_{\\lambda_\\mathrm{Max}} &= \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Max}}} \\\\[1ex]\n&= 1\n\\end{split}\n\\]\nThe smallest eigenvalue will have a condition index of\n\\[\n\\kappa_{\\lambda_\\mathrm{Min}} = \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}}\n\\]\nThis value will be larger than 1 since \\(\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}\\) will be greater than 1. In general, the largest eigenvalue will have a condition index of 1 and the other condition indices for every other eigenvalue will be larger than one.\nThe condition number of the correlation matrix is equivalent to the condition index for the smallest eigenvalue, that is,\n\\[\n\\kappa = \\sqrt{\\frac{\\lambda_\\mathrm{Max}}{\\lambda_\\mathrm{Min}}}\n\\]\nIf the condition number is small, it indicates that the predictors are not collinear, whereas large condition numbers are evidence supporting collinearity.\nFrom empirical work, a condition number between 10 and 30 indicates the presence of multicollinearity. When the condition number is larger than 30, the multicollinearity is regarded as strong and corrective action will almost surely need to be taken. Below we compute the condition indices and the condition number for our empirical example.\n\n# Sort eigenvalues from largest to smallest\nlambda = sort(eigen(r_xx)$values, decreasing = TRUE)\n\n# View eigenvalues\nlambda\n\n[1] 2.951993158 0.040047507 0.007959335\n\n# Compute condition indices\nsqrt(max(lambda) / lambda)\n\n[1]  1.000000  8.585586 19.258359\n\n# Compute condition number directly\nsqrt(max(lambda) / min(lambda))\n\n[1] 19.25836\n\n\nThe condition number of the correlation matrix, \\(\\kappa = 19.26\\), suggests there is collinearity among the predictors."
  },
  {
    "objectID": "notes/06-02-pca-via-spectral-decomposition.html",
    "href": "notes/06-02-pca-via-spectral-decomposition.html",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to principal components analysis via spectral decomposition. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(car)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")\nThe problem we faced from the last set of notes, was that the predictors in the model were collinear, so we encountered computational issues when trying to estimate the effects and standard errors. One method to deal with collinearity among a set of predictors is to combine the predictors into a smaller subset of orthogonal measures (called principal components) that can be used instead of the original predictors. This subset of measures will not have the collinearity problems (they are orthogonal to one another), but constitute a slightly smaller amount of ‚Äúvariance accounted for‚Äù than the original set of predictors."
  },
  {
    "objectID": "notes/06-02-pca-via-spectral-decomposition.html#matrix-algebra-to-carry-out-the-pca-using-spectral-decomposition",
    "href": "notes/06-02-pca-via-spectral-decomposition.html#matrix-algebra-to-carry-out-the-pca-using-spectral-decomposition",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "Matrix Algebra to Carry Out the PCA using Spectral Decomposition",
    "text": "Matrix Algebra to Carry Out the PCA using Spectral Decomposition\nTo carry out the spectral decomposition in R, we need to create the matrix of the predictors (\\(\\mathbf{X}_p\\)), compute the \\(\\mathbf{X}_p^\\intercal\\mathbf{X}_p = \\mathbf{PDP}^\\intercal\\) matrix, and then use the eigen() function to carry out the spectral decomposition.\n\n# Create predictor matrix\nX_p = eeo |&gt;\n  select(peer, faculty) |&gt;\n  data.matrix()\n\n# Spectral decomposition\nspec_decomp = eigen(t(X_p) %*% X_p)\nspec_decomp\n\neigen() decomposition\n$values\n[1] 137.561000   2.724415\n\n$vectors\n          [,1]       [,2]\n[1,] 0.6469680 -0.7625172\n[2,] 0.7625172  0.6469680\n\n\nThe matrix of eigenvectors, in the $vectors component, compose the P matrix and make up the set of basis vectors for the rotated predictor space. The elements in the $values component are the diagonal elements in D and are the eigenvalues. The decomposition is:\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_p\\mathbf{X}_p &= \\mathbf{PDP}^\\intercal \\\\[1em]\n\\begin{bmatrix}59.16 & 66.52 \\\\ 66.62 & 81.12\\end{bmatrix} &= \\begin{bmatrix}0.647 & -0.763 \\\\ 0.762 & 0.647\\end{bmatrix} \\begin{bmatrix}137.561 & 0  \\\\ 0 & 2.724 \\end{bmatrix} \\begin{bmatrix}0.647 & -0.763 \\\\ 0.762 & 0.647\\end{bmatrix}^\\intercal\n\\end{split}\n\\]\nThe span of the basis vectors define the principal components, with the first eigenvector defining the first principal component and the second eigenvector defining the second principal component. (Note: There number of principal components will always be the same as the number of predictors in the \\(\\mathbf{X}_p\\) matrix.)\nWe can post-multiply the matrix of the original predictor values (in \\(\\mathbf{X}_p\\)) by this matrix of basis vectors to obtain the predictor values in the rotated space.\n\n# Matrix of basis vectors for rotated predictor space\nrot_basis = spec_decomp$vectors\n\n# Compute rotated values under the new basis\nrot_pred = X_p %*% rot_basis\nhead(rot_pred)\n\n            [,1]        [,2]\n[1,]  0.48641930  0.36669037\n[2,]  0.91525519  0.14806327\n[3,] -1.03087107 -0.06220262\n[4,] -1.74270855  0.11707722\n[5,]  0.01287131  0.25376126\n[6,]  0.23695822  0.03365744\n\n\nFor example, the first observation, has a value of 0.486 on the first principal component and a value of 0.367 on the second principal component. Similarly, the second observation has a value of 0.915 on the first principal component and a value of 0.148 on the second principal component. Each observation has a set of values on the principal components.\nThe eigenvalues are related to the variances of the principal components. Because we decomposed the \\(\\mathbf{X}_p^\\intercal\\mathbf{X}_p = \\mathbf{PDP}^\\intercal\\) matrix, the variance on each prinicpal component can be computed as:\n\\[\n\\mathrm{Var}(\\mathrm{PC}_i) = \\frac{\\lambda_i}{n-1}\n\\]\nIn our example, the variances can be computed as:\n\n# Compute variances of PCs\nvar_pc = spec_decomp$values / (70 - 1)\nvar_pc\n\n[1] 1.99363769 0.03948427\n\n\nThe first principal component has the largest variance, which will always be the case. Remember, the principal components are selected so the first component maximizes the variation in the predictor space, the second component will maximize the remaining variance (and be orthogonal to the first), etc.\nWe can use these variances to determine the proportion of variation in the predictor space that each principal component accounts for. This is often more useful to the applied data analyst than the actual variance measure itself. Since the principal components are orthogonal, we can sum the variances to obtain a total measure of variation in the original set of predictors accounted for by the principal components. Below, we compute the proportion of variance in the predictor space that each principal component in our example accounts for:\n\n# Compute proportion of variation\nvar_pc / sum(var_pc)\n\n[1] 0.98057949 0.01942051\n\n\nHere the first principal component accounts for 98.1% of the variation in the predictor space, and the second principal component accounts for the remaining 1.9% of the variation."
  },
  {
    "objectID": "notes/06-02-pca-via-spectral-decomposition.html#using-princomp-to-obtain-the-principal-components",
    "href": "notes/06-02-pca-via-spectral-decomposition.html#using-princomp-to-obtain-the-principal-components",
    "title": "üìù Principal Components Analysis via Spectral Decomposition",
    "section": "Using princomp() to Obtain the Principal Components",
    "text": "Using princomp() to Obtain the Principal Components\nWe can also use the R function princomp() to obtain the principal components based on the spectral decomposition. We provide this function with a data frame of the predictors.\n\n# Select predictors\neeo_pred = eeo |&gt;\n  select(faculty, peer)\n\n# Create princomp object\nmy_pca = princomp(eeo_pred)\n\n# View output\nsummary(my_pca, loadings = TRUE)\n\nImportance of components:\n                          Comp.1     Comp.2\nStandard deviation     1.4002088 0.19725327\nProportion of Variance 0.9805406 0.01945935\nCumulative Proportion  0.9805406 1.00000000\n\nLoadings:\n        Comp.1 Comp.2\nfaculty  0.763  0.647\npeer     0.647 -0.763\n\n\nThe values of the principal components, the rotated set of basis vectors, are given in the loadings output. Note that the signs of the principal components are arbitrary. For example, the vector associated with the first principal component could also have been \\((-0.763, -0.647)\\) and that for the second principal component could have been \\((-0.647, 0.763)\\). The variances of each component can be computed by squaring the appropriate standard deviations in the output.\n\n# Compute variance of PC1\n1.4002088 ^ 2\n\n[1] 1.960585\n\n# Compute variance of PC2\n0.19725327 ^ 2\n\n[1] 0.03890885\n\n\nWe can use the variance measures to obtain a total measure of variation in the original set of predictors accounted for by each of the principal components.\n\n# Compute total variation accounted for\ntotal_var = 1.4002088 ^ 2 + 0.19725327 ^ 2\ntotal_var\n\n[1] 1.999494\n\n# Compute variation accounted for by PC1\n(1.4002088 ^ 2) / total_var\n\n[1] 0.9805406\n\n# Compute variation accounted for by PC2\n(0.19725327 ^ 2) / total_var\n\n[1] 0.01945935\n\n\nThis suggests that the first principal component accounts for 98% of the variance in the original set of predictors and that the second principal component accounts for 2% of the variance. (Same as we computed in the matrix algebra.) Note that these values are also given in the summary() output.\nWe can also obtain the principal component scores (the values under the rotation) for each observation by accessing the scores element of the princomp object. (Below we only show the first six scores.)\n\n# Get PC scores\npc_scores = my_pca$scores\n\n# View PC scores\nhead(pc_scores)\n\n          Comp.1      Comp.2\n[1,]  0.41884376  0.37000669\n[2,]  0.84765375  0.15132881\n[3,] -1.09849740 -0.05870659\n[4,] -1.81031365  0.12065755\n[5,] -0.05471761  0.25713367\n[6,]  0.16934323  0.03700331\n\n\nThese are slightly different than the scores we obtained by multiplying the original predictor values by the new basis matrix. For example, the PC scores for the first observation were \\(-0.486\\) and \\(0.367\\). The princomp() function mean centers each variable prior to multiplying by the basis matrix.\n\n# Mimic scores from princomp()\nold = t(c(0.608 - mean(eeo$faculty), 0.0351 - mean(eeo$peer)))\n\n# Compute PC scores\nold %*% basis\n\n          [,1]      [,2]\n[1,] 0.4186997 0.3699581\n\n\n\nBecause we want the principal components to be solely functions of the predictors, we mean center them. Otherwise we would have to include a column of ones (intercept) in the \\(\\mathbf{X}_p\\) matrix. Mean centering the predictors makes each predictor orthogonal to the intercept, in which case it can be ignored. (This is similar to how mean centering predictors removes the intercept from the fitted equation.)\n\nSince we only have two principal components, we can visualize the scores using a scatterplot.\n\n# Create data frame of scores\npc_scores = pc_scores |&gt;\n  data.frame()\n\n# Plot the scores\nggplot(data = pc_scores, aes(x = Comp.1, y = Comp.2)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"lightgrey\") +\n  geom_vline(xintercept = 0, color = \"lightgrey\") +\n  scale_x_continuous(name = \"Principal Component 1\", limits = c(-4, 4)) +\n  scale_y_continuous(name = \"Principal Component 2\", limits = c(-4, 4)) +\n  theme_bw() +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nRotated predictor space using the principal components as the new basis.\n\n\n\n\nConceptually this visualization shows the rotated predictor space after re-orienting the rotated coordinate system. From this visualization, it is also clear that there is much more variation in the values of the first principal component than in the second principal component."
  },
  {
    "objectID": "notes/06-03-pca-via-svd.html",
    "href": "notes/06-03-pca-via-svd.html",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to principal components analysis via singular value decomposition. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n\n\n\n  \n\n\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")"
  },
  {
    "objectID": "notes/06-03-pca-via-svd.html#pca-using-svd-matrix-algebra",
    "href": "notes/06-03-pca-via-svd.html#pca-using-svd-matrix-algebra",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "PCA using SVD: Matrix Algebra",
    "text": "PCA using SVD: Matrix Algebra\nTo carry out a principal components analysis, we need to use SVD to decompose the matrix \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\), where \\(\\mathbf{X}_{\\mathrm{Predictor}}\\) is a matrix of the predictors being used in the PCA. Below, we create the \\(\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix we use the svd() function to decompose the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix using singular value decomposition.\n\n# Create matrix of predictors\nX_p = as.matrix(eeo[ , c(\"faculty\", \"peer\", \"school\")])\n\n# SVD decomposition\nsv_decomp = svd(t(X_p) %*% X_p)\n\n# View results\nsv_decomp\n\n$d\n[1] 209.3295610   2.7303093   0.5833274\n\n$u\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n\n$v\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n\n\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[1em]\n\\begin{bmatrix}81.123 & 66.518 & 75.512 \\\\ 66.518 & 59.163 & 64.251 \\\\ 75.512 & 64.251 & 72.358\\end{bmatrix} &= \\begin{bmatrix}0.617 & 0.670 & -0.412 \\\\ -0.524 & -0.741 & -0.419 \\\\ -0.586 & -0.042 & 0.809\\end{bmatrix} \\begin{bmatrix}209.330 & 0 & 0 \\\\ 0 & 2.730 & 0 \\\\ 0 & 0 & 0.583 \\end{bmatrix} \\begin{bmatrix}-0.617 & -0.524 & -0.586 \\\\ 0.670 & -0.741 & -0.042 \\\\ -0.412 & -0.419 &  0.809 \\end{bmatrix}\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/06-03-pca-via-svd.html#understanding-what-the-matrix-algebra-is-doing",
    "href": "notes/06-03-pca-via-svd.html#understanding-what-the-matrix-algebra-is-doing",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Understanding What the Matrix Algebra is Doing",
    "text": "Understanding What the Matrix Algebra is Doing\nMathematically, since any matrix can be decomposed using SVD, we can also decompose \\(\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\\). Then we can write the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix, \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\), as:\n\\[\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})^{\\intercal} (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})\n\\]\nRe-expressing this we get:\n\\[\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{V}\\mathbf{D}^{\\intercal}\\mathbf{U}^{\\intercal}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[0.5em]\n\\end{split}\n\\]\nSince D is a diagonal matrix, \\(\\mathbf{D}^{\\intercal}\\mathbf{D} = \\mathbf{D}^2\\), so reducing this expression gives:\n\\[\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{V}\\mathbf{D}^2\\mathbf{V}^{\\intercal}\n\\]\nThe matrices V and \\(\\mathbf{V}^{\\intercal}\\) are both orthogonal basis matrices that ultimately act to change the coordinate system by rotating the original basis vectors used in the predictor space. The \\(\\mathbf{D}^2\\) matrix is diagonalizing the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix which amounts to finding the the major axes in the data ellipse along which our data varies."
  },
  {
    "objectID": "notes/06-03-pca-via-svd.html#scaling-the-predictors",
    "href": "notes/06-03-pca-via-svd.html#scaling-the-predictors",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Scaling the Predictors",
    "text": "Scaling the Predictors\nIn practice, it is important to scale all the predictors used in the PCA. This is especially true when the variables are measured in different metrics or have varying degrees of magnitude. In these cases, not scaling the predictors will often result in results in which variables with large magnitudes of scale dominate the PCA. It also is helpful when the predictors are measured using qualitatively different scales (e.g., one is measured in dollars and another in years of education).\n\nRecall, the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix for a set of standardized predictors his the correlation matrix of the predictors. Thus, the SVD is actually being carried out on the correlation matrix rather than the raw \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix.\n\nWhile it isn‚Äôt necessary to also center the predictors, it is common to simply standardize the set of predictors being used in the PCA (i.e., convert them to z-scores); thus both centering and scaling them. To do this, we will pipe the selected predictors into the scale() function prior to piping into the prcomp() function.\n\n# Fit the PCA using SVD decomposition on standardized predictors\nsvd_pca_z = eeo |&gt;\n  select(faculty, peer, school) |&gt;\n  scale(center = TRUE, scale = TRUE) |&gt;\n  prcomp()\n\n# View standard deviations and rotation matrix (eigenvector matrix)\nsvd_pca_z\n\nStandard deviations (1, .., p=3):\n[1] 1.71813654 0.20011873 0.08921511\n\nRotation (n x k) = (3 x 3):\n               PC1         PC2        PC3\nfaculty -0.5761385  0.67939712 -0.4544052\npeer    -0.5754361 -0.73197527 -0.3648089\nschool  -0.5804634  0.05130072  0.8126687\n\n# tidy version of the rotation matrix (good for graphing)\nsvd_pca_z |&gt;\n  tidy(matrix = \"rotation\")\n\n\n\n  \n\n\n# View sds, variance accounted for\nsvd_pca_z |&gt;\n  tidy(matrix = \"eigenvalues\")\n\n\n\n  \n\n\n# Obtain PC scores\npc_scores = augment(svd_pca_z)\npc_scores\n\n\n\n  \n\n\n\nHere the results from using the standardized predictors are not that different from the previous results since the variables were already reported as z-scores to begin with. The variance accounted for by the principal components is comparable (within rounding); the standardization of the predictors does not change this. The actual principal components in the V (rotation) matrix are different because of the centering and scaling, but the interpretations are the same as when we used the decomposition based on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix. Similarly, because of the centering and scaling, the PC scores are different."
  },
  {
    "objectID": "notes/06-03-pca-via-svd.html#behind-the-scenes",
    "href": "notes/06-03-pca-via-svd.html#behind-the-scenes",
    "title": "üìù Principal Components Analysis via Singular Value Decomposition",
    "section": "Behind the Scenes",
    "text": "Behind the Scenes\nBy standardizing the predictors, we are carrying out the SVD on the correlation matrix of the predictors rather than on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}\\) matrix. To see this, recall that the correlation matrix of the predictors (\\(\\mathbf{R_X}\\)) is based on the standardized predictors, namely,\n\nThis implies that you can also carry out PCA on summaries of the predictors (rather than the raw data) by decomposing either the covariance matrix of the predictors or the correlation matrix of the predictors. This can be useful for example, when trying to reproduce the results of a PCA from a published paper, in which authors will often report summaries of the data used (e.g., correlation matrices) but not the raw data.\n\n\\[\n\\mathbf{R_X} = \\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big)\n\\]\nThe \\(1/(n-1)\\) component is a scalar and is pulled out so that the decomposition is carried out on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\) matrix:\n\\[\n\\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big) = \\frac{1}{n-1}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\n\\]\nSimilarly, we can also decompose the covariance matrix of the predictors (\\(\\boldsymbol\\Sigma_{\\mathbf{X}}\\)), which is based on the centered predictors,\n\\[\n\\boldsymbol\\Sigma_{\\mathbf{X}} = \\frac{1}{n-1} \\big( \\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}\\big)\n\\]\nIn this case, the decomposition is carried out on the \\(\\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}\\) matrix. To do this using prcomp() we would change the scale= argument to FALSE in the scale() function, while still leaving center=TRUE."
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html",
    "href": "notes/06-04-biased-estimation-ridge-regression.html",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "",
    "text": "In this set of notes, we will give a brief introduction to ridge regression. We will continue to use the equal-education-opportunity.csv data provided from Chatterjee & Hadi (2012) to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\nAny table is essentially a rectangular layout (rows and columns) of information. Below I show two common tables of statistical output. I have also added guide-lines to show the rectangular display of information within each of these tables.\nA script file for the analyses in these notes is also available:\n# Load libraries\nlibrary(broom)\nlibrary(MASS)\nlibrary(tidyverse)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)"
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#matrix-formulation-of-ridge-regression",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#matrix-formulation-of-ridge-regression",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Matrix Formulation of Ridge Regression",
    "text": "Matrix Formulation of Ridge Regression\nRecall that the OLS estimates are given by:\n\\[\n\\mathbf{b} = (\\mathbf{X}^{\\intercal}\\mathbf{X})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{y}\n\\]\nUnder collinearity, the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix is ill-conditioned. (A matrix is said to be ill-conditioned if it has a high condition number, meaning that small changes in the data impact the regression results. This ill-conditioning results in inaccuracy when we compute the inverse of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix, which translates into bad estimates of the coefficients and standard errors.\nTo see this, consider our EEO example data. We first standardize the variables (so we can omit the ones column in the design matrix) using the scale() function. Note that the output of the scale() function is a matrix. Then, we will select the predictors using indexing and compute the condition number for the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix.\n\n# Standardize all variables in the eeo data frame\nz_eeo = eeo |&gt; \n  scale()\n\n# Create and view the design matrix\nX = z_eeo[ , c(\"faculty\", \"peer\", \"school\")]\nhead(X)\n\n        faculty        peer     school\n[1,]  0.5158617 -0.01213684  0.1310782\n[2,]  0.6871673  0.46812962  0.4901170\n[3,] -0.8084583 -0.71996624 -0.7994390\n[4,] -1.2024935 -1.36577136 -1.0479983\n[5,]  0.1150408 -0.25030749  0.1078451\n[6,]  0.1413252  0.08793894  0.2356566\n\n# Get eigenvalues\neig_val = eigen(t(X) %*% X)$values\n\n# Compute condition number\nsqrt(max(eig_val) / min(eig_val))\n\n[1] 19.25836\n\n\nWe can inflate the diagonal elements of \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) to better condition the matrix. This, hopefully, leads to more stability in the inverse matrix and produces better (albeit biased) coefficient estimates. To do this, we can add some constant amount (\\(\\lambda\\)) to each of the diagonal elements of \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\), prior to finding the inverse. This can be expressed as:\n\\[\n\\widetilde{\\mathbf{b}} = (\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{Y}\n\\]\nwhere the tilde over b indicates that the coefficients are biased. To see how increasing the diagonal values leads to better conditioning, we will add some value (here \\(\\lambda=10\\), but it could be any value between 0 and positive infinity) to each diagonal element of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix in our example.\n\nTechnically this equation is for standardized variables; it assumes that there is no ones column in the X matrix. This is because we only want to add the \\(\\lambda\\) value to the parts of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix associated with the predictors.\n\n\n# Add 50 to each of the diagonal elements of X^T(X)\ninflated = t(X) %*% X + 10*diag(3)\n\n# Get eigenvalues\neig_val_inflated = eigen(inflated)$values\n\n# Compute condition number\nsqrt(max(eig_val_inflated) / min(eig_val_inflated))\n\n[1] 4.500699\n\n\nThe condition number has decreased from 19.26 (problematic collinearity) to 4.5 (non-collinear). Adding 10 to each diagonal element of the \\(\\mathbf{X}^{\\intercal}\\mathbf{X}\\) matrix resulted in a better conditioned matrix!"
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#using-an-built-in-r-function",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#using-an-built-in-r-function",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Using an Built-In R Function",
    "text": "Using an Built-In R Function\nWe can also use the lm.ridge() function from the {MASS} package to fit a ridge regression. This function uses a formula based on variables from a data frame in the same fashion as the lm() function. It also takes the argument lambda= which specifies the values of \\(\\lambda\\) to use in the penalty term. Because the data= argument has to be a data frame (or tibble), we convert the standardized data (which is a matrix) to a data frame using the data.frame() function.\n\n# Create data frame for use in lm.ridge()\nz_data = z_eeo |&gt;\n  data.frame()\n\n# Fit ridge regression (lambda = 0.1)\nridge_1 = lm.ridge(achievement ~ -1 + faculty + peer + school, data = z_data, lambda = 0.1)\n\n# View coefficients\ntidy(ridge_1)"
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#comparison-to-the-ols-coefficients",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#comparison-to-the-ols-coefficients",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Comparison to the OLS Coefficients",
    "text": "Comparison to the OLS Coefficients\nHow do these biased coefficients from the ridge regression compare to the unbiased coefficients from the OLS estimation? Below, we fit a standardized OLS model to the data, and compare the coefficients to those from the ridge regression with \\(\\lambda=0.1\\).\n\n# Fit standardized OLS model\nlm.1 = lm(achievement ~ faculty + peer + school - 1, data = z_data)\n\n# Obtain coefficients\ncoef(lm.1)\n\n   faculty       peer     school \n 0.5248647  0.9449056 -1.0272986 \n\n\nComparing these coefficients from the different models:\n\n\n\nComparison of the coefficients from the OLS (Œª=0) and the ridge regression using Œª=0.1 based on the standardized data.\n\n\nPredictor\nŒª=0\nŒª=0.1\n\n\n\n\nFaculty\n0.525\n0.436\n\n\nPeer\n0.945\n0.856\n\n\nSchool\n-1.027\n-0.851\n\n\n\n\n\n\n\nBased on this comparison, the ridge regression has ‚Äúshrunk‚Äù the estimate of each coefficient toward zero. Remember, the larger the value of \\(\\lambda\\), the more the coefficient estimates will shrink toward 0. The table below shows the coefficient estimates for four different values of \\(\\lambda\\).\n\n\n\nComparison of the coefficients from the OLS (Œª=0) and three ridge regressions (using Œª=0.1, Œª=1, and Œª=10) based on the standardized data. The condition numbers for the XTX + ŒªI matrix are also provided.\n\n\nPredictor\n&lambda;=0\n&lambda;=0.1\n&lambda;=1\n&lambda;=10\n\n\n\n\nFaculty\n0.525\n0.436\n0.180\n0.114\n\n\nPeer\n0.945\n0.856\n0.537\n0.227\n\n\nSchool\n-1.027\n-0.851\n-0.283\n0.073\n\n\nCondition Number\n370.884\n313.908\n132.125\n20.256\n\n\n\n\n\n\n\nExamining these results we see that increasing the penalty (i.e., higher \\(\\lambda\\) values) better conditions the \\(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I}\\) matrix, but a higher penalty also shrinks the estimates toward zero more (increased bias). This implies that we want a \\(\\lambda\\) that is large enough so that it conditions the \\(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I}\\) matrix, but not too large because we want to introduce the least amount of bias as possible."
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#ridge-trace",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#ridge-trace",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Ridge Trace",
    "text": "Ridge Trace\nA ridge trace computes the ridge regression coefficients for many different values of \\(\\lambda\\). A plot of this trace, can be examined to select the \\(\\lambda\\) value. To do this, we pick the smallest value for \\(\\lambda\\) that produces stable regression coefficients. Here we examine the values of \\(\\lambda\\) where \\(\\lambda = \\{ 0,0.001,0.002,0.003,\\ldots,100\\}\\).\nTo create this plot, we fit a ridge regression that includes a sequence of values in the lambda= argument of the lm.ridge() function. Then we use the tidy() function to summarize the output from this model. This output includes the coefficient estimates for each of the \\(\\lambda\\) values in our sequence. We can then create a line plot of the coefficient values versus the \\(\\lambda\\) values for each predictor.\n\n# Fit ridge model across several lambda values\nridge_models = lm.ridge(achievement ~ -1 + faculty + peer + school, data = z_data, \n                        lambda = seq(from = 0, to = 100, by = 0.01))\n\n# Get tidy() output\nridge_trace = tidy(ridge_models)\nridge_trace\n\n\n\n\n\nRidge plot showing the size of the standardized regression coefficients for \\(\\lambda\\) values between 0 (OLS) and 100.\n\n# Ridge trace\nggplot(data = ridge_trace, aes(x = lambda, y = estimate)) +\n  geom_line(aes(group = term, color = term)) +\n  theme_bw() +\n  xlab(expression(lambda)) +\n  ylab(\"Coefficient estimate\") +\n  ggsci::scale_color_d3(name = \"Predictor\")\n\n\n\n\nRidge plot showing the size of the standardized regression coefficients for \\(\\lambda\\) values between 0 (OLS) and 100.\n\n\n\n\nWe want to find the \\(\\lambda\\) value where the lines begin to flatten out; where the coefficients are no longer changing value. This is difficult to ascertain, but somewhere around \\(\\lambda=50\\), there doesn‚Äôt seem to be a lot of change in the coefficients. This suggests that a \\(\\lambda\\) value around 50 would produce stable coefficient estimates."
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#aic-value",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#aic-value",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "AIC Value",
    "text": "AIC Value\nIt turns out that not only is it difficult to make a subjective call about where the trace lines begin to flatten, but even when people do make this determination, they often select a \\(\\lambda\\) value that is too high. A better method for obtaining \\(\\lambda\\) is to compute a model-level metric that we can then evaluate across the models produced by the different values of \\(\\lambda\\). One such metric is the Akiake Information Criteria (AIC). We can compute the AIC for a ridge regression as\n\\[\n\\mathrm{AIC} = n \\times \\ln\\big(\\mathbf{e}^{\\intercal}\\mathbf{e}\\big) + 2(\\mathit{df})\n\\]\nwhere n is the sample size, \\(\\mathbf{e}\\) is the vector of residuals from the ridge model, and df is the degrees of freedom associated with the ridge regression model, which we compute by finding the trace of the H matrix, namely,\n\\[\ntr(\\mathbf{H}_{\\mathrm{Ridge}}) =  tr(\\mathbf{X}(\\mathbf{X}^{\\intercal}\\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^{\\intercal})\n\\]\nFor example, to compute the AIC value associated with the ridge regression estimated using a \\(\\lambda\\) value of 0.1 we can use the following syntax.\n\n# Compute coefficients for ridge model\nb = solve(t(X) %*% X + 0.1*diag(3)) %*% t(X) %*% y\n\n# Compute residual vector\ne = y - (X %*% b)\n\n# Compute H matrix\nH = X %*% solve(t(X) %*% X + 0.1*diag(3)) %*% t(X)\n\n# Compute df\ndf = sum(diag(H))\n\n# Compute AIC\naic = 70 * log(t(e) %*% e) + 2 * df\naic\n\n         [,1]\n[1,] 285.8729\n\n\nWe want to compute the AIC value for every single one of the models associated with the \\(\\lambda\\) values from our sequence we used to produce the ridge trace plot. To do this, we will create a function that will compute the AIC from a given \\(\\lambda\\) value.\n\n# Function to compute AIC based on inputted lambda value\nridge_aic = function(lambda){\n  b = solve(t(X) %*% X + lambda*diag(3)) %*% t(X) %*% y\n  e = y - (X %*% b)\n  H = X %*% solve(t(X) %*% X + lambda*diag(3)) %*% t(X)\n  df = sum(diag(H))\n  n = length(y)\n  aic = n * log(t(e) %*% e) + 2 * df\n  return(aic)\n}\n\n# Try function\nridge_aic(lambda = 0.1)\n\n         [,1]\n[1,] 285.8729\n\n\nTo be able to evaluate which \\(\\lambda\\) value is assocuated with the lowest AIC, we need to compute the AIC for many different \\(\\lambda\\) values. To do this, we will create a data frame that has a column that includes the \\(\\lambda\\) values we want to evaluate. Then we use the rowwise() and mutate() functions to apply the ridge_aic() function to each of the lambda values. Finally, we can use filter() to find the \\(\\lambda\\) value associated with the smallest AIC value.\n\n# Create data frame with column of lambda values\n# Create a new column by using the ridge_aic() function for each row\nmy_models = data.frame(\n  Lambda = seq(from = 0, to = 100, by = 0.01)\n  ) |&gt;\n  rowwise() |&gt;\n   mutate(\n    AIC = ridge_aic(Lambda)\n  ) |&gt;\n  ungroup() #Turn off the rowwise() operation\n\n# Find lambda associated with smallest AIC\nmy_models |&gt; \n  filter(AIC == min(AIC))\n\n\n\n  \n\n\n\nA \\(\\lambda\\) value of 21.77 produces the smallest AIC value, so this is the \\(\\lambda\\) value we will adopt.\n\n# Re-fit ridge regression using lambda = 21.77\nridge_smallest_aic = lm.ridge(achievement ~ -1 + faculty + peer + school, \n                              data = z_data, lambda = 21.77)\n\n# View coefficients\ntidy(ridge_smallest_aic)\n\n\n\n  \n\n\n\nBased on using \\(\\lambda=21.77\\), the fitted ridge regression model is:\n\\[\n\\hat{\\mathrm{Achievement}}^{\\star}_i = 0.115(\\mathrm{Faculty}^{\\star}_i) + 0.174(\\mathrm{Peer}^{\\star}_i) + 0.099(\\mathrm{School}^{\\star}_i)\n\\]"
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#estimating-sampling-variance",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#estimating-sampling-variance",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Estimating Sampling Variance",
    "text": "Estimating Sampling Variance\nIn theory it is possible to obtain the sampling variances for the ridge regression coefficients using matrix algebra:\n\\[\n\\sigma^2_{\\mathbf{b}} = \\sigma^2_{e}(\\mathbf{X}^\\intercal \\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^\\intercal \\mathbf{X} (\\mathbf{X}^\\intercal \\mathbf{X} + \\lambda\\mathbf{I})^{-1}\n\\]\nwhere \\(\\sigma^2_e\\) is the the error variance estimated from the standardized OLS model.\n\n# Fit standardized model to obtain sigma^2_e\nglance(lm(achievement ~ -1 + faculty + peer + school, data = z_data))\n\n\n\n  \n\n\n# Compute sigma^2_epsilon\nresid_var = 0.9041214 ^ 2\n\n# Compute variance-covariance matrix of ridge estimates\nW = solve(t(X) %*% X + 21.77*diag(3))\nvar_b = resid_var * W %*% t(X) %*% X %*% W\n\n# Compute SEs\nsqrt(diag(var_b))\n\n   faculty       peer     school \n0.05482363 0.05670386 0.04133673 \n\n\nComparing these SEs to the SEs from the OLS regression:\n\n\n\nComparison of the standard errors from the OLS (Œª=0) and ridge regression (Œª;=21.77) based on the standardized data.\n\n\nPredictor\n&lambda;=0\n&lambda;=21.77\n\n\n\n\nFaculty\n0.667\n0.055\n\n\nPeer\n0.598\n0.057\n\n\nSchool\n0.993\n0.041\n\n\n\n\n\n\n\nBased on this comparison, we can see that the standard errors from the ridge regression are quite a bit smaller than those from the OLS. We can then use the estimates and SEs to compute t- and p-values, and confidence intervals. Here we only do it for the school facilities predictor (since it is of primary interest based on the RQ) but one could do it for all the predictors.\n\n# Compute t-value for school predictor\nt = 0.09944444 / 0.04133673 \nt\n\n[1] 2.405716\n\n# Compute df residual\nH = X %*% solve(t(X) %*% X + 21.77*diag(3)) %*% t(X)\ndf_model = sum(diag(H))\ndf_residual = 69 - df_model\n\n# Compute p-value\np = pt(-abs(t), df = df_residual) * 2\np\n\n[1] 0.01886747\n\n# Compute CI\n0.09944444 - qt(p = 0.975, df = df_residual) * 0.04133673 \n\n[1] 0.01695739\n\n0.09944444 + qt(p = 0.975, df = df_residual) * 0.04133673\n\n[1] 0.1819315\n\n\nThis suggests that after controlling for peer influence and faculty credential, there is evidence of an effect of school facilities on student achievement (\\(p=.019\\)). The uncertainty in the 95% CI suggests that the true partial effect of school facilities is between 0.017 and 0.182. The empirical evidence is pointing toward a slight positive effect of school facilities."
  },
  {
    "objectID": "notes/06-04-biased-estimation-ridge-regression.html#footnotes",
    "href": "notes/06-04-biased-estimation-ridge-regression.html#footnotes",
    "title": "üìù Biased Estimation: Ridge Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt least within the class of linear, unbiased estimators.‚Ü©Ô∏é"
  },
  {
    "objectID": "notes/07-03-cross-validation.html",
    "href": "notes/07-03-cross-validation.html",
    "title": "üìù Cross Validation",
    "section": "",
    "text": "In the previous activity, we examined predictors of average life expectancy in a state, using data from states-2019.csv. We used several model building strategies and performance metrics to select and evaluate predictors. Unfortunately, we were evaluating the model/predictors using the same data that we used to build the model. This has several problems in practice, especially if you are using inferential metrics (p-values) to select the predictors:\nOne set of methods for dealing with these problems is to use cross-validation. The basic idea of cross-validation is to use one set of data to fit your model(s) and a completely separate set of data to evaluate the models‚Äô performance. We will again use the states-2019.csv data to introduce methods of cross-validation. After importing the data, we will also standardize all the numeric variables.\n# Load libraries\nlibrary(modelr)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(tidymodels) # Loads broom, rsample, parsnip, recipes, workflow, tune, yardstick, and dials\n\n# Import and view data\nusa = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/states-2019.csv\")\n\n# Create standardized variables after removing state names\nz_usa = usa |&gt;\n  select(-state) |&gt;\n  scale(center = TRUE, scale = TRUE) |&gt;\n  data.frame()\n\n# View data\nz_usa\nFrom our previous notes, there were a several candidate models that we may have been considering based on their AICc values. In this set of notes we will consider the best k-predictor models that had an AICc value within four of the minimum AICc value. These candidate models include:\n\\[\n\\begin{split}\n\\mathbf{M1:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M2:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M3:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M4:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\beta_4(\\mathrm{Murder~Rate}_i) + \\epsilon_i\n\\end{split}\n\\]"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#cross-validated-mean-square-error-cv-mse",
    "href": "notes/07-03-cross-validation.html#cross-validated-mean-square-error-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Cross-Validated Mean Square Error (CV-MSE)",
    "text": "Cross-Validated Mean Square Error (CV-MSE)\nOne very common metric used is the residual variance (a.k.a., mean square error). Because this is computed on the validation data rather than on the data used to fit the model, we refer to it as the Cross-Validated Mean Square Error (CV-MSE). The CV-MSE is:\n\\[\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n e_i^2\n\\]\nwhere n is the number of observations in the validation set, and \\(e_i\\) are the residuals computed on the validation set. This value summarizes the model-data misfit in the validation data. Note that because this is a residual-based measure, lower values of CV-MSE correspond to better fitting models. Because this metric is computed on the validation data (data not used to initially fit the model), it is a better measure of how the model might perform in future samples."
  },
  {
    "objectID": "notes/07-03-cross-validation.html#divide-the-sample-data-into-a-training-and-validation-set",
    "href": "notes/07-03-cross-validation.html#divide-the-sample-data-into-a-training-and-validation-set",
    "title": "üìù Cross Validation",
    "section": "Divide the Sample Data into a Training and Validation Set",
    "text": "Divide the Sample Data into a Training and Validation Set\nThere are many ways to do this, but here we will use the sample() function to randomly sample 35 cases (rows) from the z_usa data (about 2/3 of the data). These 35 cases will make up the training data. Then we will use the filter() function to select those cases. The remaining cases (those 17 observations not sampled) are put into a validation set of data.\n\n# Make the random sampling replicable\nset.seed(42)\n\n# Select the cases to be in the training set\ntraining_cases = sample(1:nrow(z_usa), size = 35, replace = FALSE)\n\n# Create training data from the sampled cases\ntrain = z_usa |&gt;\n  filter(row_number() %in% training_cases)\n\n# Create validation data from the remaining cases\nvalidate = z_usa |&gt;\n  filter(!row_number() %in% training_cases)"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#fit-the-candidate-models-to-the-training-data",
    "href": "notes/07-03-cross-validation.html#fit-the-candidate-models-to-the-training-data",
    "title": "üìù Cross Validation",
    "section": "Fit the Candidate Models to the Training Data",
    "text": "Fit the Candidate Models to the Training Data\nWe now fit the four candidate models to the observations in the training data.\n\nlm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\nlm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\nlm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#use-the-coefficients-from-the-fitted-models-and-the-validation-data-to-obtain-fitted-values-residuals-and-cv-mses",
    "href": "notes/07-03-cross-validation.html#use-the-coefficients-from-the-fitted-models-and-the-validation-data-to-obtain-fitted-values-residuals-and-cv-mses",
    "title": "üìù Cross Validation",
    "section": "Use the Coefficients from the Fitted Models and the Validation Data to Obtain Fitted Values, Residuals, and CV-MSEs",
    "text": "Use the Coefficients from the Fitted Models and the Validation Data to Obtain Fitted Values, Residuals, and CV-MSEs\nNow we can obtain the predicted life expectancy for the observations in the validation data based on the coefficients from the models fitted to the training data. These vectors of fitted values can be used to compute the residuals for the validation observations, which in turn can be used to compute the CV-MSE.\n\n# Get the predicted values for the validation data\nyhat_1 = predict(lm.1, newdata = validate)\nyhat_2 = predict(lm.2, newdata = validate)\nyhat_3 = predict(lm.3, newdata = validate)\nyhat_4 = predict(lm.4, newdata = validate)\n\n# Compute residuals and CV-MSE\nsum((validate$life_expectancy - yhat_1) ^ 2) / nrow(validate)\n\n[1] 0.7349516\n\nsum((validate$life_expectancy - yhat_2) ^ 2) / nrow(validate)\n\n[1] 0.7483797\n\nsum((validate$life_expectancy - yhat_3) ^ 2) / nrow(validate)\n\n[1] 0.8547222\n\nsum((validate$life_expectancy - yhat_4) ^ 2) / nrow(validate)\n\n[1] 0.8968336"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#select-candidate-model-with-the-lowest-cv-mse",
    "href": "notes/07-03-cross-validation.html#select-candidate-model-with-the-lowest-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Select Candidate Model with the Lowest CV-MSE",
    "text": "Select Candidate Model with the Lowest CV-MSE\nSince the CV-MSE is a measure of model misfit, the candidate model having the smallest CV-MSE is the model that should be adopted. In this case, the values for the CV-MSE suggest adopting the single predictor model.\n\n\n\nCV-MSE for four potential models based on simple cross-validation. \n\n\nModel\nCV-MSE\n\n\n\n\n1-Predictor Model\n0.735\n\n\n2-Predictor Model\n0.748\n\n\n3-Predictor Model\n0.855\n\n\n4-Predictor Model\n0.897"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#function-to-carry-out-loocv",
    "href": "notes/07-03-cross-validation.html#function-to-carry-out-loocv",
    "title": "üìù Cross Validation",
    "section": "Function to Carry Out LOOCV",
    "text": "Function to Carry Out LOOCV\nTo carry out LOOCV, we will write a function that computes \\(\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i\\) for each model given a particular case.\n\n# Function to compute CV-MSE for LOOCV\ncv_mse_i = function(case_index){\n\n  # Create training and validation data sets\n  train = z_usa |&gt; filter(row_number() != case_index)\n  validate = z_usa |&gt; filter(row_number() == case_index)\n\n  # Fit models to training data\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  # Compute fitted value for validation data\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  # Compute CV-MSE_i for each model\n  cv_mse_1 = (validate$life_expectancy - yhat_1) ^ 2\n  cv_mse_2 = (validate$life_expectancy - yhat_2) ^ 2\n  cv_mse_3 = (validate$life_expectancy - yhat_3) ^ 2\n  cv_mse_4 = (validate$life_expectancy - yhat_4) ^ 2\n\n  # Output a data frame\n  return(data.frame(cv_mse_1, cv_mse_2, cv_mse_3, cv_mse_4))\n}\n\n# Test function on Case 1\ncv_mse_i(1)\n\n\n\n  \n\n\n\nThen we can use this function to compute the four \\(\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i\\) values for each case in the data. We set up a data frame that includes a column called case that has each case number in the data. Then we use rowwise() to operate on each row separately and mutate() a new column by applying our cv_mse_i() function using map(). This creates a list column where the contents of each cell in the column is actually a list; in our case a data frame of four columns. Finally, we use unnest() to take the contents of the list column and spread them out into separate columns.\n\n# Apply cv_mse_i() function to all cases\nmy_cv_mse = data.frame(case = 1:52) |&gt;\n  rowwise() |&gt;\n  mutate(\n    cv_mse = map(case, cv_mse_i) #New list column that includes the data frame of output\n  ) |&gt;\n  unnest(cols = cv_mse) #Turn list column into multiple columns\n\n# View output\nmy_cv_mse"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#alternative-programming-use-a-for-loop",
    "href": "notes/07-03-cross-validation.html#alternative-programming-use-a-for-loop",
    "title": "üìù Cross Validation",
    "section": "Alternative Programming: Use a for() Loop",
    "text": "Alternative Programming: Use a for() Loop\nAlternatively, we could also have used a for() loop to carry out the LOOCV. Here is some example syntax (not run):\n\n# Set up empty vector to store results\nmse_1 = rep(NA, 52)\nmse_2 = rep(NA, 52)\nmse_3 = rep(NA, 52)\nmse_4 = rep(NA, 52)\nmse_5 = rep(NA, 52)\n\n# Loop through the cross-validation\nfor(i in 1:nrow(z_usa)){\n  train = z_usa |&gt; filter(row_number() != i)\n  validate = z_usa |&gt; filter(row_number() == i)\n\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  mse_1[i] = (validate$life_expectancy - yhat_1) ^ 2\n  mse_2[i] = (validate$life_expectancy - yhat_2) ^ 2\n  mse_3[i] = (validate$life_expectancy - yhat_3) ^ 2\n  mse_4[i] = (validate$life_expectancy - yhat_4) ^ 2\n\n} \n\n# Create data frame of results\nmy_cv_mse = data.frame(\n  case = 1:52,\n  cv_mse_1 = mse_1, \n  cv_mse_2 = mse_2,\n  cv_mse_3 = mse_3,\n  cv_mse_4 = mse_4\n  )"
  },
  {
    "objectID": "notes/07-03-cross-validation.html#select-model-with-lowest-cv-mse",
    "href": "notes/07-03-cross-validation.html#select-model-with-lowest-cv-mse",
    "title": "üìù Cross Validation",
    "section": "Select Model with Lowest CV-MSE",
    "text": "Select Model with Lowest CV-MSE\nWe can now compute the average CV-MSE for each of the candidate models and select the candidate model with the lowest average CV-MSE.\n\n# Compute average CV-MSE\nmy_cv_mse |&gt;\n  select(-case) |&gt;\n  summarize_all(mean)\n\n\n\n  \n\n\n\nThe LOOCV results suggest that we adopt the three-predictor model; it has the smallest average CV-MSE. Since LOOCV method is less biased than simple cross-validation (it trains the models on a much larger set of observations) its results are more believable than those from the simple cross-validation. Another advantage of LOOCV is that it will always produce the same results as opposed to simple cross-validation) since there is no randomness in producing the training and validation datasets.\n\n\n\nCV-MSE for four potential models based on simple cross-validation and Leave-One-Out Cross-Validation (LOOCV). \n\n\n\n\n\n\n\n\n\nCV-MSE\n\n\n\nModel\nSimple CV\nLOOCV\n\n\n\n\n1-Predictor Model\n0.735\n0.832\n\n\n2-Predictor Model\n0.748\n0.807\n\n\n3-Predictor Model\n0.855\n0.769\n\n\n4-Predictor Model\n0.897\n1.124\n\n\n\n\n\n\n\n\n\nComputing the CV-MSE under LOOCV: A Shortcut for OLS Models\nLOOCV can be computationally expensive when you sample is very large; we have to fit the candidate models n times. It turns out, however, that models fit with OLS, can give us the LOOCV results using the following formula:\n\\[\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n \\bigg(\\frac{e_i}{1-h_{ii}}\\bigg)^2\n\\]\nwhere \\(\\hat{y}_i\\) is the ith fitted value from the original least squares fit, and \\(h_{ii}\\) is the leverage value. This is similar to the model (biased) MSE, except the ith residual is divided by \\(1 ‚àí h_{ii}\\). Below, we compute the LOOCV CV-MSE for the three-predictor candidate model\n\n# Compute CV-MSE for Candidate Model 3\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy, data = z_usa)\n\n# Augment the model to get e_i and h_ii\nout.3 = augment(lm.3)\n\n# Compute CV-MSE for best three-predictor model\n1 / 52 * sum((out.3$.resid / (1 - out.3$.hat))^2)\n\n[1] 0.7686342"
  },
  {
    "objectID": "index.html#welcome-to-epsy-8264-advanced-multiple-regression-analysis",
    "href": "index.html#welcome-to-epsy-8264-advanced-multiple-regression-analysis",
    "title": "",
    "section": "Welcome to EPsy 8264: Advanced Multiple Regression Analysis",
    "text": "Welcome to EPsy 8264: Advanced Multiple Regression Analysis\nWelcome to EPsy 8264: Advanced Multiple Regression Analysis. This is an advanced seminar for doctoral students in education covering a diverse set of regression methodologies. We will begin with a brief review of the General Linear Model and establishment of a mathematical foundation for the estimation of regression coefficients and standard errors in these models through the use of matrix algebra. The course will also cover more advanced modeling techniques, such as regression diagnostics, WLS and sandwich estimation, PCA, shrinkage methods, model selection and local models.\nEPsy 8264 is a 3 credit course. It is expected that the academic work required of Graduate School and professional school students will exceed three hours per credit per week (see Expected Student Academic Work Policy). In my experience, it is typical for students to spend 10‚Äì15 hours a week on this course. As with every class, some students will spend more time than that on this course, while others will spend less time than that‚Äîit all depends on your prior experiences with statistics and computing. If you find yourself consistently spending more than 20 hours a week on the course, please make an appointment to see the instructor so that we can strategize about how to best optimize how you are devoting time to the course.\n\n\nA Note on Inclusion and Respect\nIn this class, we will work together to develop a learning community that is inclusive and respectful, and where every student is supported in the learning process. As a class full of diverse individuals (reflected by differences in race, culture, age, religion, gender identity, sexual orientation, socioeconomic background, abilities, professional goals, and other social identities and life experiences) I expect that different students may need different things to support and promote their learning. The TAs and I will do everything we can to help with this, but as we only know what we know, we need you to communicate with us if things are not working for you or you need something we are not providing. I hope you all feel comfortable in helping to promote an inclusive classroom through respecting one another‚Äôs individual differences, speaking up, and challenging oppressive/problematic ideas. Finally, I look forward to learning from each of you and the experiences you bring to the class."
  },
  {
    "objectID": "index.html#class",
    "href": "index.html#class",
    "title": "",
    "section": "Class",
    "text": "Class\n\nTuesday/Thursday (9:45am‚Äì11:00am): Peik Hall 215"
  }
]