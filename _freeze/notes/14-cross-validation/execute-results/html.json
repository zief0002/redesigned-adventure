{
  "hash": "ed83a3a05bbfb94b27bcfba3aee4045b",
  "result": {
    "markdown": "---\ntitle: \"📝 Cross Validation\"\nformat:\n  html:\n    code-copy: true\n    code-fold: false\n    highlight-style: zenburn\n    df-print: paged\n    css: [\"../assets/style.css\", \"../assets/notes.css\", \"../assets/gt-table-styles.css\"]\ndate: 10-13-2022\nbibliography: '../assets/epsy8264.bib'\ncsl: '../assets/apa-single-spaced.csl'\n---\n\n::: {.cell}\n\n:::\n\n\n---\n\nIn the previous activity, we examined predictors of average life expectancy in a state, using data from *states-2019.csv*. We used several model building strategies and performance metrics to select and evaluate predictors. Unfortunately, we were evaluating the model/predictors using the same data that we used to build the model. This has several problems in practice, especially if you are using inferential metrics (*p*-values) to select the predictors: \n\n- **Increased Type I error rates:** If you use *p*-values to select predictors, there are many tests you are examining across the model selection process. You probably need to adjust the *p*-values obtained from these tests to accommodate this. \n- **Overfit/Lack of generalization:** The adopted model still has the potential to not perform well on future (out-of-sample) data.\n\nOne set of methods for dealing with these problems is to use *cross-validation*. The basic idea of cross-validation is to use one set of data to fit your model(s) and a completely separate set of data to evaluate the models' performance. We will again use the *states-2019.csv* data to introduce methods of cross-validation. After importing the data, we will also standardize all the numeric variables.\n\n- [[CSV]](https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/states-2019.csv)\n- [[R Script File]](https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/scripts/14-cross-validation.R)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(modelr)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(tidymodels) # Loads broom, rsample, parsnip, recipes, workflow, tune, yardstick, and dials\n\n# Import and view data\nusa = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/states-2019.csv\")\n\n# Create standardized variables after removing state names\nz_usa = usa |>\n  select(-state) |>\n  scale(center = TRUE, scale = TRUE) |>\n  data.frame()\n\n# View data\nz_usa\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"life_expectancy\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"population\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"income\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"illiteracy\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"murder\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hs_grad\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"frost\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"area\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-1.875390080\",\"2\":\"-0.20138748\",\"3\":\"-0.91513393\",\"4\":\"0.70500165\",\"5\":\"0.90297951\",\"6\":\"-0.955626982\",\"7\":\"-1.20337822\",\"8\":\"-0.203318102\"},{\"1\":\"0.047863784\",\"2\":\"-0.77268875\",\"3\":\"0.86568367\",\"4\":\"-0.58942761\",\"5\":\"1.02638276\",\"6\":\"1.087323115\",\"7\":\"1.77777264\",\"8\":\"5.898861811\"},{\"1\":\"0.670092975\",\"2\":\"0.12393888\",\"3\":\"-0.51795285\",\"4\":\"0.31204991\",\"5\":\"0.07000761\",\"6\":\"-0.610339642\",\"7\":\"-0.29136266\",\"8\":\"0.534871825\"},{\"1\":\"-1.592558630\",\"2\":\"-0.45958823\",\"3\":\"-1.05129416\",\"4\":\"0.45073876\",\"5\":\"0.71787464\",\"6\":\"-0.869305147\",\"7\":\"-0.82907184\",\"8\":\"-0.187766018\"},{\"1\":\"1.631719907\",\"2\":\"4.53828023\",\"3\":\"0.37207930\",\"4\":\"2.62353075\",\"5\":\"-0.14594807\",\"6\":\"-1.761297443\",\"7\":\"-1.49408318\",\"8\":\"1.031728623\"},{\"1\":\"1.009490716\",\"2\":\"-0.08422076\",\"3\":\"0.73291333\",\"4\":\"-0.42762395\",\"5\":\"-0.36190375\",\"6\":\"0.713261830\",\"7\":\"1.16786223\",\"8\":\"0.418530501\"},{\"1\":\"1.235755877\",\"2\":\"-0.38461106\",\"3\":\"2.05421370\",\"4\":\"-0.72811646\",\"5\":\"-0.79381510\",\"6\":\"0.454296324\",\"7\":\"-0.33506341\",\"8\":\"-0.742124446\"},{\"1\":\"-0.178401377\",\"2\":\"-0.73951714\",\"3\":\"0.38093066\",\"4\":\"-0.24270549\",\"5\":\"0.03915680\",\"6\":\"0.195330819\",\"7\":\"0.14944486\",\"8\":\"-0.776045594\"},{\"1\":\"-0.065268796\",\"2\":\"-0.77622148\",\"3\":\"3.27909078\",\"4\":\"1.67582360\",\"5\":\"0.31681410\",\"6\":\"0.483070269\",\"7\":\"-0.17356065\",\"8\":\"-0.798276271\"},{\"1\":\"0.726659265\",\"2\":\"2.06847824\",\"3\":\"-0.35467357\",\"4\":\"1.83762726\",\"5\":\"0.10085842\",\"6\":\"-0.293826246\",\"7\":\"-1.88168980\",\"8\":\"-0.165206694\"},{\"1\":\"-0.517799117\",\"2\":\"0.58117080\",\"3\":\"-0.53678552\",\"4\":\"1.14418301\",\"5\":\"0.37851572\",\"6\":\"-0.667887532\",\"7\":\"-1.21287839\",\"8\":\"-0.119172526\"},{\"1\":\"2.027683938\",\"2\":\"-0.67897096\",\"3\":\"0.23930895\",\"4\":\"0.95926455\",\"5\":\"-0.73211348\",\"6\":\"0.857131555\",\"7\":\"-2.01659210\",\"8\":\"-0.723602794\"},{\"1\":\"0.330695235\",\"2\":\"-0.62813651\",\"3\":\"-0.85260945\",\"4\":\"-0.28893510\",\"5\":\"-0.88636754\",\"6\":\"0.454296324\",\"7\":\"0.33374800\",\"8\":\"0.172291130\"},{\"1\":\"0.330695235\",\"2\":\"0.86251823\",\"3\":\"0.36755946\",\"4\":\"0.26582030\",\"5\":\"0.62532221\",\"6\":\"-0.006086796\",\"7\":\"0.40784927\",\"8\":\"-0.146473768\"},{\"1\":\"-0.970329438\",\"2\":\"0.04909661\",\"3\":\"-0.62624072\",\"4\":\"-0.86680531\",\"5\":\"0.50191897\",\"6\":\"-0.092408631\",\"7\":\"0.21594599\",\"8\":\"-0.377970937\"},{\"1\":\"0.387261525\",\"2\":\"-0.44078981\",\"3\":\"-0.01964031\",\"4\":\"-0.98237935\",\"5\":\"-0.97891997\",\"6\":\"0.914679445\",\"7\":\"0.77265549\",\"8\":\"-0.143163816\"},{\"1\":\"-0.121835086\",\"2\":\"-0.47389801\",\"3\":\"-0.11210873\",\"4\":\"-0.91303493\",\"5\":\"-0.30020212\",\"6\":\"0.540618159\",\"7\":\"0.38884894\",\"8\":\"0.161398803\"},{\"1\":\"-1.875390080\",\"2\":\"-0.26103034\",\"3\":\"-0.90044444\",\"4\":\"0.10401664\",\"5\":\"0.19341085\",\"6\":\"-0.984400927\",\"7\":\"-0.38256422\",\"8\":\"-0.332641014\"},{\"1\":\"-1.479426049\",\"2\":\"-0.23622603\",\"3\":\"-0.69027181\",\"4\":\"0.98237935\",\"5\":\"2.01360871\",\"6\":\"-1.243366432\",\"7\":\"-1.65558594\",\"8\":\"-0.287639739\"},{\"1\":\"-0.008702506\",\"2\":\"-0.68878471\",\"3\":\"-0.09176944\",\"4\":\"-1.00549416\",\"5\":\"-0.94806916\",\"6\":\"1.001001280\",\"7\":\"1.19446269\",\"8\":\"-0.436716733\"},{\"1\":\"0.217562654\",\"2\":\"-0.04492411\",\"3\":\"1.48264206\",\"4\":\"-0.12713145\",\"5\":\"0.99553195\",\"6\":\"0.339200544\",\"7\":\"-0.23056163\",\"8\":\"-0.684258957\"},{\"1\":\"1.009490716\",\"2\":\"0.07104732\",\"3\":\"1.53066538\",\"4\":\"-0.42762395\",\"5\":\"-0.88636754\",\"6\":\"0.483070269\",\"7\":\"0.26914690\",\"8\":\"-0.706994342\"},{\"1\":\"-0.404666537\",\"2\":\"0.49481552\",\"3\":\"-0.34883544\",\"4\":\"-0.79746089\",\"5\":\"0.19341085\",\"6\":\"0.454296324\",\"7\":\"0.86385705\",\"8\":\"-0.135370168\"},{\"1\":\"1.235755877\",\"2\":\"-0.10053191\",\"3\":\"0.78583314\",\"4\":\"-1.32910148\",\"5\":\"-0.91721835\",\"6\":\"1.202418895\",\"7\":\"1.30086450\",\"8\":\"0.135506051\"},{\"1\":\"-2.158221531\",\"2\":\"-0.46529283\",\"3\":\"-1.39913364\",\"4\":\"0.98237935\",\"5\":\"0.25511248\",\"6\":\"-1.502331938\",\"7\":\"-1.00387482\",\"8\":\"-0.248342852\"},{\"1\":\"-0.800630568\",\"2\":\"-0.03235933\",\"3\":\"-0.44055056\",\"4\":\"-0.98237935\",\"5\":\"1.55084655\",\"6\":\"0.166556874\",\"7\":\"-0.07855903\",\"8\":\"0.009692627\"},{\"1\":\"0.047863784\",\"2\":\"-0.72650508\",\"3\":\"-0.46635132\",\"4\":\"-0.68188685\",\"5\":\"-0.51615780\",\"6\":\"1.259966785\",\"7\":\"1.23816343\",\"8\":\"0.909459901\"},{\"1\":\"0.500394105\",\"2\":\"-0.60795805\",\"3\":\"-0.19195927\",\"4\":\"-1.02860897\",\"5\":\"-0.79381510\",\"6\":\"0.655713940\",\"7\":\"0.98355909\",\"8\":\"0.103357253\"},{\"1\":\"-0.121835086\",\"2\":\"-0.45104919\",\"3\":\"-0.50702990\",\"4\":\"1.00549416\",\"5\":\"0.56362059\",\"6\":\"-0.811757257\",\"7\":\"0.97405893\",\"8\":\"0.489847075\"},{\"1\":\"0.443827815\",\"2\":\"-0.68666214\",\"3\":\"1.17246793\",\"4\":\"-1.37533110\",\"5\":\"-1.04062159\",\"6\":\"1.202418895\",\"7\":\"1.86897419\",\"8\":\"-0.693719318\"},{\"1\":\"0.952924426\",\"2\":\"0.34353265\",\"3\":\"1.66155246\",\"4\":\"1.19041263\",\"5\":\"-0.51615780\",\"6\":\"0.166556874\",\"7\":\"-0.13556001\",\"8\":\"-0.711912322\"},{\"1\":\"-0.348100247\",\"2\":\"-0.58571469\",\"3\":\"-0.90063277\",\"4\":\"1.09795340\",\"5\":\"0.96468113\",\"6\":\"-1.041948817\",\"7\":\"0.09244388\",\"8\":\"0.625519932\"},{\"1\":\"1.462021037\",\"2\":\"1.79126968\",\"3\":\"0.87189846\",\"4\":\"2.39238266\",\"5\":\"-0.60871024\",\"6\":\"-0.725435422\",\"7\":\"0.13424460\",\"8\":\"-0.244704251\"},{\"1\":\"-0.404666537\",\"2\":\"0.56345798\",\"3\":\"-0.50684157\",\"4\":\"0.42762395\",\"5\":\"0.34766491\",\"6\":\"-0.495243862\",\"7\":\"-0.81577161\",\"8\":\"-0.227168543\"},{\"1\":\"0.670092975\",\"2\":\"-0.76850948\",\"3\":\"0.86737862\",\"4\":\"-1.25975705\",\"5\":\"-0.76296429\",\"6\":\"1.058549170\",\"7\":\"1.47566748\",\"8\":\"0.010819420\"},{\"1\":\"-1.026895728\",\"2\":\"0.72793573\",\"3\":\"-0.28781758\",\"4\":\"-0.61254242\",\"5\":\"-0.02254482\",\"6\":\"0.339200544\",\"7\":\"0.28434716\",\"8\":\"-0.318309622\"},{\"1\":\"-1.535992340\",\"2\":\"-0.33097039\",\"3\":\"-0.60947964\",\"4\":\"0.12713145\",\"5\":\"0.10085842\",\"6\":\"-0.322600191\",\"7\":\"-0.57256746\",\"8\":\"0.007122132\"},{\"1\":\"0.613526685\",\"2\":\"-0.29525879\",\"3\":\"-0.15429392\",\"4\":\"-0.35827953\",\"5\":\"-0.88636754\",\"6\":\"0.454296324\",\"7\":\"-0.47186574\",\"8\":\"0.327835443\"},{\"1\":\"-0.234967667\",\"2\":\"0.88034459\",\"3\":\"0.14213236\",\"4\":\"0.19647587\",\"5\":\"0.37851572\",\"6\":\"0.367974489\",\"7\":\"0.16274508\",\"8\":\"-0.272921013\"},{\"1\":\"0.670092975\",\"2\":\"-0.72779473\",\"3\":\"0.44533840\",\"4\":\"-0.75123127\",\"5\":\"-1.04062159\",\"6\":\"-0.380148081\",\"7\":\"0.14944486\",\"8\":\"-0.786855760\"},{\"1\":\"-0.970329438\",\"2\":\"-0.16776257\",\"3\":\"-0.72869046\",\"4\":\"0.68188685\",\"5\":\"0.87212870\",\"6\":\"-0.610339642\",\"7\":\"-1.22427858\",\"8\":\"-0.445566749\"},{\"1\":\"0.217562654\",\"2\":\"-0.75171997\",\"3\":\"-0.28367439\",\"4\":\"-1.09795340\",\"5\":\"-1.07147240\",\"6\":\"0.799583665\",\"7\":\"1.22866327\",\"8\":\"0.091854579\"},{\"1\":\"-1.535992340\",\"2\":\"0.06237449\",\"3\":\"-0.66729595\",\"4\":\"0.33516472\",\"5\":\"0.77957627\",\"6\":\"-0.610339642\",\"7\":\"-0.62386834\",\"8\":\"-0.315175731\"},{\"1\":\"0.217562654\",\"2\":\"3.09807936\",\"3\":\"-0.25241215\",\"4\":\"1.67582360\",\"5\":\"-0.08424645\",\"6\":\"-1.674975608\",\"7\":\"-1.34018056\",\"8\":\"2.275202817\"},{\"1\":\"0.670092975\",\"2\":\"-0.43382075\",\"3\":\"-0.67577065\",\"4\":\"-0.54319800\",\"5\":\"-0.91721835\",\"6\":\"0.914679445\",\"7\":\"0.30144745\",\"8\":\"0.165448214\"},{\"1\":\"0.556960395\",\"2\":\"-0.78741842\",\"3\":\"0.13422264\",\"4\":\"-1.19041263\",\"5\":\"-1.00977078\",\"6\":\"1.058549170\",\"7\":\"0.90945782\",\"8\":\"-0.690432840\"},{\"1\":\"0.443827815\",\"2\":\"0.29605646\",\"3\":\"1.05212714\",\"4\":\"0.05778702\",\"5\":\"-0.08424645\",\"6\":\"0.109008984\",\"7\":\"-0.58016759\",\"8\":\"-0.334213829\"},{\"1\":\"0.952924426\",\"2\":\"0.16997779\",\"3\":\"0.63573673\",\"4\":\"-0.45073876\",\"5\":\"-0.54700861\",\"6\":\"0.626939995\",\"7\":\"-0.37876415\",\"8\":\"-0.017491241\"},{\"1\":\"-2.214787821\",\"2\":\"-0.62744053\",\"3\":\"-1.08312138\",\"4\":\"0.38139434\",\"5\":\"-0.36190375\",\"6\":\"-0.782983312\",\"7\":\"0.08864382\",\"8\":\"-0.516272977\"},{\"1\":\"0.387261525\",\"2\":\"-0.07549739\",\"3\":\"-0.04751266\",\"4\":\"-1.02860897\",\"5\":\"-0.57785942\",\"6\":\"0.885905500\",\"7\":\"0.80115598\",\"8\":\"-0.161485931\"},{\"1\":\"0.160996364\",\"2\":\"-0.79361262\",\"3\":\"0.23215254\",\"4\":\"-0.65877204\",\"5\":\"-0.79381510\",\"6\":\"1.202418895\",\"7\":\"1.41296641\",\"8\":\"0.340770082\"},{\"1\":\"0.613526685\",\"2\":\"-0.43550029\",\"3\":\"-3.08559955\",\"4\":\"-0.86680531\",\"5\":\"4.69762929\",\"6\":\"-4.005665155\",\"7\":\"-2.01659210\",\"8\":\"-0.758803322\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nFrom our previous notes, there were a several candidate models that we may have been considering based on their AICc values. In this set of notes we will consider the best *k*-predictor models that had an AICc value within four of the minimum AICc value. These candidate models include:\n\n$$\n\\begin{split}\n\\mathbf{M1:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M2:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M3:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\epsilon_i \\\\[1ex]\n\\mathbf{M4:~} \\mathrm{Life~Expectancy}_i &= \\beta_1(\\mathrm{Income}_i) + \\beta_2(\\mathrm{Population}_i) + \\beta_3(\\mathrm{Illiteracy~Rate}_i) + \\beta_4(\\mathrm{Murder~Rate}_i) + \\epsilon_i\n\\end{split}\n$$\n\n<br />\n\n\n\n# Evaluating Predictors: Cross-Validation\n\nIn practice, we do not typically have two data sets at our disposal. Instead, we randomly split our sample data into two parts: a *training* set (used to fit the candidate models), and a *validation* set (used to evaluate the candidate models). Because we use a data set composed of different observations to evaluate the candidate models than we did to fit the candidate models, the resulting evaluation is not biased toward the data we used to fit the model (i.e., less overfit). Because of this, we get better indications about the generalizability of the models to out-of-sample data.\n\nThe essential algorithm for cross-validation is:\n\n- Randomly divide the data into two sets of observations; training and validation data sets.\n- Fit any candidate models using the training data.\n- Use the coefficients obtained from the training data to \"fit\" the exact same models to the validation data to obtain fitted values or residuals.\n- Use the fitted values/residuals to compute one or more measures of model performance for each candidate model.\n- Use measures of model performance to select a \"best\" candidate model.\n\n\n:::note\nThere are several metrics of model performance we can use to compare the candidate models. In cross-validation, the model performance metrics are simply compared to determine the \"best\" model; there are no significance tests performed.\n:::\n\n<br />\n\n\n## Cross-Validated Mean Square Error (CV-MSE)\n\nOne very common metric used is the residual variance (a.k.a., mean square error). Because this is computed on the validation data rather than on the data used to fit the model, we refer to it as the *Cross-Validated Mean Square Error* (CV-MSE). The CV-MSE is:\n\n$$\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n e_i^2\n$$\n\nwhere *n* is the number of observations in the validation set, and $e_i$ are the residuals computed on the validation set. This value summarizes the model-data misfit in the validation data. Note that because this is a residual-based measure, lower values of CV-MSE correspond to better fitting models. Because this metric is computed on the validation data (data not used to initially fit the model), it is a better measure of how the model might perform in  future samples.\n\n<br />\n\n\n# Cross-Validation Example\n\nTo select a \"best\" model from our candidate models for the `z_usa` data, we can use cross-validation based on the following:\n\n1. Randomly divide the `z_usa` data into two sets of observations; training and validation data sets.\n2. Fit the four candidate models to the training observations.\n3. Use the estimated coefficients from those fitted models to obtain the fitted values and residuals for the observations in the validation data. Using these residuals, compute the CV-MSE for each candidate model.\n4. Select the model with the lowest CV-MSE.\n\nNext, we will explore and carry out each of the steps in this algorithm to select a \"best\" model from our candidate models for the `z_usa` data.\n\n<br />\n\n\n## Divide the Sample Data into a Training and Validation Set\n\nThere are many ways to do this, but here we will use the `sample()` function to randomly sample 35 cases (rows) from the `z_usa` data (about 2/3 of the data). These 35 cases will make up the training data. Then we will use the `filter()` function to select those cases. The remaining cases (those 17 observations not sampled) are put into a validation set of data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Make the random sampling replicable\nset.seed(42)\n\n# Select the cases to be in the training set\ntraining_cases = sample(1:nrow(z_usa), size = 35, replace = FALSE)\n\n# Create training data from the sampled cases\ntrain = z_usa |>\n  filter(row_number() %in% training_cases)\n\n# Create validation data from the remaining cases\nvalidate = z_usa |>\n  filter(!row_number() %in% training_cases)\n```\n:::\n\n\n<br />\n\n\n## Fit the Candidate Models to the Training Data\n\nWe now fit the four candidate models to the observations in the training data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\nlm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\nlm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n```\n:::\n\n\n<br />\n\n\n## Use the Coefficients from the Fitted Models and the Validation Data to Obtain Fitted Values, Residuals, and CV-MSEs\n\nNow we can obtain the predicted life expectancy for the observations in the validation data based on the coefficients from the models fitted to the training data. These vectors of fitted values can be used to compute the residuals for the validation observations, which in turn can be used to compute the CV-MSE.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Get the predicted values for the validation data\nyhat_1 = predict(lm.1, newdata = validate)\nyhat_2 = predict(lm.2, newdata = validate)\nyhat_3 = predict(lm.3, newdata = validate)\nyhat_4 = predict(lm.4, newdata = validate)\n\n# Compute residuals and CV-MSE\nsum((validate$life_expectancy - yhat_1) ^ 2) / nrow(validate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7349516\n```\n:::\n\n```{.r .cell-code}\nsum((validate$life_expectancy - yhat_2) ^ 2) / nrow(validate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7483797\n```\n:::\n\n```{.r .cell-code}\nsum((validate$life_expectancy - yhat_3) ^ 2) / nrow(validate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8547222\n```\n:::\n\n```{.r .cell-code}\nsum((validate$life_expectancy - yhat_4) ^ 2) / nrow(validate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8968336\n```\n:::\n:::\n\n\n<br />\n\n\n## Select Candidate Model with the Lowest CV-MSE\n\nSince the CV-MSE is a measure of model misfit, the candidate model having the smallest CV-MSE is the model that should be adopted. In this case, the values for the CV-MSE suggest adopting the single predictor model.\n\n\n::: {.cell layout-align=\"center\" tbl-cap='CV-MSE for four potential models based on simple cross-validation.'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:center;\"> CV-MSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Predictor Model </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.735</span> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.748 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.855 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.897 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n<br />\n\n\n# Leave-One-Out Cross-Validation\n\nThere are two major problems with the cross-validation we just performed.\n\n1. The estimate of the CV-MSE is highly dependent on the observations chosen to be in the training and validation sets. This is illustrated in the figure below which shows the CV-MSE values for the four models for 10 different random splits of the data. Some of these splits support adopting the first candidate model, other splits support adopting the second candidate model, while others support adopting the third or even the fourth candidate models!\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Model that has the lowest CV-MSE for 10 random splits of the data.](14-cross-validation_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n2. Only a subset of the observations (those in the training set) are used to initially fit the model. Since statistical methods tend to perform worse when trained on fewer observations, this suggests that the CV-MSE may tend to overestimate the error rate (model accuracy measure) for the model fit.\n\nLeave-one-out cross-validation (LOOCV) is one method that can be used to overcome these issues. The algorithm for performing LOOCV is:\n\n1. Hold out the *i*th observation as your validation data (a single observation) and use the remaining $n-1$ observations as your training data.\n3. Fit all candidate models to the training data.\n4. Use the estimated coefficients from those fits to compute the $\\mathrm{CV\\mbox{-}MSE}_i$ using the validation data.\n5. Repeat Steps 2--4 for each observation.\n\nWe then have *n* estimates of the CV-MSE that can be averaged to get an overall estimate for the CV-MSE. That is,\n\n$$\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n \\widehat{\\mathrm{CV\\mbox{-}MSE}}_i\n$$\n\nwhere $\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i$ is the estimated CV-MSE based on the validation set composed of the *i*th observation. Since the validation dataset is composed of a single observation ($n=1$), $\\mathrm{CV\\mbox{-}MSE}_i$ is simply the squared residual value for the validation observation. That is,\n\n$$\n\\begin{split}\n\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i = \\frac{1}{n} \\sum_{i=1}^n e_i^2 \\\\[0.5em]\n= \\frac{1}{1} \\sum_{i=1}^1 e_i^2 \\\\[0.5em]\n= e_i^2\n\\end{split}\n$$\n<br />\n\n\n## Function to Carry Out LOOCV\n\nTo carry out LOOCV, we will write a function that computes $\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i$ for each model given a particular case.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Function to compute CV-MSE for LOOCV\ncv_mse_i = function(case_index){\n\n  # Create training and validation data sets\n  train = z_usa |> filter(row_number() != case_index)\n  validate = z_usa |> filter(row_number() == case_index)\n\n  # Fit models to training data\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  # Compute fitted value for validation data\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  # Compute CV-MSE_i for each model\n  cv_mse_1 = (validate$life_expectancy - yhat_1) ^ 2\n  cv_mse_2 = (validate$life_expectancy - yhat_2) ^ 2\n  cv_mse_3 = (validate$life_expectancy - yhat_3) ^ 2\n  cv_mse_4 = (validate$life_expectancy - yhat_4) ^ 2\n\n  # Output a data frame\n  return(data.frame(cv_mse_1, cv_mse_2, cv_mse_3, cv_mse_4))\n}\n\n# Test function on Case 1\ncv_mse_i(1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"cv_mse_1\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_2\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_3\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_4\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2.08481\",\"2\":\"1.988258\",\"3\":\"1.383972\",\"4\":\"1.297868\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThen we can use this function to compute the four $\\widehat{\\mathrm{CV\\mbox{-}MSE}}_i$ values for each case in the data. We set up a data frame that includes a column called `case` that has each case number in the data. Then we use `rowwise()` to operate on each row separately and `mutate()` a new column by applying our `cv_mse_i()` function using `map()`. This creates a *list column* where the contents of each cell in the column is actually a list; in our case a data frame of four columns. Finally, we use `unnest()` to take the contents of the list column and spread them out into separate columns.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Apply cv_mse_i() function to all cases\nmy_cv_mse = data.frame(case = 1:52) |>\n  rowwise() |>\n  mutate(\n    cv_mse = map(case, cv_mse_i) #New list column that includes the data frame of output\n  ) |>\n  unnest(cols = cv_mse) #Turn list column into multiple columns\n\n# View output\nmy_cv_mse\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"case\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_3\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_4\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"2.084810130\",\"3\":\"1.9882578052\",\"4\":\"1.38397159247\",\"5\":\"1.297868444\"},{\"1\":\"2\",\"2\":\"0.150900695\",\"3\":\"0.0504382607\",\"4\":\"0.06808356332\",\"5\":\"0.001132126\"},{\"1\":\"3\",\"2\":\"0.869823055\",\"3\":\"0.8164548577\",\"4\":\"0.95625620472\",\"5\":\"0.888907105\"},{\"1\":\"4\",\"2\":\"1.195324253\",\"3\":\"1.0186874078\",\"4\":\"0.62851608660\",\"5\":\"0.615671557\"},{\"1\":\"5\",\"2\":\"2.104167949\",\"3\":\"0.7731378792\",\"4\":\"0.65672991737\",\"5\":\"0.562273253\"},{\"1\":\"6\",\"2\":\"0.424822774\",\"3\":\"0.4556548806\",\"4\":\"0.31488696678\",\"5\":\"0.330855966\"},{\"1\":\"7\",\"2\":\"0.054396628\",\"3\":\"0.1139547839\",\"4\":\"0.03095797326\",\"5\":\"0.053704046\"},{\"1\":\"8\",\"2\":\"0.136114184\",\"3\":\"0.0471327866\",\"4\":\"0.02295382454\",\"5\":\"0.014313644\"},{\"1\":\"9\",\"2\":\"4.620693190\",\"3\":\"3.8271774336\",\"4\":\"1.79966596773\",\"5\":\"1.243909044\"},{\"1\":\"10\",\"2\":\"0.819598361\",\"3\":\"0.2747830705\",\"4\":\"0.53058692668\",\"5\":\"0.449958925\"},{\"1\":\"11\",\"2\":\"0.063610930\",\"3\":\"0.1431324490\",\"4\":\"0.01796598673\",\"5\":\"0.023773078\"},{\"1\":\"12\",\"2\":\"3.651121079\",\"3\":\"4.2873738068\",\"4\":\"7.06563041837\",\"5\":\"6.637385726\"},{\"1\":\"13\",\"2\":\"0.586328984\",\"3\":\"0.8017735100\",\"4\":\"0.85248821139\",\"5\":\"0.588938115\"},{\"1\":\"14\",\"2\":\"0.021979161\",\"3\":\"0.0006621793\",\"4\":\"0.01137821404\",\"5\":\"0.000203531\"},{\"1\":\"15\",\"2\":\"0.440796911\",\"3\":\"0.4609738026\",\"4\":\"0.97048474014\",\"5\":\"0.851149317\"},{\"1\":\"16\",\"2\":\"0.157636124\",\"3\":\"0.2388102856\",\"4\":\"0.07340001495\",\"5\":\"0.025503068\"},{\"1\":\"17\",\"2\":\"0.004367278\",\"3\":\"0.0008940476\",\"4\":\"0.02780230602\",\"5\":\"0.035731500\"},{\"1\":\"18\",\"2\":\"2.104080495\",\"3\":\"1.9737784524\",\"4\":\"1.76037050749\",\"5\":\"1.883848601\"},{\"1\":\"19\",\"2\":\"1.315103663\",\"3\":\"1.2198231846\",\"4\":\"0.61562126653\",\"5\":\"0.363610201\"},{\"1\":\"20\",\"2\":\"0.001365469\",\"3\":\"0.0318469475\",\"4\":\"0.00002658336\",\"5\":\"0.015415037\"},{\"1\":\"21\",\"2\":\"0.295245484\",\"3\":\"0.2724485207\",\"4\":\"0.30387575511\",\"5\":\"0.098113338\"},{\"1\":\"22\",\"2\":\"0.067621661\",\"3\":\"0.0661514859\",\"4\":\"0.01175376082\",\"5\":\"0.010492295\"},{\"1\":\"23\",\"2\":\"0.053684409\",\"3\":\"0.1137777915\",\"4\":\"0.50063709837\",\"5\":\"0.441152670\"},{\"1\":\"24\",\"2\":\"0.731394565\",\"3\":\"0.7786327592\",\"4\":\"0.26232581923\",\"5\":\"0.233020716\"},{\"1\":\"25\",\"2\":\"2.312288062\",\"3\":\"2.0681011073\",\"4\":\"1.18355079704\",\"5\":\"1.494711605\"},{\"1\":\"26\",\"2\":\"0.340717217\",\"3\":\"0.3369679204\",\"4\":\"0.82272061925\",\"5\":\"0.511709416\"},{\"1\":\"27\",\"2\":\"0.078982528\",\"3\":\"0.1853934774\",\"4\":\"0.12592904537\",\"5\":\"0.070473551\"},{\"1\":\"28\",\"2\":\"0.355586578\",\"3\":\"0.5243297828\",\"4\":\"0.27589404911\",\"5\":\"0.186196208\"},{\"1\":\"29\",\"2\":\"0.017170473\",\"3\":\"0.0485869584\",\"4\":\"0.42576310091\",\"5\":\"0.427020619\"},{\"1\":\"30\",\"2\":\"0.020520988\",\"3\":\"0.0001025051\",\"4\":\"0.09263816580\",\"5\":\"0.110342824\"},{\"1\":\"31\",\"2\":\"0.017864305\",\"3\":\"0.0053573313\",\"4\":\"0.16974254772\",\"5\":\"0.166759880\"},{\"1\":\"32\",\"2\":\"0.010305090\",\"3\":\"0.0471891476\",\"4\":\"0.52415292089\",\"5\":\"0.568641710\"},{\"1\":\"33\",\"2\":\"1.089674193\",\"3\":\"0.5246094696\",\"4\":\"1.52234607008\",\"5\":\"1.290278187\"},{\"1\":\"34\",\"2\":\"0.023507570\",\"3\":\"0.0754245080\",\"4\":\"0.06205846125\",\"5\":\"0.058808605\"},{\"1\":\"35\",\"2\":\"0.058664640\",\"3\":\"0.1709265238\",\"4\":\"0.02764842801\",\"5\":\"0.023645226\"},{\"1\":\"36\",\"2\":\"0.783517185\",\"3\":\"1.0970483164\",\"4\":\"2.04240195223\",\"5\":\"2.009021642\"},{\"1\":\"37\",\"2\":\"1.542230121\",\"3\":\"1.3942402382\",\"4\":\"1.17285295596\",\"5\":\"1.260166499\"},{\"1\":\"38\",\"2\":\"0.476927151\",\"3\":\"0.5638814131\",\"4\":\"0.48420273672\",\"5\":\"0.333601498\"},{\"1\":\"39\",\"2\":\"0.093507136\",\"3\":\"0.2418581348\",\"4\":\"0.36029481891\",\"5\":\"0.283606966\"},{\"1\":\"40\",\"2\":\"0.202788554\",\"3\":\"0.3714969092\",\"4\":\"0.26517094334\",\"5\":\"0.173914678\"},{\"1\":\"41\",\"2\":\"0.377307930\",\"3\":\"0.3428810915\",\"4\":\"0.12133085975\",\"5\":\"0.090081958\"},{\"1\":\"42\",\"2\":\"0.129051208\",\"3\":\"0.2665149564\",\"4\":\"0.10169935874\",\"5\":\"0.031256355\"},{\"1\":\"43\",\"2\":\"1.475413905\",\"3\":\"1.5199811202\",\"4\":\"1.30980660008\",\"5\":\"1.194006279\"},{\"1\":\"44\",\"2\":\"0.118025660\",\"3\":\"0.1293180086\",\"4\":\"0.19420417045\",\"5\":\"0.259549507\"},{\"1\":\"45\",\"2\":\"1.030898121\",\"3\":\"1.2167060596\",\"4\":\"1.03356728873\",\"5\":\"0.773625753\"},{\"1\":\"46\",\"2\":\"0.240460343\",\"3\":\"0.4359579214\",\"4\":\"0.19754161957\",\"5\":\"0.118479312\"},{\"1\":\"47\",\"2\":\"0.006608695\",\"3\":\"0.0182090537\",\"4\":\"0.02943297562\",\"5\":\"0.011719787\"},{\"1\":\"48\",\"2\":\"0.411878072\",\"3\":\"0.3745549241\",\"4\":\"0.19759026983\",\"5\":\"0.183782332\"},{\"1\":\"49\",\"2\":\"2.942851946\",\"3\":\"2.5730144801\",\"4\":\"1.92728474270\",\"5\":\"2.549537528\"},{\"1\":\"50\",\"2\":\"0.168850174\",\"3\":\"0.1814750830\",\"4\":\"0.01570768989\",\"5\":\"0.005815210\"},{\"1\":\"51\",\"2\":\"0.002076207\",\"3\":\"0.0450043229\",\"4\":\"0.02479800135\",\"5\":\"0.005186411\"},{\"1\":\"52\",\"2\":\"6.977634377\",\"3\":\"7.4434988067\",\"4\":\"6.39227540838\",\"5\":\"27.589014985\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n<br />\n\n\n## Alternative Programming: Use a for() Loop\n\nAlternatively, we could also have used a `for()` loop to carry out the LOOCV. Here is some example syntax (not run):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set up empty vector to store results\nmse_1 = rep(NA, 52)\nmse_2 = rep(NA, 52)\nmse_3 = rep(NA, 52)\nmse_4 = rep(NA, 52)\nmse_5 = rep(NA, 52)\n\n# Loop through the cross-validation\nfor(i in 1:nrow(z_usa)){\n  train = z_usa |> filter(row_number() != i)\n  validate = z_usa |> filter(row_number() == i)\n\n  lm.1 = lm(life_expectancy ~ -1 + income,                                    data = train)\n  lm.2 = lm(life_expectancy ~ -1 + income + population,                       data = train)\n  lm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = train)\n  lm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = train)\n\n  yhat_1 = predict(lm.1, newdata = validate)\n  yhat_2 = predict(lm.2, newdata = validate)\n  yhat_3 = predict(lm.3, newdata = validate)\n  yhat_4 = predict(lm.4, newdata = validate)\n\n  mse_1[i] = (validate$life_expectancy - yhat_1) ^ 2\n  mse_2[i] = (validate$life_expectancy - yhat_2) ^ 2\n  mse_3[i] = (validate$life_expectancy - yhat_3) ^ 2\n  mse_4[i] = (validate$life_expectancy - yhat_4) ^ 2\n\n} \n\n# Create data frame of results\nmy_cv_mse = data.frame(\n  case = 1:52,\n  cv_mse_1 = mse_1, \n  cv_mse_2 = mse_2,\n  cv_mse_3 = mse_3,\n  cv_mse_4 = mse_4\n  )\n```\n:::\n\n\n<br />\n\n\n## Select Model with Lowest CV-MSE\n\nWe can now compute the average CV-MSE for each of the candidate models and select the candidate model with the lowest average CV-MSE.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Compute average CV-MSE\nmy_cv_mse |>\n  select(-case) |>\n  summarize_all(mean)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"cv_mse_1\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_2\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_3\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse_4\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.8319288\",\"2\":\"0.8068921\",\"3\":\"0.7686342\",\"4\":\"1.123998\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nThe LOOCV results suggest that we adopt the three-predictor model; it has the smallest average CV-MSE. Since LOOCV method is less biased than simple cross-validation (it trains the models on a much larger set of observations) its results are more believable than those from the simple cross-validation. Another advantage of LOOCV is that it will always produce the same results as opposed to simple cross-validation) since there is no randomness in producing the training and validation datasets.\n\n\n::: {.cell layout-align=\"center\" tbl-cap='CV-MSE for four potential models based on simple cross-validation and Leave-One-Out Cross-Validation (LOOCV).'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;\" colspan=\"1\"></th>\n<th style=\"padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #111111; margin-bottom: -1px; \">CV-MSE</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:center;\"> Simple CV </th>\n   <th style=\"text-align:center;\"> LOOCV </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Predictor Model </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.735</span> </td>\n   <td style=\"text-align:center;\"> 0.832 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.748 </td>\n   <td style=\"text-align:center;\"> 0.807 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.855 </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.769</span> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.897 </td>\n   <td style=\"text-align:center;\"> 1.124 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n<br />\n\n\n### Computing the CV-MSE under LOOCV: A Shortcut for OLS Models\n\nLOOCV can be computationally expensive when you sample is very large; we have to fit the candidate models *n* times. It turns out, however, that models fit with OLS, can give us the LOOCV results using the following formula:\n\n$$\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{n} \\sum_{i=1}^n \\bigg(\\frac{e_i}{1-h_{ii}}\\bigg)^2\n$$\n\nwhere $\\hat{y}_i$ is the *i*th fitted value from the original least squares fit, and $h_{ii}$ is the leverage value. This is similar to the model (biased) MSE, except the *i*th residual is divided by $1 − h_{ii}$. Below, we compute the LOOCV CV-MSE for the three-predictor candidate model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Compute CV-MSE for Candidate Model 3\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy, data = z_usa)\n\n# Augment the model to get e_i and h_ii\nout.3 = augment(lm.3)\n\n# Compute CV-MSE for best three-predictor model\n1 / 52 * sum((out.3$.resid / (1 - out.3$.hat))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7686342\n```\n:::\n:::\n\n\n<br />\n\n\n# k-Fold Cross-Validation\n\nLOOCV is a very general method, and can be used with any kind of modeling. For example we could use it with logistic regression, or mixed-effects analysis, or any of the methods you have encountered in your statistics courses to date.  That being said, the shortcut formula does not hold for all these methods, so, outside of OLS regression, the candidate models will actually need to be fitted *n* times. This can, as pointed out earlier, be quite computationally expensive.\n\nOne alternative to LOOCV is *k*-fold cross-validation. The algorithm for *k*-fold cross-validation is:\n\n1. Randomly divide the data into *k* groups or folds.\n2. Hold out the *i*th fold as your validation data and use the remaining $k-1$ folds as your training data.\n3. Fit all candidate models to the training data.\n4. Use the estimated coefficients from those fits to compute $\\mathrm{CV\\mbox{-}MSE}_i$ using the validation data.\n5. Repeat Steps 2--4 for each fold.\n\nWe then have *k* estimates of the MSE that can be averaged to get the overall CV-MSE.\n\n$$\n\\mathrm{CV\\mbox{-}MSE} = \\frac{1}{k} \\sum_{j=1}^k \\widehat{\\mathrm{CV\\mbox{-}MSE}}_j\n$$\n\nwhere $\\widehat{\\mathrm{CV\\mbox{-}MSE}}_j$ is the estimated CV-MSE based on the *j*th validation set. From this algorithm, it is clear that LOOCV is a special case of *k*-fold cross-validation in which *k* is set to equal *n*. In practice we typically use $k=5$ or $k=10$.\n\n\nWe can carry out *k*-fold cross-validation by using the `crossv_kfold()` function from the `{modelr}` package. This function takes the argument `k=` to indicate the number of folds. Here is some example syntax to carry out a 10-fold cross-validation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set seed for reproducible results\nset.seed(100)\n\n# Divide data into 10 folds\nmy_cv = z_usa |>\n  crossv_kfold(k = 10)\n\n# View output\nmy_cv\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"train\"],\"name\":[1],\"type\":[\"named list\"],\"align\":[\"right\"]},{\"label\":[\"test\"],\"name\":[2],\"type\":[\"named list\"],\"align\":[\"right\"]},{\"label\":[\".id\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"01\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"02\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"03\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"04\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"05\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"06\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"07\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"08\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"09\"},{\"1\":\"<S3: resample>\",\"2\":\"<S3: resample>\",\"3\":\"10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe output of `cross_kfold()` is a tibble/data frame with three columns: `train`, `test`, and `.id`. The first two columns are named lists of `resample` objects. These contain references to the row numbers used in the training and test data sets.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# View rows used in first fold (train set)\nmy_cv$train[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<resample [46 x 8]> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\n```\n:::\n:::\n\n\n\n\n\nThen we will use the `map()` and `map2_dbl()` functions from the `{purrr}` package to fit a model to the training (`train`) data and find the MSE on the validation (`test`) data created from the `crossv_kfold()` function. We will have to carry this out for each of the candidate models.\n\n:::fyi\nFor more detailed information about using the purrr functions, see Jenny Bryan's fantastic [purrr tutorial](https://jennybc.github.io/purrr-tutorial/index.html).\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Best 1-predictor model\ncv_1 = my_cv |>\n  mutate(\n    model = map(train, ~lm(life_expectancy ~ 1 + income, data = .)),\n    MSE = map2_dbl(model, test, modelr::mse),\n    k = 1\n    )\n\n# Best 2-predictor model\ncv_2 = my_cv |>\n  mutate(\n    model = map(train, ~lm(life_expectancy ~ 1 + income + population, data = .)),\n    MSE = map2_dbl(model, test, modelr::mse),\n    k = 2\n    )\n\n# Best 3-predictor model\ncv_3 = my_cv |>\n  mutate(\n    model = map(train, ~lm(life_expectancy ~ 1 + income + population + illiteracy, data = .)),\n    MSE = map2_dbl(model, test, modelr::mse),\n    k = 3\n    )\n\n# Best 4-predictor model\ncv_4 = my_cv |>\n mutate(\n    model = map(train, ~lm(life_expectancy ~ 1 + income + population + illiteracy + murder, data = .)),\n    MSE = map2_dbl(model, test, modelr::mse),\n    k = 4\n    )\n```\n:::\n\n\nOnce we have the results, we can stack these into  single data frame and then use `group_by()` and `summarize()` to obtain the CV-MSE estimates.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrbind(cv_1, cv_2, cv_3, cv_4) |>\n  group_by(k) |>\n  summarize(\n    cv_mse = mean(MSE)\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"k\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cv_mse\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0.8847779\"},{\"1\":\"2\",\"2\":\"0.8588566\"},{\"1\":\"3\",\"2\":\"0.8304027\"},{\"1\":\"4\",\"2\":\"1.2214235\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nThe results of carrying out the 10-fold cross-validation suggest that we adopt the best two- or three-predictor model.\n\n\n\n::: {.cell layout-align=\"center\" tbl-cap='CV-MSE for four potential models based on simple cross-validation, Leave-One-Out Cross-Validation (LOOCV), and 10-fold cross-validation.'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;\" colspan=\"1\"></th>\n<th style=\"padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #111111; margin-bottom: -1px; \">CV-MSE</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:center;\"> Simple CV </th>\n   <th style=\"text-align:center;\"> LOOCV </th>\n   <th style=\"text-align:center;\"> 10-Fold CV </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Predictor Model </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.735</span> </td>\n   <td style=\"text-align:center;\"> 0.832 </td>\n   <td style=\"text-align:center;\"> 0.885 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.748 </td>\n   <td style=\"text-align:center;\"> 0.807 </td>\n   <td style=\"text-align:center;\"> 0.859 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.855 </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.769</span> </td>\n   <td style=\"text-align:center;\"> <span style=\" font-weight: bold;    border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #eeff41 !important;\">0.831</span> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Predictor Model </td>\n   <td style=\"text-align:center;\"> 0.897 </td>\n   <td style=\"text-align:center;\"> 1.124 </td>\n   <td style=\"text-align:center;\"> 1.22 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nUsing *k*-fold cross-validation is computationally less expensive so long as $k<n$. But this computational gain has a cost in that the results are again dependent on the *k* random splits. This variation, however, is less than that in the single split simple cross-validation. We can also alleviate some of this by fitting the *k*-fold cross-validation several times and averaging across the results to get the CV-MSE estimate.\n\n:::fyi\nThere are several other R packages that will also fit a *k*-fold cross-validation (e.g., `{DAAG}`).\n:::\n\n<br />\n\n\n<br />\n\n# Model Selection\n\nThe different model selection methods suggest we adopt the following candidate models:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table style='width:60%; font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;' class=\" lightable-classic\">\n<caption>Predictors selected from forward selection (FS), backward elimination (BE) and cross-validation (CV) methods. The CV-MSE was used as a performance metric for model selection in all cross-validation methods.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;text-align: center;\"> Method </th>\n   <th style=\"text-align:left;text-align: center;\"> Model </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> FS (t-value) </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy, Murder </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FS (AIC) </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BE (R2) </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> All Subsets (AICc) </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Simple CV </td>\n   <td style=\"text-align:left;\"> Income </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Leave-One-Out CV </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10-Fold CV </td>\n   <td style=\"text-align:left;\"> Income, Population, Illiteracy </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::fyi\nWhile the different CV methods can suggest different models, this is usually less problematic when the sample size is larger; we only have 52 observations in the `z_usa` data.\n:::\n\nThe LOOCV and *k*-fold CV are better suited for considering how the model will perform on future data sets, so, here, I would adopt the model that includes income, population, and illiteracy rate. To get the coefficient estimates, we fit whichever model we adopt to the FULL data set (with all the observations) as this will give us the \"best\" estimates.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit model\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy, data = z_usa)\n\n# Get model-level output\nglance(lm.3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"r.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"adj.r.squared\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sigma\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"logLik\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df.residual\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[12],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.3494565\",\"2\":\"0.3096273\",\"3\":\"0.8228586\",\"4\":\"8.773877\",\"5\":\"0.00009239393\",\"6\":\"3\",\"7\":\"-62.10131\",\"8\":\"132.2026\",\"9\":\"140.0076\",\"10\":\"33.17772\",\"11\":\"49\",\"12\":\"52\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Get coefficient-level output\ntidy(lm.3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"income\",\"2\":\"0.4876851\",\"3\":\"0.1153093\",\"4\":\"4.229363\",\"5\":\"0.0001020906\"},{\"1\":\"population\",\"2\":\"0.3923549\",\"3\":\"0.1452027\",\"4\":\"2.702119\",\"5\":\"0.0094390550\"},{\"1\":\"illiteracy\",\"2\":\"-0.3096511\",\"3\":\"0.1451187\",\"4\":\"-2.133778\",\"5\":\"0.0378919617\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n<br />\n\n\n# Reporting Results from a Cross-Validation\n\nWhen we report the results of a regression model evaluated using cross-validation, there are some subtle differences in what is reported. At the model-level, we report the $R^2$ from the adopted model fitted to the full-data. We also report the CV-MSE as a measure of the model error for future observations (generalized error).\n\nAt the coefficient-level we typically report the coefficient estimates and standard errors based on fitting the adopted model to the full data. However, we DO NOT REPORT NOR INTERPRET P-VALUES. The *p*-values do not take into account that the model was selected using cross-validation. Because of this they are incredibly misleading. As with any model, interpretations should also be offered, again typically by way of providing a plot of the fitted model to help facilitate these interpretations. For example:\n\n:::interpret\nThe regression model using income, population, and illiteracy rate to predict variation in life expectancy was selected using 10-fold cross-validation (CV-MSE = 0.830). The model explains 34.9% of the variation in life expectancy. The fitted equation is:\n\n$$\n\\begin{split}\n\\hat{\\mathrm{Life~Expectancy}}_i = &0.488(\\mathrm{Income}_i) + 0.392(\\mathrm{Population}_i) \\\\\n&- 0.310(\\mathrm{Illiteracy~Rate}_i)\n\\end{split}\n$$\n\nwhere, the outcome and all predictors are standardized. This model suggests moderate, positive, partial effects of both income and population and a moderate negative effect of illiteracy rate on life expectancy.\n:::\n\n<br />\n\n\n# Relationship between Information Criteria and Cross-Validation\n\nIn EPsy 8252, we learned about using [information criteria for model selection](https://zief0002.github.io/epsy-8252/misc/s21-12-information-criteria-and-model-selection.html). In particular, we used AIC, BIC, and AICc for model selection. It turns out the AIC-based model selection and cross-validation are asymptotically equivalent [@Stone:1977]. @Shao:1997 also proved that for linear models, using BIC for model selection is asymptotically equivalent to leave-*v*-out cross-validation when\n\n$$\nv = n\\bigg(1 - \\frac{1}{\\ln (n) - 1}\\bigg)\n$$\n\nAs a practical note, computer simulations have suggested that the results from using AICc for model selection will, on average, be quite similar to those from cross-validation techniques. As such, AICc can be a useful alternative to the computationally expensive cross-validation methods. However, using AICc does not provide a measure of the model performance (MSE) in new datasets like cross-validation does.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit models to all data\nlm.1 = lm(life_expectancy ~ -1 + income,                                    data = z_usa)\nlm.2 = lm(life_expectancy ~ -1 + income + population,                       data = z_usa)\nlm.3 = lm(life_expectancy ~ -1 + income + population + illiteracy,          data = z_usa)\nlm.4 = lm(life_expectancy ~ -1 + income + population + illiteracy + murder, data = z_usa)\n\n\n# Load library\nlibrary(AICcmodavg)\n\n# Get AICc for all models\naictab(\n  cand.set = list(lm.1, lm.2, lm.3, lm.4),\n  modnames = c(\"Best 1-Predictor\", \"Best 2-Predictor\", \"Best 3-Predictor\", \"Best 4-Predictor\")\n)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Modnames\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"K\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AICc\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Delta_AICc\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ModelLik\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AICcWt\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"LL\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Cum.Wt\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Best 3-Predictor\",\"2\":\"4\",\"3\":\"133.0537\",\"4\":\"0.000000\",\"5\":\"1.0000000\",\"6\":\"0.4766122\",\"7\":\"-62.10131\",\"8\":\"0.4766122\",\"_rn_\":\"3\"},{\"1\":\"Best 4-Predictor\",\"2\":\"5\",\"3\":\"134.2494\",\"4\":\"1.195668\",\"5\":\"0.5500017\",\"6\":\"0.2621376\",\"7\":\"-61.47250\",\"8\":\"0.7387498\",\"_rn_\":\"4\"},{\"1\":\"Best 2-Predictor\",\"2\":\"3\",\"3\":\"135.3229\",\"4\":\"2.269225\",\"5\":\"0.3215468\",\"6\":\"0.1532531\",\"7\":\"-64.41145\",\"8\":\"0.8920029\",\"_rn_\":\"2\"},{\"1\":\"Best 1-Predictor\",\"2\":\"2\",\"3\":\"136.0229\",\"4\":\"2.969198\",\"5\":\"0.2265932\",\"6\":\"0.1079971\",\"7\":\"-65.88899\",\"8\":\"1.0000000\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe model with the lowest AICc is, indeed, the three-predictor model. There is also some evidence for the four-predictor model given the AICc weight.\n\n<br />\n\n",
    "supporting": [
      "14-cross-validation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint/kePrint.js\"></script>\n<link href=\"../site_libs/lightable/lightable.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/pagedtable/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}