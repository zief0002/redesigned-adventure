{
  "hash": "ecbca93d70015662e5a3edcbfd65853c",
  "result": {
    "markdown": "---\ntitle: \"üìù Principal Components Analysis via Singular Value Decomposition\"\nformat:\n  html:\n    code-copy: true\n    code-fold: false\n    highlight-style: zenburn\n    df-print: paged\n    css: [\"../assets/style.css\", \"../assets/notes.css\", \"../assets/table-styles.css\"]\ndate: 08-05-2023\nbibliography: '../assets/epsy8264.bib'\ncsl: '../assets/apa-single-spaced.csl'\n---\n\n::: {.cell}\n\n:::\n\n\n---\n\nIn this set of notes, we will give a brief introduction to principal components analysis via singular value decomposition. We will continue to use the *equal-education-opportunity.csv* data provided from @Chatterjee:2012 to evaluate the availability of equal educational opportunity in public education. The goal of the regression analysis is to examine whether the level of school facilities was an important predictor of student achievement after accounting for the variation in faculty credentials and peer influence.\n\n- [[CSV]](https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv)\n- [[Codebook]](../codebooks/equal-education-opportunity.html)\n  \nA script file for the analyses in these notes is also available:\n\n- [[R Script File]](https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/scripts/06-03-pca-via-svd.R)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(broom)\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\n\n# Read in data\neeo = read_csv(\"https://raw.githubusercontent.com/zief0002/redesigned-adventure/main/data/equal-education-opportunity.csv\")\nhead(eeo)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"achievement\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"faculty\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"peer\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"school\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.43148\",\"2\":\"0.60814\",\"3\":\"0.03509\",\"4\":\"0.16607\"},{\"1\":\"0.79969\",\"2\":\"0.79369\",\"3\":\"0.47924\",\"4\":\"0.53356\"},{\"1\":\"-0.92467\",\"2\":\"-0.82630\",\"3\":\"-0.61951\",\"4\":\"-0.78635\"},{\"1\":\"-2.19081\",\"2\":\"-1.25310\",\"3\":\"-1.21675\",\"4\":\"-1.04076\"},{\"1\":\"-2.84818\",\"2\":\"0.17399\",\"3\":\"-0.18517\",\"4\":\"0.14229\"},{\"1\":\"-0.66233\",\"2\":\"0.20246\",\"3\":\"0.12764\",\"4\":\"0.27311\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Source the residual_plots() function from the script file\nsource(\"../scripts/residual_plots.R\")\n```\n:::\n\n\n<br />\n\n\n# Singular Value Decomposition\n\nAnother decomposition method that creates orthogonal unit vectors (i.e., basis) is [singular value decomposition (SVD)](https://zief0002.github.io/matrix-algebra/singular-value-decompostion.html). This decomposition method decomposes a matrix **A** into the product of three matrices, namely:\n\n$$\n\\mathbf{A} = \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\n$$\n\nwhere, **U** and **V** are an orthogonal matrices and **D** is a diagonal matrix. \n\n\n## PCA using SVD: Matrix Algebra\n\nTo carry out a principal components analysis, we need to use SVD to decompose the matrix $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$, where $\\mathbf{X}_{\\mathrm{Predictor}}$ is a matrix of the predictors being used in the PCA. Below, we create the $\\mathbf{X}_{\\mathrm{Predictor}}$ matrix we use the `svd()` function to decompose the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix using singular value decomposition.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create matrix of predictors\nX_p = as.matrix(eeo[ , c(\"faculty\", \"peer\", \"school\")])\n\n# SVD decomposition\nsv_decomp = svd(t(X_p) %*% X_p)\n\n# View results\nsv_decomp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$d\n[1] 209.3295610   2.7303093   0.5833274\n\n$u\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n\n$v\n           [,1]       [,2]       [,3]\n[1,] -0.6174223  0.6698093 -0.4124865\n[2,] -0.5243779 -0.7413256 -0.4188844\n[3,] -0.5863595 -0.0423298  0.8089442\n```\n:::\n:::\n\n\n$$\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[1em]\n\\begin{bmatrix}81.123 & 66.518 & 75.512 \\\\ 66.518 & 59.163 & 64.251 \\\\ 75.512 & 64.251 & 72.358\\end{bmatrix} &= \\begin{bmatrix}0.617 & 0.670 & -0.412 \\\\ -0.524 & -0.741 & -0.419 \\\\ -0.586 & -0.042 & 0.809\\end{bmatrix} \\begin{bmatrix}209.330 & 0 & 0 \\\\ 0 & 2.730 & 0 \\\\ 0 & 0 & 0.583 \\end{bmatrix} \\begin{bmatrix}-0.617 & -0.524 & -0.586 \\\\ 0.670 & -0.741 & -0.042 \\\\ -0.412 & -0.419 &  0.809 \\end{bmatrix}\n\\end{split}\n$$\n\n<br />\n\n\n## Understanding What the Matrix Algebra is Doing\n\nMathematically, since any matrix can be decomposed using SVD, we can also decompose $\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}$. Then we can write the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix, $\\mathbf{X}^{\\intercal}\\mathbf{X}$, as:\n\n$$\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})^{\\intercal} (\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal})\n$$\n\nRe-expressing this we get:\n\n$$\n\\begin{split}\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} &= \\mathbf{V}\\mathbf{D}^{\\intercal}\\mathbf{U}^{\\intercal}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal} \\\\[0.5em]\n\\end{split}\n$$\n\nSince **D** is a diagonal matrix, $\\mathbf{D}^{\\intercal}\\mathbf{D} = \\mathbf{D}^2$, so reducing this expression gives:\n\n$$\n\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}} = \\mathbf{V}\\mathbf{D}^2\\mathbf{V}^{\\intercal}\n$$\n\nThe matrices **V** and $\\mathbf{V}^{\\intercal}$ are both orthogonal basis matrices that ultimately act to change the coordinate system by rotating the original basis vectors used in the predictor space. The $\\mathbf{D}^2$ matrix is diagonalizing the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix which amounts to finding the the major axes in the data ellipse along which our data varies.\n\n<br />\n\n\n# Using the SVD Decomposition as PCA\n\nAs was pointed out in the previous section, the important matrices from the SVD are the **V** matrix (rotation matrix) and the **D** matrix (diagonalization matrix). The **V** matrix are the principal components:\n\n$$\n\\mathbf{V} = \\begin{bmatrix}-0.617 & 0.670 & -0.412 \\\\ -0.524 &  -0.741 & -0.419 \\\\ -0.586 & -0.042  & 0.809 \\end{bmatrix}\n$$\n\nNote these are the same principal components we obtained using the eigendecomposition. The values in the **D** matrix are mathematically related to the eigenvalues. Because we based the SVD on the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix, the diagonal elements on **D** are the eigenvalues! That is, \n\n$$\n\\lambda_i = d_{ii}\n$$\n\nThe eigenvalues (which are the variances) can then be used to compute the proportion of variance for each of the principal components.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Compute proportion of variance\nsv_decomp$d / sum(sv_decomp$d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.984416916 0.012839862 0.002743222\n```\n:::\n:::\n\n\nThe principal component scores can be obtained by postmultiplying the mean centered predictor matrix by the **V** matrix.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Mean center each predictor\nX_p[, 1] = X_p[, 1] - mean(X_p[, 1])\nX_p[, 2] = X_p[, 2] - mean(X_p[, 2])\nX_p[, 3] = X_p[, 3] - mean(X_p[, 3])\n\n# Compute PC scores\npc_scores = X_p %*% sv_decomp$v\nhead(pc_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]        [,2]        [,3]\n[1,] -0.41777127  0.37690208 -0.11724716\n[2,] -0.98071768  0.15636966 -0.08255266\n[3,]  1.36960233 -0.05831171 -0.02181284\n[4,]  2.09547335  0.10933210  0.19860746\n[5,] -0.02027426  0.25039535  0.13486066\n[6,] -0.27859048  0.03203317  0.09791201\n```\n:::\n:::\n\n\n<br />\n\n\n# Using the prcomp() Function to Carry out PCA using SVD\n\nIn practice, we will use R functions (not the matrix algebra) to carry out a PCA using SVD. The `prcomp()` function carries out PCA using SVD decomposition. Different elements of the The `prcomp()` object can then be accessed to obtain output from the PCA.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit the PCA using SVD decomposition\nsvd_pca = eeo |>\n  select(faculty, peer, school) |>\n  scale(center = TRUE, scale = FALSE) |> # center data\n  prcomp()\n\n# View standard deviations and rotation matrix (eigenvector matrix)\nsvd_pca \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStandard deviations (1, .., p=3):\n[1] 1.7401965 0.1989041 0.0908621\n\nRotation (n x k) = (3 x 3):\n               PC1         PC2        PC3\nfaculty -0.6173237  0.67025631 -0.4119077\npeer    -0.5241853 -0.74086406 -0.4199407\nschool  -0.5866355 -0.04332342  0.8086915\n```\n:::\n:::\n\n\nAgain, to compute the variances we can square the standard deviations output by the function and then use those variances to compute the variance accounted for by the principal components.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Compute variances\nvar_pc = svd_pca[[1]] ^ 2\nvar_pc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.028283805 0.039562836 0.008255921\n```\n:::\n\n```{.r .cell-code}\n# Compute variance accounted for\nvar_pc / sum(var_pc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.98445476 0.01286135 0.00268389\n```\n:::\n:::\n\n\nWe can also obtain the scores on each principal component for each observation in the sample using the `augment()` function from the `{broom}` package.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Obtain PC scores\naugment(svd_pca)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".rownames\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".fittedPC1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC3\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"-0.41775535\",\"3\":\"0.377013352\",\"4\":\"-0.1169457640\"},{\"1\":\"2\",\"2\":\"-0.98069934\",\"3\":\"0.156403711\",\"4\":\"-0.0827058802\"},{\"1\":\"3\",\"2\":\"1.36961355\",\"3\":\"-0.058197398\",\"4\":\"-0.0214096538\"},{\"1\":\"4\",\"2\":\"2.09539768\",\"3\":\"0.109232775\",\"4\":\"0.1994587407\"},{\"1\":\"5\",\"2\":\"-0.02033702\",\"3\":\"0.250234525\",\"4\":\"0.1351494085\"},{\"1\":\"6\",\"2\":\"-0.27862628\",\"3\":\"0.031899464\",\"4\":\"0.0978537560\"},{\"1\":\"7\",\"2\":\"-0.05765964\",\"3\":\"0.229378988\",\"4\":\"-0.0075729005\"},{\"1\":\"8\",\"2\":\"-0.71167315\",\"3\":\"0.217255930\",\"4\":\"0.0974081114\"},{\"1\":\"9\",\"2\":\"1.08107464\",\"3\":\"-0.019823990\",\"4\":\"-0.0380349105\"},{\"1\":\"10\",\"2\":\"-1.41400396\",\"3\":\"0.167294666\",\"4\":\"0.0983272711\"},{\"1\":\"11\",\"2\":\"-1.89400304\",\"3\":\"0.022075255\",\"4\":\"0.0392863309\"},{\"1\":\"12\",\"2\":\"-0.90101150\",\"3\":\"-0.272005138\",\"4\":\"0.0216696271\"},{\"1\":\"13\",\"2\":\"-1.25637710\",\"3\":\"-0.017431356\",\"4\":\"-0.0595493220\"},{\"1\":\"14\",\"2\":\"1.21156669\",\"3\":\"-0.001642385\",\"4\":\"0.1346749133\"},{\"1\":\"15\",\"2\":\"0.50438236\",\"3\":\"-0.136553019\",\"4\":\"0.0499154896\"},{\"1\":\"16\",\"2\":\"-2.19552202\",\"3\":\"0.038688617\",\"4\":\"0.0658700256\"},{\"1\":\"17\",\"2\":\"-2.44039555\",\"3\":\"0.084935412\",\"4\":\"-0.0706813561\"},{\"1\":\"18\",\"2\":\"0.43441976\",\"3\":\"-0.138805721\",\"4\":\"0.0029381853\"},{\"1\":\"19\",\"2\":\"-2.06822631\",\"3\":\"-0.095252658\",\"4\":\"-0.0557049069\"},{\"1\":\"20\",\"2\":\"2.48143874\",\"3\":\"-0.011516538\",\"4\":\"0.0708733872\"},{\"1\":\"21\",\"2\":\"0.54611315\",\"3\":\"-0.198539188\",\"4\":\"-0.0936555767\"},{\"1\":\"22\",\"2\":\"0.73037784\",\"3\":\"0.212917556\",\"4\":\"-0.1624804340\"},{\"1\":\"23\",\"2\":\"-1.68086687\",\"3\":\"0.215064163\",\"4\":\"-0.1100237827\"},{\"1\":\"24\",\"2\":\"-0.68754546\",\"3\":\"0.105150870\",\"4\":\"0.0514664645\"},{\"1\":\"25\",\"2\":\"2.46251906\",\"3\":\"-0.251775706\",\"4\":\"-0.1006108111\"},{\"1\":\"26\",\"2\":\"-1.31633686\",\"3\":\"-0.158585661\",\"4\":\"-0.0569152008\"},{\"1\":\"27\",\"2\":\"1.66269539\",\"3\":\"-0.085431981\",\"4\":\"0.0319262840\"},{\"1\":\"28\",\"2\":\"2.86050854\",\"3\":\"0.077179366\",\"4\":\"-0.0790868818\"},{\"1\":\"29\",\"2\":\"-0.71229957\",\"3\":\"-0.166118941\",\"4\":\"-0.1590637380\"},{\"1\":\"30\",\"2\":\"0.28734852\",\"3\":\"-0.215672978\",\"4\":\"-0.0554491781\"},{\"1\":\"31\",\"2\":\"0.70445497\",\"3\":\"0.085572254\",\"4\":\"0.0161732263\"},{\"1\":\"32\",\"2\":\"0.24118900\",\"3\":\"-0.035204243\",\"4\":\"0.2031905172\"},{\"1\":\"33\",\"2\":\"3.29514377\",\"3\":\"0.004058795\",\"4\":\"0.0283640145\"},{\"1\":\"34\",\"2\":\"-1.16435715\",\"3\":\"-0.172366106\",\"4\":\"-0.0294020157\"},{\"1\":\"35\",\"2\":\"0.34465273\",\"3\":\"-0.253602507\",\"4\":\"-0.1300963783\"},{\"1\":\"36\",\"2\":\"1.03424153\",\"3\":\"0.222222713\",\"4\":\"-0.0005640946\"},{\"1\":\"37\",\"2\":\"0.21749307\",\"3\":\"-0.008128879\",\"4\":\"-0.0897987029\"},{\"1\":\"38\",\"2\":\"3.05002011\",\"3\":\"-0.331570043\",\"4\":\"0.0274009376\"},{\"1\":\"39\",\"2\":\"2.01447802\",\"3\":\"0.225267569\",\"4\":\"-0.0427638210\"},{\"1\":\"40\",\"2\":\"-0.50642506\",\"3\":\"0.136613889\",\"4\":\"-0.0118769265\"},{\"1\":\"41\",\"2\":\"-1.24939036\",\"3\":\"0.132101509\",\"4\":\"-0.0742558614\"},{\"1\":\"42\",\"2\":\"1.75078998\",\"3\":\"0.127586856\",\"4\":\"-0.0328349790\"},{\"1\":\"43\",\"2\":\"0.72774408\",\"3\":\"0.008806172\",\"4\":\"-0.0827564051\"},{\"1\":\"44\",\"2\":\"-0.12652813\",\"3\":\"-0.268553127\",\"4\":\"-0.1148979122\"},{\"1\":\"45\",\"2\":\"0.22182854\",\"3\":\"-0.065802361\",\"4\":\"0.1390088724\"},{\"1\":\"46\",\"2\":\"-1.04960073\",\"3\":\"0.209847482\",\"4\":\"-0.0843191442\"},{\"1\":\"47\",\"2\":\"3.58157257\",\"3\":\"0.064261501\",\"4\":\"-0.1179989904\"},{\"1\":\"48\",\"2\":\"-0.11576350\",\"3\":\"0.400999804\",\"4\":\"0.1655455583\"},{\"1\":\"49\",\"2\":\"1.98978535\",\"3\":\"-0.330109349\",\"4\":\"0.0573034832\"},{\"1\":\"50\",\"2\":\"0.30277987\",\"3\":\"0.113209550\",\"4\":\"0.0409545821\"},{\"1\":\"51\",\"2\":\"0.39704453\",\"3\":\"-0.057936546\",\"4\":\"-0.2070950794\"},{\"1\":\"52\",\"2\":\"-1.08520291\",\"3\":\"-0.261713483\",\"4\":\"0.0418289241\"},{\"1\":\"53\",\"2\":\"2.33913499\",\"3\":\"-0.180717119\",\"4\":\"-0.0600304094\"},{\"1\":\"54\",\"2\":\"2.06670464\",\"3\":\"0.377195713\",\"4\":\"-0.0632536742\"},{\"1\":\"55\",\"2\":\"-0.86691998\",\"3\":\"-0.479475416\",\"4\":\"0.0429273912\"},{\"1\":\"56\",\"2\":\"0.85165358\",\"3\":\"0.185539523\",\"4\":\"0.1560941506\"},{\"1\":\"57\",\"2\":\"-2.52466294\",\"3\":\"-0.285508747\",\"4\":\"0.0852703967\"},{\"1\":\"58\",\"2\":\"-1.62025460\",\"3\":\"-0.022828544\",\"4\":\"-0.0091188230\"},{\"1\":\"59\",\"2\":\"1.32622917\",\"3\":\"-0.204817359\",\"4\":\"-0.0490875727\"},{\"1\":\"60\",\"2\":\"-1.46612071\",\"3\":\"0.205383051\",\"4\":\"0.0135070134\"},{\"1\":\"61\",\"2\":\"3.40862545\",\"3\":\"0.215555063\",\"4\":\"0.0996707191\"},{\"1\":\"62\",\"2\":\"-4.61075583\",\"3\":\"-0.051856944\",\"4\":\"0.0658271845\"},{\"1\":\"63\",\"2\":\"-2.94935632\",\"3\":\"0.026276353\",\"4\":\"0.0489739621\"},{\"1\":\"64\",\"2\":\"1.59576019\",\"3\":\"-0.191178609\",\"4\":\"0.1162008584\"},{\"1\":\"65\",\"2\":\"-2.11792874\",\"3\":\"0.074192316\",\"4\":\"-0.0316120031\"},{\"1\":\"66\",\"2\":\"-0.54071593\",\"3\":\"0.229741569\",\"4\":\"-0.0054240707\"},{\"1\":\"67\",\"2\":\"-0.84569988\",\"3\":\"-0.429495960\",\"4\":\"0.1424384577\"},{\"1\":\"68\",\"2\":\"-2.51771060\",\"3\":\"-0.160286049\",\"4\":\"0.0333885176\"},{\"1\":\"69\",\"2\":\"-3.25511953\",\"3\":\"-0.039162856\",\"4\":\"-0.0525686066\"},{\"1\":\"70\",\"2\":\"-1.54293015\",\"3\":\"0.318510569\",\"4\":\"-0.0612409944\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n:::protip\nIn general it is more efficient to use singular value decomposition than eigendecomposition when carrying out a PCA. As such the use of `prcomp()` rather than `princomp()` is recommended in practice. \n:::\n\n\n<br />\n\n## Scaling the Predictors\n\nIn practice, it is important to scale all the predictors used in the PCA. This is especially true when the variables are measured in different metrics or have varying degrees of magnitude. In these cases, not scaling the predictors will often result in results in which variables with large magnitudes of scale dominate the PCA. It also is helpful when the predictors are measured using qualitatively different scales (e.g., one is measured in dollars and another in years of education). \n\n:::fyi\nRecall, the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix for a set of standardized predictors his the correlation matrix of the predictors. Thus, the SVD is actually being carried out on the correlation matrix rather than the raw  $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix. \n:::\n\nWhile it isn't necessary to also center the predictors, it is common to simply standardize the set of predictors being used in the PCA (i.e., convert them to *z*-scores); thus both centering and scaling them. To do this, we will pipe the selected predictors into the `scale()` function prior to piping into the `prcomp()` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit the PCA using SVD decomposition on standardized predictors\nsvd_pca_z = eeo |>\n  select(faculty, peer, school) |>\n  scale(center = TRUE, scale = TRUE) |>\n  prcomp()\n\n# View standard deviations and rotation matrix (eigenvector matrix)\nsvd_pca_z\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStandard deviations (1, .., p=3):\n[1] 1.71813654 0.20011873 0.08921511\n\nRotation (n x k) = (3 x 3):\n               PC1         PC2        PC3\nfaculty -0.5761385  0.67939712 -0.4544052\npeer    -0.5754361 -0.73197527 -0.3648089\nschool  -0.5804634  0.05130072  0.8126687\n```\n:::\n\n```{.r .cell-code}\n# tidy version of the rotation matrix (good for graphing)\nsvd_pca_z |>\n  tidy(matrix = \"rotation\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"column\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"PC\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"faculty\",\"2\":\"1\",\"3\":\"-0.57613845\"},{\"1\":\"faculty\",\"2\":\"2\",\"3\":\"0.67939712\"},{\"1\":\"faculty\",\"2\":\"3\",\"3\":\"-0.45440515\"},{\"1\":\"peer\",\"2\":\"1\",\"3\":\"-0.57543610\"},{\"1\":\"peer\",\"2\":\"2\",\"3\":\"-0.73197527\"},{\"1\":\"peer\",\"2\":\"3\",\"3\":\"-0.36480886\"},{\"1\":\"school\",\"2\":\"1\",\"3\":\"-0.58046342\"},{\"1\":\"school\",\"2\":\"2\",\"3\":\"0.05130072\"},{\"1\":\"school\",\"2\":\"3\",\"3\":\"0.81266873\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# View sds, variance accounted for\nsvd_pca_z |>\n  tidy(matrix = \"eigenvalues\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"PC\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.dev\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"percent\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cumulative\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"1.71813654\",\"3\":\"0.98400\",\"4\":\"0.98400\"},{\"1\":\"2\",\"2\":\"0.20011873\",\"3\":\"0.01335\",\"4\":\"0.99735\"},{\"1\":\"3\",\"2\":\"0.08921511\",\"3\":\"0.00265\",\"4\":\"1.00000\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Obtain PC scores\npc_scores = augment(svd_pca_z)\npc_scores\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".rownames\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".fittedPC1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC3\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"-0.36630991\",\"3\":\"0.366083254\",\"4\":\"-0.123459444\"},{\"1\":\"2\",\"2\":\"-0.94977721\",\"3\":\"0.149343548\",\"4\":\"-0.084727422\"},{\"1\":\"3\",\"2\":\"1.34412355\",\"3\":\"-0.063278543\",\"4\":\"-0.019661363\"},{\"1\":\"4\",\"2\":\"2.08704153\",\"3\":\"0.128977212\",\"4\":\"0.192989279\"},{\"1\":\"5\",\"2\":\"0.01515640\",\"3\":\"0.266909829\",\"4\":\"0.126681564\"},{\"1\":\"6\",\"2\":\"-0.26881618\",\"3\":\"0.043736173\",\"4\":\"0.095210936\"},{\"1\":\"7\",\"2\":\"-0.02748806\",\"3\":\"0.229673318\",\"4\":\"-0.012776619\"},{\"1\":\"8\",\"2\":\"-0.67241667\",\"3\":\"0.230646070\",\"4\":\"0.090457272\"},{\"1\":\"9\",\"2\":\"1.06386403\",\"3\":\"-0.026134791\",\"4\":\"-0.036853020\"},{\"1\":\"10\",\"2\":\"-1.37219342\",\"3\":\"0.181768424\",\"4\":\"0.092537736\"},{\"1\":\"11\",\"2\":\"-1.86607933\",\"3\":\"0.029940082\",\"4\":\"0.038043107\"},{\"1\":\"12\",\"2\":\"-0.92411758\",\"3\":\"-0.269230860\",\"4\":\"0.027612018\"},{\"1\":\"13\",\"2\":\"-1.24385723\",\"3\":\"-0.022169317\",\"4\":\"-0.057959986\"},{\"1\":\"14\",\"2\":\"1.19879446\",\"3\":\"0.011689953\",\"4\":\"0.132069854\"},{\"1\":\"15\",\"2\":\"0.48139865\",\"3\":\"-0.132336560\",\"4\":\"0.052120923\"},{\"1\":\"16\",\"2\":\"-2.16101996\",\"3\":\"0.050194885\",\"4\":\"0.063727714\"},{\"1\":\"17\",\"2\":\"-2.39976796\",\"3\":\"0.081435895\",\"4\":\"-0.071241348\"},{\"1\":\"18\",\"2\":\"0.41101703\",\"3\":\"-0.139860379\",\"4\":\"0.006111503\"},{\"1\":\"19\",\"2\":\"-2.05528327\",\"3\":\"-0.098512321\",\"4\":\"-0.052359021\"},{\"1\":\"20\",\"2\":\"2.44976450\",\"3\":\"-0.007725645\",\"4\":\"0.069715758\"},{\"1\":\"21\",\"2\":\"0.51147071\",\"3\":\"-0.211127612\",\"4\":\"-0.087211303\"},{\"1\":\"22\",\"2\":\"0.74497495\",\"3\":\"0.194033799\",\"4\":\"-0.164301261\"},{\"1\":\"23\",\"2\":\"-1.63401661\",\"3\":\"0.206352504\",\"4\":\"-0.112869183\"},{\"1\":\"24\",\"2\":\"-0.66406402\",\"3\":\"0.112717626\",\"4\":\"0.048024774\"},{\"1\":\"25\",\"2\":\"2.39634941\",\"3\":\"-0.268708397\",\"4\":\"-0.092825678\"},{\"1\":\"26\",\"2\":\"-1.32120750\",\"3\":\"-0.163572431\",\"4\":\"-0.052082379\"},{\"1\":\"27\",\"2\":\"1.63110467\",\"3\":\"-0.085034538\",\"4\":\"0.033266746\"},{\"1\":\"28\",\"2\":\"2.83216679\",\"3\":\"0.063550398\",\"4\":\"-0.079403717\"},{\"1\":\"29\",\"2\":\"-0.72809081\",\"3\":\"-0.183882030\",\"4\":\"-0.152079301\"},{\"1\":\"30\",\"2\":\"0.25463606\",\"3\":\"-0.223518554\",\"4\":\"-0.049343509\"},{\"1\":\"31\",\"2\":\"0.70684120\",\"3\":\"0.086607838\",\"4\":\"0.013848414\"},{\"1\":\"32\",\"2\":\"0.23798665\",\"3\":\"-0.012507535\",\"4\":\"0.200054088\"},{\"1\":\"33\",\"2\":\"3.25414842\",\"3\":\"0.001650850\",\"4\":\"0.027654460\"},{\"1\":\"34\",\"2\":\"-1.17235034\",\"3\":\"-0.174526888\",\"4\":\"-0.024785850\"},{\"1\":\"35\",\"2\":\"0.30468755\",\"3\":\"-0.270273220\",\"4\":\"-0.121654459\"},{\"1\":\"36\",\"2\":\"1.04967957\",\"3\":\"0.221405970\",\"4\":\"-0.005758073\"},{\"1\":\"37\",\"2\":\"0.21170748\",\"3\":\"-0.018827486\",\"4\":\"-0.087866077\"},{\"1\":\"38\",\"2\":\"2.96882863\",\"3\":\"-0.335220713\",\"4\":\"0.034546120\"},{\"1\":\"39\",\"2\":\"2.01685524\",\"3\":\"0.217942570\",\"4\":\"-0.047226556\"},{\"1\":\"40\",\"2\":\"-0.48257905\",\"3\":\"0.136758500\",\"4\":\"-0.014823814\"},{\"1\":\"41\",\"2\":\"-1.21798429\",\"3\":\"0.126359531\",\"4\":\"-0.075869619\"},{\"1\":\"42\",\"2\":\"1.74415056\",\"3\":\"0.121400936\",\"4\":\"-0.035206637\"},{\"1\":\"43\",\"2\":\"0.71777230\",\"3\":\"-0.001886201\",\"4\":\"-0.081365699\"},{\"1\":\"44\",\"2\":\"-0.16206634\",\"3\":\"-0.282740528\",\"4\":\"-0.106393837\"},{\"1\":\"45\",\"2\":\"0.21352776\",\"3\":\"-0.050565960\",\"4\":\"0.137835477\"},{\"1\":\"46\",\"2\":\"-1.01093624\",\"3\":\"0.202968753\",\"4\":\"-0.087554998\"},{\"1\":\"47\",\"2\":\"3.54149592\",\"3\":\"0.044873349\",\"4\":\"-0.117271128\"},{\"1\":\"48\",\"2\":\"-0.05893310\",\"3\":\"0.422019659\",\"4\":\"0.152970310\"},{\"1\":\"49\",\"2\":\"1.92299129\",\"3\":\"-0.328501725\",\"4\":\"0.063853075\"},{\"1\":\"50\",\"2\":\"0.31440849\",\"3\":\"0.117903698\",\"4\":\"0.037510439\"},{\"1\":\"51\",\"2\":\"0.37998150\",\"3\":\"-0.082611286\",\"4\":\"-0.201721609\"},{\"1\":\"52\",\"2\":\"-1.10418661\",\"3\":\"-0.256265047\",\"4\":\"0.047142482\"},{\"1\":\"53\",\"2\":\"2.28459622\",\"3\":\"-0.192459709\",\"4\":\"-0.054690472\"},{\"1\":\"54\",\"2\":\"2.08757269\",\"3\":\"0.368137396\",\"4\":\"-0.070863738\"},{\"1\":\"55\",\"2\":\"-0.91677116\",\"3\":\"-0.475285807\",\"4\":\"0.053296498\"},{\"1\":\"56\",\"2\":\"0.86810421\",\"3\":\"0.202812372\",\"4\":\"0.148711680\"},{\"1\":\"57\",\"2\":\"-2.52736408\",\"3\":\"-0.272714928\",\"4\":\"0.090321507\"},{\"1\":\"58\",\"2\":\"-1.60267993\",\"3\":\"-0.021187984\",\"4\":\"-0.008377765\"},{\"1\":\"59\",\"2\":\"1.28177134\",\"3\":\"-0.213673386\",\"4\":\"-0.043378834\"},{\"1\":\"60\",\"2\":\"-1.42057581\",\"3\":\"0.210406950\",\"4\":\"0.008480000\"},{\"1\":\"61\",\"2\":\"3.39502328\",\"3\":\"0.222099386\",\"4\":\"0.092636766\"},{\"1\":\"62\",\"2\":\"-4.55705387\",\"3\":\"-0.036614805\",\"4\":\"0.065844608\"},{\"1\":\"63\",\"2\":\"-2.90718418\",\"3\":\"0.037088167\",\"4\":\"0.047464410\"},{\"1\":\"64\",\"2\":\"1.55321495\",\"3\":\"-0.181502142\",\"4\":\"0.118370378\"},{\"1\":\"65\",\"2\":\"-2.08196024\",\"3\":\"0.074562941\",\"4\":\"-0.032687618\"},{\"1\":\"66\",\"2\":\"-0.50427367\",\"3\":\"0.231115777\",\"4\":\"-0.010668820\"},{\"1\":\"67\",\"2\":\"-0.88720610\",\"3\":\"-0.413712532\",\"4\":\"0.149704902\"},{\"1\":\"68\",\"2\":\"-2.50547162\",\"3\":\"-0.152867180\",\"4\":\"0.036527049\"},{\"1\":\"69\",\"2\":\"-3.21969291\",\"3\":\"-0.039759058\",\"4\":\"-0.050569804\"},{\"1\":\"70\",\"2\":\"-1.48343272\",\"3\":\"0.315628485\",\"4\":\"-0.067451885\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nHere the results from using the standardized predictors are not that different from the previous results since the variables were already reported as *z*-scores to begin with. The variance accounted for by the principal components is comparable (within rounding); the standardization of the predictors does not change this. The actual principal components in the **V** (rotation) matrix are different because of the centering and scaling, but the interpretations are the same as when we used the decomposition based on the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix. Similarly, because of the centering and scaling, the PC scores are different.\n\n<br />\n\n\n## Behind the Scenes\n\nBy standardizing the predictors, we are carrying out the SVD on the correlation matrix of the predictors rather than on the $\\mathbf{X}^{\\intercal}_{\\mathrm{Predictor}}\\mathbf{X}_{\\mathrm{Predictor}}$ matrix. To see this, recall that the correlation matrix of the predictors ($\\mathbf{R_X}$) is based on the standardized predictors, namely,\n\n:::protip\nThis implies that you can also carry out PCA on summaries of the predictors (rather than the raw data) by decomposing either the covariance matrix of the predictors or the correlation matrix of the predictors. This can be useful for example, when trying to reproduce the results of a PCA from a published paper, in which authors will often report summaries of the data used (e.g., correlation matrices) but not the raw data.\n:::\n\n$$\n\\mathbf{R_X} = \\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big)\n$$\n\nThe $1/(n-1)$ component is a scalar and is pulled out so that the decomposition is carried out on the $\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}$ matrix:\n\n$$\n\\frac{1}{n-1} \\big(\\mathbf{X}^{\\intercal}_{\\mathrm{Standardized~Predictor}}\\mathbf{X}_{\\mathrm{Standardized~Predictor}}\\big) = \\frac{1}{n-1}\\mathbf{U}\\mathbf{D}\\mathbf{V}^{\\intercal}\n$$\n\nSimilarly, we can also decompose the covariance matrix of the predictors ($\\boldsymbol\\Sigma_{\\mathbf{X}}$), which is based on the centered predictors,\n\n$$\n\\boldsymbol\\Sigma_{\\mathbf{X}} = \\frac{1}{n-1} \\big( \\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}\\big)\n$$\n\nIn this case, the decomposition is carried out on the $\\mathbf{X}^{\\intercal}_{\\mathrm{Centered~Predictor}}\\mathbf{X}_{\\mathrm{Centered~Predictor}}$ matrix. To do this using `prcomp()` we would change the `scale=` argument to `FALSE` in the `scale()` function, while still leaving `center=TRUE`.\n\n<br />\n\n\n# Using the Principal Components in a Regression Model\n\nRemember, we undertook the PCA because of the collinearity in the original predictors. Rather than using the original predictor values in our regression, we can use the scores from the PCA. Since we created the principal components to be orthogonal, this should alleviate any collinearity problems. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add the PC scores to the original data\neeo2 = eeo |>\n  bind_cols(pc_scores)\n\n# View data\neeo2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"achievement\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"faculty\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"peer\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"school\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".rownames\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".fittedPC1\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC2\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC3\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.43148\",\"2\":\"0.60814\",\"3\":\"0.03509\",\"4\":\"0.16607\",\"5\":\"1\",\"6\":\"-0.36630991\",\"7\":\"0.366083254\",\"8\":\"-0.123459444\"},{\"1\":\"0.79969\",\"2\":\"0.79369\",\"3\":\"0.47924\",\"4\":\"0.53356\",\"5\":\"2\",\"6\":\"-0.94977721\",\"7\":\"0.149343548\",\"8\":\"-0.084727422\"},{\"1\":\"-0.92467\",\"2\":\"-0.82630\",\"3\":\"-0.61951\",\"4\":\"-0.78635\",\"5\":\"3\",\"6\":\"1.34412355\",\"7\":\"-0.063278543\",\"8\":\"-0.019661363\"},{\"1\":\"-2.19081\",\"2\":\"-1.25310\",\"3\":\"-1.21675\",\"4\":\"-1.04076\",\"5\":\"4\",\"6\":\"2.08704153\",\"7\":\"0.128977212\",\"8\":\"0.192989279\"},{\"1\":\"-2.84818\",\"2\":\"0.17399\",\"3\":\"-0.18517\",\"4\":\"0.14229\",\"5\":\"5\",\"6\":\"0.01515640\",\"7\":\"0.266909829\",\"8\":\"0.126681564\"},{\"1\":\"-0.66233\",\"2\":\"0.20246\",\"3\":\"0.12764\",\"4\":\"0.27311\",\"5\":\"6\",\"6\":\"-0.26881618\",\"7\":\"0.043736173\",\"8\":\"0.095210936\"},{\"1\":\"2.63674\",\"2\":\"0.24184\",\"3\":\"-0.09022\",\"4\":\"0.04967\",\"5\":\"7\",\"6\":\"-0.02748806\",\"7\":\"0.229673318\",\"8\":\"-0.012776619\"},{\"1\":\"2.35847\",\"2\":\"0.59421\",\"3\":\"0.21750\",\"4\":\"0.51876\",\"5\":\"8\",\"6\":\"-0.67241667\",\"7\":\"0.230646070\",\"8\":\"0.090457272\"},{\"1\":\"-0.91305\",\"2\":\"-0.61561\",\"3\":\"-0.48971\",\"4\":\"-0.63219\",\"5\":\"9\",\"6\":\"1.06386403\",\"7\":\"-0.026134791\",\"8\":\"-0.036853020\"},{\"1\":\"0.59445\",\"2\":\"0.99391\",\"3\":\"0.62228\",\"4\":\"0.93368\",\"5\":\"10\",\"6\":\"-1.37219342\",\"7\":\"0.181768424\",\"8\":\"0.092537736\"},{\"1\":\"1.21073\",\"2\":\"1.21721\",\"3\":\"1.00627\",\"4\":\"1.17381\",\"5\":\"11\",\"6\":\"-1.86607933\",\"7\":\"0.029940082\",\"8\":\"0.038043107\"},{\"1\":\"1.87164\",\"2\":\"0.41436\",\"3\":\"0.71103\",\"4\":\"0.58978\",\"5\":\"12\",\"6\":\"-0.92411758\",\"7\":\"-0.269230860\",\"8\":\"0.027612018\"},{\"1\":\"-0.10178\",\"2\":\"0.83782\",\"3\":\"0.74281\",\"4\":\"0.72154\",\"5\":\"13\",\"6\":\"-1.24385723\",\"7\":\"-0.022169317\",\"8\":\"-0.057959986\"},{\"1\":\"-2.87949\",\"2\":\"-0.75512\",\"3\":\"-0.64411\",\"4\":\"-0.56986\",\"5\":\"14\",\"6\":\"1.19879446\",\"7\":\"0.011689953\",\"8\":\"0.132069854\"},{\"1\":\"3.92590\",\"2\":\"-0.37407\",\"3\":\"-0.13787\",\"4\":\"-0.21770\",\"5\":\"15\",\"6\":\"0.48139865\",\"7\":\"-0.132336560\",\"8\":\"0.052120923\"},{\"1\":\"4.35084\",\"2\":\"1.40353\",\"3\":\"1.14085\",\"4\":\"1.37147\",\"5\":\"16\",\"6\":\"-2.16101996\",\"7\":\"0.050194885\",\"8\":\"0.063727714\"},{\"1\":\"1.57922\",\"2\":\"1.64194\",\"3\":\"1.29229\",\"4\":\"1.40269\",\"5\":\"17\",\"6\":\"-2.39976796\",\"7\":\"0.081435895\",\"8\":\"-0.071241348\"},{\"1\":\"3.95689\",\"2\":\"-0.31304\",\"3\":\"-0.07980\",\"4\":\"-0.21455\",\"5\":\"18\",\"6\":\"0.41101703\",\"7\":\"-0.139860379\",\"8\":\"0.006111503\"},{\"1\":\"1.09275\",\"2\":\"1.28525\",\"3\":\"1.22441\",\"4\":\"1.20428\",\"5\":\"19\",\"6\":\"-2.05528327\",\"7\":\"-0.098512321\",\"8\":\"-0.052359021\"},{\"1\":\"-0.62389\",\"2\":\"-1.51938\",\"3\":\"-1.27565\",\"4\":\"-1.36598\",\"5\":\"20\",\"6\":\"2.44976450\",\"7\":\"-0.007725645\",\"8\":\"0.069715758\"},{\"1\":\"-0.63654\",\"2\":\"-0.38224\",\"3\":\"-0.05353\",\"4\":\"-0.35560\",\"5\":\"21\",\"6\":\"0.51147071\",\"7\":\"-0.211127612\",\"8\":\"-0.087211303\"},{\"1\":\"-2.02659\",\"2\":\"-0.19186\",\"3\":\"-0.42605\",\"4\":\"-0.53718\",\"5\":\"22\",\"6\":\"0.74497495\",\"7\":\"0.194033799\",\"8\":\"-0.164301261\"},{\"1\":\"-1.46692\",\"2\":\"1.27649\",\"3\":\"0.81427\",\"4\":\"0.91967\",\"5\":\"23\",\"6\":\"-1.63401661\",\"7\":\"0.206352504\",\"8\":\"-0.112869183\"},{\"1\":\"3.15078\",\"2\":\"0.52310\",\"3\":\"0.30720\",\"4\":\"0.47231\",\"5\":\"24\",\"6\":\"-0.66406402\",\"7\":\"0.112717626\",\"8\":\"0.048024774\"},{\"1\":\"-2.18938\",\"2\":\"-1.59810\",\"3\":\"-1.01572\",\"4\":\"-1.48315\",\"5\":\"25\",\"6\":\"2.39634941\",\"7\":\"-0.268708397\",\"8\":\"-0.092825678\"},{\"1\":\"1.91715\",\"2\":\"0.77914\",\"3\":\"0.87771\",\"4\":\"0.76496\",\"5\":\"26\",\"6\":\"-1.32120750\",\"7\":\"-0.163572431\",\"8\":\"-0.052082379\"},{\"1\":\"-2.71428\",\"2\":\"-1.04745\",\"3\":\"-0.77536\",\"4\":\"-0.91397\",\"5\":\"27\",\"6\":\"1.63110467\",\"7\":\"-0.085034538\",\"8\":\"0.033266746\"},{\"1\":\"-6.59852\",\"2\":\"-1.63217\",\"3\":\"-1.47709\",\"4\":\"-1.71347\",\"5\":\"28\",\"6\":\"2.83216679\",\"7\":\"0.063550398\",\"8\":\"-0.079403717\"},{\"1\":\"0.65101\",\"2\":\"0.44328\",\"3\":\"0.60956\",\"4\":\"0.32833\",\"5\":\"29\",\"6\":\"-0.72809081\",\"7\":\"-0.183882030\",\"8\":\"-0.152079301\"},{\"1\":\"-0.13772\",\"2\":\"-0.24972\",\"3\":\"0.07876\",\"4\":\"-0.17216\",\"5\":\"30\",\"6\":\"0.25463606\",\"7\":\"-0.223518554\",\"8\":\"-0.049343509\"},{\"1\":\"-2.43959\",\"2\":\"-0.33480\",\"3\":\"-0.39314\",\"4\":\"-0.37198\",\"5\":\"31\",\"6\":\"0.70684120\",\"7\":\"0.086607838\",\"8\":\"0.013848414\"},{\"1\":\"-3.27802\",\"2\":\"-0.20680\",\"3\":\"-0.13936\",\"4\":\"0.05626\",\"5\":\"32\",\"6\":\"0.23798665\",\"7\":\"-0.012507535\",\"8\":\"0.200054088\"},{\"1\":\"-2.48058\",\"2\":\"-1.99375\",\"3\":\"-1.69587\",\"4\":\"-1.87838\",\"5\":\"33\",\"6\":\"3.25414842\",\"7\":\"0.001650850\",\"8\":\"0.027654460\"},{\"1\":\"1.88639\",\"2\":\"0.66475\",\"3\":\"0.79670\",\"4\":\"0.69865\",\"5\":\"34\",\"6\":\"-1.17235034\",\"7\":\"-0.174526888\",\"8\":\"-0.024785850\"},{\"1\":\"5.06459\",\"2\":\"-0.27977\",\"3\":\"0.10817\",\"4\":\"-0.26450\",\"5\":\"35\",\"6\":\"0.30468755\",\"7\":\"-0.270273220\",\"8\":\"-0.121654459\"},{\"1\":\"1.96335\",\"2\":\"-0.43990\",\"3\":\"-0.66022\",\"4\":\"-0.58490\",\"5\":\"36\",\"6\":\"1.04967957\",\"7\":\"0.221405970\",\"8\":\"-0.005758073\"},{\"1\":\"0.26274\",\"2\":\"-0.05334\",\"3\":\"-0.02396\",\"4\":\"-0.16795\",\"5\":\"37\",\"6\":\"0.21170748\",\"7\":\"-0.018827486\",\"8\":\"-0.087866077\"},{\"1\":\"-2.94593\",\"2\":\"-2.06699\",\"3\":\"-1.31832\",\"4\":\"-1.72082\",\"5\":\"38\",\"6\":\"2.96882863\",\"7\":\"-0.335220713\",\"8\":\"0.034546120\"},{\"1\":\"-1.38628\",\"2\":\"-1.02560\",\"3\":\"-1.15858\",\"4\":\"-1.19420\",\"5\":\"39\",\"6\":\"2.01685524\",\"7\":\"0.217942570\",\"8\":\"-0.047226556\"},{\"1\":\"-0.20797\",\"2\":\"0.45847\",\"3\":\"0.21555\",\"4\":\"0.31347\",\"5\":\"40\",\"6\":\"-0.48257905\",\"7\":\"0.136758500\",\"8\":\"-0.014823814\"},{\"1\":\"-1.07820\",\"2\":\"0.93979\",\"3\":\"0.63454\",\"4\":\"0.69907\",\"5\":\"41\",\"6\":\"-1.21798429\",\"7\":\"0.126359531\",\"8\":\"-0.075869619\"},{\"1\":\"-1.66386\",\"2\":\"-0.93238\",\"3\":\"-0.95216\",\"4\":\"-1.02725\",\"5\":\"42\",\"6\":\"1.74415056\",\"7\":\"0.121400936\",\"8\":\"-0.035206637\"},{\"1\":\"0.58117\",\"2\":\"-0.35988\",\"3\":\"-0.30693\",\"4\":\"-0.46232\",\"5\":\"43\",\"6\":\"0.71777230\",\"7\":\"-0.001886201\",\"8\":\"-0.081365699\"},{\"1\":\"1.37447\",\"2\":\"-0.00518\",\"3\":\"0.35985\",\"4\":\"0.02485\",\"5\":\"44\",\"6\":\"-0.16206634\",\"7\":\"-0.282740528\",\"8\":\"-0.106393837\"},{\"1\":\"-2.82687\",\"2\":\"-0.18892\",\"3\":\"-0.07959\",\"4\":\"0.01704\",\"5\":\"45\",\"6\":\"0.21352776\",\"7\":\"-0.050565960\",\"8\":\"0.137835477\"},{\"1\":\"3.86363\",\"2\":\"0.87271\",\"3\":\"0.47644\",\"4\":\"0.57036\",\"5\":\"46\",\"6\":\"-1.01093624\",\"7\":\"0.202968753\",\"8\":\"-0.087554998\"},{\"1\":\"-2.64141\",\"2\":\"-2.06993\",\"3\":\"-1.82915\",\"4\":\"-2.16738\",\"5\":\"47\",\"6\":\"3.54149592\",\"7\":\"0.044873349\",\"8\":\"-0.117271128\"},{\"1\":\"0.05387\",\"2\":\"0.32143\",\"3\":\"-0.25961\",\"4\":\"0.21632\",\"5\":\"48\",\"6\":\"-0.05893310\",\"7\":\"0.422019659\",\"8\":\"0.152970310\"},{\"1\":\"0.50763\",\"2\":\"-1.42382\",\"3\":\"-0.77620\",\"4\":\"-1.07473\",\"5\":\"49\",\"6\":\"1.92299129\",\"7\":\"-0.328501725\",\"8\":\"0.063853075\"},{\"1\":\"0.64347\",\"2\":\"-0.07852\",\"3\":\"-0.21347\",\"4\":\"-0.11750\",\"5\":\"50\",\"6\":\"0.31440849\",\"7\":\"0.117903698\",\"8\":\"0.037510439\"},{\"1\":\"2.49414\",\"2\":\"-0.14925\",\"3\":\"-0.03192\",\"4\":\"-0.36598\",\"5\":\"51\",\"6\":\"0.37998150\",\"7\":\"-0.082611286\",\"8\":\"-0.201721609\"},{\"1\":\"0.61955\",\"2\":\"0.52666\",\"3\":\"0.79149\",\"4\":\"0.71369\",\"5\":\"52\",\"6\":\"-1.10418661\",\"7\":\"-0.256265047\",\"8\":\"0.047142482\"},{\"1\":\"0.61745\",\"2\":\"-1.49102\",\"3\":\"-1.02073\",\"4\":\"-1.38103\",\"5\":\"53\",\"6\":\"2.28459622\",\"7\":\"-0.192459709\",\"8\":\"-0.054690472\"},{\"1\":\"-1.00743\",\"2\":\"-0.94757\",\"3\":\"-1.28991\",\"4\":\"-1.24799\",\"5\":\"54\",\"6\":\"2.08757269\",\"7\":\"0.368137396\",\"8\":\"-0.070863738\"},{\"1\":\"-0.37469\",\"2\":\"0.24550\",\"3\":\"0.83794\",\"4\":\"0.59596\",\"5\":\"55\",\"6\":\"-0.91677116\",\"7\":\"-0.475285807\",\"8\":\"0.053296498\"},{\"1\":\"-2.52824\",\"2\":\"-0.41630\",\"3\":\"-0.60312\",\"4\":\"-0.34951\",\"5\":\"56\",\"6\":\"0.86810421\",\"7\":\"0.202812372\",\"8\":\"0.148711680\"},{\"1\":\"0.02372\",\"2\":\"1.38143\",\"3\":\"1.54542\",\"4\":\"1.59429\",\"5\":\"57\",\"6\":\"-2.52736408\",\"7\":\"-0.272714928\",\"8\":\"0.090321507\"},{\"1\":\"2.51077\",\"2\":\"1.03806\",\"3\":\"0.91637\",\"4\":\"0.97602\",\"5\":\"58\",\"6\":\"-1.60267993\",\"7\":\"-0.021187984\",\"8\":\"-0.008377765\"},{\"1\":\"-4.22716\",\"2\":\"-0.88639\",\"3\":\"-0.47652\",\"4\":\"-0.77693\",\"5\":\"59\",\"6\":\"1.28177134\",\"7\":\"-0.213673386\",\"8\":\"-0.043378834\"},{\"1\":\"1.96847\",\"2\":\"1.08655\",\"3\":\"0.65700\",\"4\":\"0.89401\",\"5\":\"60\",\"6\":\"-1.42057581\",\"7\":\"0.210406950\",\"8\":\"0.008480000\"},{\"1\":\"1.25668\",\"2\":\"-1.95142\",\"3\":\"-1.94199\",\"4\":\"-1.89645\",\"5\":\"61\",\"6\":\"3.39502328\",\"7\":\"0.222099386\",\"8\":\"0.092636766\"},{\"1\":\"-0.16848\",\"2\":\"2.83384\",\"3\":\"2.47398\",\"4\":\"2.79222\",\"5\":\"62\",\"6\":\"-4.55705387\",\"7\":\"-0.036614805\",\"8\":\"0.065844608\"},{\"1\":\"-0.34158\",\"2\":\"1.86753\",\"3\":\"1.55229\",\"4\":\"1.80057\",\"5\":\"63\",\"6\":\"-2.90718418\",\"7\":\"0.037088167\",\"8\":\"0.047464410\"},{\"1\":\"-2.23973\",\"2\":\"-1.11172\",\"3\":\"-0.69732\",\"4\":\"-0.80197\",\"5\":\"64\",\"6\":\"1.55321495\",\"7\":\"-0.181502142\",\"8\":\"0.118370378\"},{\"1\":\"3.62654\",\"2\":\"1.41958\",\"3\":\"1.11481\",\"4\":\"1.24558\",\"5\":\"65\",\"6\":\"-2.08196024\",\"7\":\"0.074562941\",\"8\":\"-0.032687618\"},{\"1\":\"0.97034\",\"2\":\"0.53940\",\"3\":\"0.16182\",\"4\":\"0.33477\",\"5\":\"66\",\"6\":\"-0.50427367\",\"7\":\"0.231115777\",\"8\":\"-0.010668820\"},{\"1\":\"3.16093\",\"2\":\"0.22491\",\"3\":\"0.74800\",\"4\":\"0.66182\",\"5\":\"67\",\"6\":\"-0.88720610\",\"7\":\"-0.413712532\",\"8\":\"0.149704902\"},{\"1\":\"-1.90801\",\"2\":\"1.48244\",\"3\":\"1.47079\",\"4\":\"1.54283\",\"5\":\"68\",\"6\":\"-2.50547162\",\"7\":\"-0.152867180\",\"8\":\"0.036527049\"},{\"1\":\"0.64598\",\"2\":\"2.05425\",\"3\":\"1.80369\",\"4\":\"1.90066\",\"5\":\"69\",\"6\":\"-3.21969291\",\"7\":\"-0.039759058\",\"8\":\"-0.050569804\"},{\"1\":\"-1.75915\",\"2\":\"1.24058\",\"3\":\"0.64484\",\"4\":\"0.87372\",\"5\":\"70\",\"6\":\"-1.48343272\",\"7\":\"0.315628485\",\"8\":\"-0.067451885\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Fit model using PC scores\nlm.pc = lm(achievement ~ 1 + .fittedPC1 + .fittedPC2 + .fittedPC3, data = eeo2)\n\n# Check for collinearity -- correlations\neeo2 |>\n  select(starts_with(\".fitted\")) |>\n  correlate()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".fittedPC1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".fittedPC3\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\".fittedPC1\",\"2\":\"NA\",\"3\":\"-2.956990e-15\",\"4\":\"1.770619e-16\"},{\"1\":\".fittedPC2\",\"2\":\"-2.956990e-15\",\"3\":\"NA\",\"4\":\"-8.996197e-16\"},{\"1\":\".fittedPC3\",\"2\":\"1.770619e-16\",\"3\":\"-8.996197e-16\",\"4\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Check for collinearity -- VIF\ncar::vif(lm.pc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.fittedPC1 .fittedPC2 .fittedPC3 \n         1          1          1 \n```\n:::\n:::\n\n\nExamining some of the collinearity diagnostics we see that the predictors in this model are completely uncorrelated and the VIF values are 1; indicating that the SEs for these coefficients are exactly as large as they would be if the predictors were independent (which they are). Looking at the model- and coefficient-level output:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Model-level output\nglance(lm.pc)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"r.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"adj.r.squared\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sigma\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"logLik\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df.residual\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[12],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.2062583\",\"2\":\"0.1701792\",\"3\":\"2.070256\",\"4\":\"5.716826\",\"5\":\"0.001534649\",\"6\":\"3\",\"7\":\"-148.2033\",\"8\":\"306.4066\",\"9\":\"317.6491\",\"10\":\"282.8732\",\"11\":\"66\",\"12\":\"70\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Coefficient-level output\ntidy(lm.pc, conf.int = 0.95)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.01919043\",\"3\":\"0.2474429\",\"4\":\"0.07755499\",\"5\":\"0.9384166886\",\"6\":\"-0.4748452\",\"7\":\"0.5132261\"},{\"1\":\".fittedPC1\",\"2\":\"-0.56774855\",\"3\":\"0.1450580\",\"4\":\"-3.91394116\",\"5\":\"0.0002174854\",\"6\":\"-0.8573662\",\"7\":\"-0.2781309\"},{\"1\":\".fittedPC2\",\"2\":\"-0.88123459\",\"3\":\"1.2454080\",\"4\":\"-0.70758704\",\"5\":\"0.4816929775\",\"6\":\"-3.3677720\",\"7\":\"1.6053028\"},{\"1\":\".fittedPC3\",\"2\":\"-3.22275876\",\"3\":\"2.7935794\",\"4\":\"-1.15363063\",\"5\":\"0.2528122549\",\"6\":\"-8.8003200\",\"7\":\"2.3548025\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe model-level output from this model is exactly the same as the model-level output from the model fitted with the original predictors. The coefficient-level output is where we start to see differences. Because there is no collinearity in this model, we now see a statistically significant result at the coefficient level (PC1). The other thing to remember here is that each principal component is a composite variable composed of all three predictors and perhaps had a more substantive interpretation. We need to use those substantive interpretations in the interpretations of coefficients:\n\n- The intercept is the predicted average achievement for cases where all the composite variables are 0.\n- The positive slope associated with the first composite indicates that higher values on this composite are associated with higher achievement, on average. In other words, higher values on all three predictors are associated with higher achievement, on average.\n- The negative slope associated with the second composite indicates that higher values on this composite are associated with lower achievement, on average. In other words, larger contrasts between faculty credentials and peer influence are associated with lower achievement, on average.\n- The positive slope associated with the third composite indicates that higher values on this composite are associated with higher achievement, on average. In other words, larger contrasts between school facilities and faculty credentials/peer influence are associated with higher achievement, on average.\n\nAgain, these interpretations may not be satisfactory---it all depends on whether the loadings offer a reasonable interpretation of the composite variable.\n\n<br />\n\n\n# Dimension Reduction\n\nOne of the most useful qualities of a PCA, aside from fixing collinearity issues, can be to reduce the size of the predictor space in a regression model; thereby reducing the complexity of the model and improving statistical power. To do this, we consider the variance accounted for by each of the principal components. \n\nIn our example, the first principal component accounted for most of the variance in the original predictor space (approximately 98%). The other two principal components did not account for that much variation, which suggests that they may not be necessary. We can capture most of the variation in the original three predictors by just using the first principal component.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit reduced model using PC1\nlm.pc.2 = lm(achievement ~ 1 + .fittedPC1, data = eeo2)\n\n# Model-level output\nglance(lm.pc.2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"r.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"adj.r.squared\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sigma\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"logLik\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df.residual\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[12],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.1842315\",\"2\":\"0.1722349\",\"3\":\"2.06769\",\"4\":\"15.35698\",\"5\":\"0.0002091806\",\"6\":\"1\",\"7\":\"-149.1614\",\"8\":\"304.3227\",\"9\":\"311.0682\",\"10\":\"290.7231\",\"11\":\"68\",\"12\":\"70\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Coefficient-level output\ntidy(lm.pc.2, conf.int = 0.95)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"0.01919043\",\"3\":\"0.2471362\",\"4\":\"0.07765123\",\"5\":\"0.9383335253\",\"6\":\"-0.4739621\",\"7\":\"0.5123430\"},{\"1\":\".fittedPC1\",\"2\":\"-0.56774855\",\"3\":\"0.1448782\",\"4\":\"-3.91879821\",\"5\":\"0.0002091806\",\"6\":\"-0.8568486\",\"7\":\"-0.2786485\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIn this model, the model $R^2$ value is slightly smaller (0.183 rather than 0.206) since the first principal component did not account for all of the variance in the original predictors. However, this difference is negligible, and the model is still explains a statistically relevant amount of variation in achievement scores, $F(1,68)=15.25$, $p=0.0002$. \n\nFrom the coefficient-level output, we see that the magnitude of the intercept and slope are comparable to those in the model where all three composites were used. The standard error and *p*-value for the composite in this model are slightly smaller than when we used all of the predictors. This represents the additional two degrees of freedom in the error term that we got from reducing the number of predictors. (In this example, the differences are negligible.)\n\n<br />\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}